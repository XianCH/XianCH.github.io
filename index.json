[{"content":"","permalink":"https://XianCH.github.io/posts/tech/distributed/kafka/","summary":"","title":"Kafka"},{"content":"简述 以前在学习mysql的过程中 ，需要复习还有需要拓展的知识点\n连表 sql优化方案 mysql中用到的算法 mysql原理 database集群 ","permalink":"https://XianCH.github.io/posts/tech/database/mysql%E9%87%8D%E5%AE%A1/","summary":"简述 以前在学习mysql的过程中 ，需要复习还有需要拓展的知识点 连表 sql优化方案 mysql中用到的算法 mysql原理 database集群","title":"Mysql重审"},{"content":"docker部署 拉取镜像\ndocker pull nginx:latest 运行镜像\ndocker run --name nginx -p 80:80 -d nginx 创建挂载目录\nmkdir -p ~/Documents/dockerdata/nginx/conf / mkdir -p ~/Documents/dockerdata/nginx/conf.d / mkdir -p ~/Documents/dockerdata/nginx/html / mkdir -p ~/Documents/dockerdata/nginx/log / 拷贝容器里面的内容\ndocker cp nginx:/etc/nginx/nginx.conf ~/Documents/dockerdata/nginx/conf/nginx.conf / docker cp nginx:/etc/nginx/conf.d ~/Documents/dockerdata/nginx / docker cp nginx:/usr/share/nginx/html ~/Documents/dockerdata/nginx / 停止并关闭容器\ndocker rm -f nginx 重新启动容器\ndocker run --name nginx -p 80:80 --privileged --restart=always \\ -v ~/Documents/dockerdata/nginx/conf/nginx.conf:/etc/nginx/nginx.conf:rw \\ -v ~/Documents/dockerdata/nginx/conf.d:/etc/nginx/conf.d:rw \\ -v ~/Documents/dockerdata/nginx/html:/usr/share/nginx/html:rw \\ -v ~/Documents/dockerdata/nginx/log:/var/log/nginx \\ -d nginx Nginx 入门 常用命令\nnginx -s stop 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务。 nginx -s quit 平稳关闭Nginx，保存相关信息，有安排的结束web服务。 nginx -s reload 因改变了Nginx相关配置，需要重新加载配置而重载。 nginx -s reopen 重新打开日志文件。 nginx -c filename 为 Nginx 指定一个配置文件，来代替缺省的。 nginx -t 不运行，仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件中所引用到的文件。 nginx -v 显示 nginx 的版本。 nginx -V 显示 nginx 的版本，编译器版本和配置参数。 实战 http反向代理 介绍：\n反向代理（Reverse Proxy）方式是指以代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。\n不考虑复杂的配置，仅仅是完成一个 http 反向代理。\n#运行用户 #user somebody; #启动进程,通常设置成和cpu的数量相等 worker_processes 1; #全局错误日志 error_log /var/log/nginx/error.log; error_log /var/log/nginx/notice.log notice; error_log /var/log/nginx/info.log info; #PID文件，记录当前启动的nginx的进程ID #pid D:/Tools/nginx-1.10.1/logs/nginx.pid; #工作模式及连接数上限 events { worker_connections 1024; #单个后台worker process进程的最大并发链接数 } #设定http服务器，利用它的反向代理功能提供负载均衡支持 http { #设定mime类型(邮件支持类型),类型由mime.types文件定义 include include /etc/nginx/mime.types; default_type application/octet-stream; #设定日志 log_format main \u0026#39;[$remote_addr] - [$remote_user] [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; rewrite_log on; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用， #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 keepalive_timeout 120; tcp_nodelay on; #gzip压缩开关 #gzip on; #设定实际的服务器列表 upstream zp_server1{ server 127.0.0.1:8089; } #HTTP服务器 include /etc/nginx/config.d/default.conf } server { #监听80端口，80端口是知名端口号，用于HTTP协议 listen 80; #定义使用www.xx.com访问 server_name www.helloworld.com; #首页 index index.html #指向webapp的目录 root D:\\01_Workspace\\Project\\github\\zp\\SpringNotes\\spring-security\\spring-shiro\\src\\main\\webapp; #编码格式 charset utf-8; #代理配置参数 proxy_connect_timeout 180; proxy_send_timeout 180; proxy_read_timeout 180; proxy_set_header Host $host; proxy_set_header X-Forwarder-For $remote_addr; #反向代理的路径（和upstream绑定），location 后面设置映射的路径 location / { proxy_pass http://zp_server1; } #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ { root D:\\01_Workspace\\Project\\github\\zp\\SpringNotes\\spring-security\\spring-shiro\\src\\main\\webapp\\views; #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。 expires 30d; } #设定查看Nginx状态的地址 location /NginxStatus { stub_status on; access_log on; auth_basic \u0026#34;NginxStatus\u0026#34;; auth_basic_user_file conf/htpasswd; } #禁止访问 .htxxx 文件 location ~ /\\.ht { deny all; } #错误处理页面（可选择性配置） #error_page 404 /404.html; #error_page 500 502 503 504 /50x.html; #location = /50x.html { # root html; #} } Https 反向代理 一些对安全性要求比较高的站点，可能会使用 HTTPS（一种使用 ssl 通信标准的安全 HTTP 协议）。\n这里不科普 HTTP 协议和 SSL 标准。但是，使用 nginx 配置 https 需要知道几点：\nHTTPS 的固定端口号是 443，不同于 HTTP 的 80 端口 SSL 标准需要引入安全证书，所以在 nginx.conf 中你需要指定证书和它对应的 key 其他和 http 反向代理基本一样，只是在 Server 部分配置有些不同。\n#HTTP服务器 server { #监听443端口。443为知名端口号，主要用于HTTPS协议 listen 443 ssl; #定义使用www.xx.com访问 server_name www.helloworld.com; #ssl证书文件位置(常见证书文件格式为：crt/pem) ssl_certificate cert.pem; #ssl证书key位置 ssl_certificate_key cert.key; #ssl配置参数（选择性配置） ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; #数字签名，此处使用MD5 ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { root /root; index index.html index.htm; } } 负载均衡 给集群服务器进行分流\nhttp { #设定mime类型,类型由mime.type文件定义 include /etc/nginx/mime.types; default_type application/octet-stream; #设定日志格式 access_log /var/log/nginx/access.log; #设定负载均衡的服务器列表 upstream load_balance_server { #weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.1.11:80 weight=5; server 192.168.1.12:80 weight=1; server 192.168.1.13:80 weight=6; } #HTTP服务器 server { #侦听80端口 listen 80; #定义使用www.xx.com访问 server_name www.helloworld.com; #对所有请求进行负载均衡请求 location / { root /root; #定义服务器的默认网站根目录位置 index index.html index.htm; #定义首页索引文件的名称 proxy_pass http://load_balance_server ;#请求转向load_balance_server 定义的服务器列表 #以下是一些反向代理的配置(可选择性配置) #proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $remote_addr; proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数 } } } 负载均衡策略 轮询\nupstream bck_testing_01 { # 默认所有服务器权重为 1 server 192.168.250.220:8080 server 192.168.250.221:8080 server 192.168.250.222:8080 } 加权轮询\nupstream bck_testing_01 { server 192.168.250.220:8080 weight=3 server 192.168.250.221:8080 # default weight=1 server 192.168.250.222:8080 # default weight=1 } 最少连接 upstream bck_testing_01 { least_conn; # with default weight for all (weight=1) server 192.168.250.220:8080 server 192.168.250.221:8080 server 192.168.250.222:8080 } 加权最少连接 upstream bck_testing_01 { least_conn; server 192.168.250.220:8080 weight=3 server 192.168.250.221:8080 # default weight=1 server 192.168.250.222:8080 # default weight=1 } ip hash\nupstream bck_testing_01 { ip_hash; # with default weight for all (weight=1) server 192.168.250.220:8080 server 192.168.250.221:8080 server 192.168.250.222:8080 } 普通hash\nupstream bck_testing_01 { hash $request_uri; # with default weight for all (weight=1) server 192.168.250.220:8080 server 192.168.250.221:8080 server 192.168.250.222:8080 } 站点有多个webapp 比如说www.x14n.com这里有有三个服务:\nwww.x14n.com/admin (后台管理)\nwww.x14n.com/shop (主站)\nwww.x14n.com/xxxxx\n这里用反向代理来解决\nhttp { #此处省略一些基本配置 upstream shop_server{ server www.x14n.com:8081; } upstream admin_server{ server www.helloworld.com:8082; } upstream xxx_server{ server www.x14n.com:8083; } server { #此处省略一些基本配置 #默认指向product的server location / { proxy_pass http://shop_server; } location /shop/{ proxy_pass http://shop_server; } location /admin/ { proxy_pass http://admin_server; } location /xxx/ { proxy_pass http://xxx_server; } } } 静态站点 有时候，我们需要配置静态站点(即 html 文件和一堆静态资源)。\n举例来说：如果所有的静态资源都放在了 /app/dist 目录下，我们只需要在 nginx.conf 中指定首页以及这个站点的 host 即可。\n配置如下：\nworker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; gzip on; gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/javascript image/jpeg image/gif image/png; gzip_vary on; server { listen 80; server_name static.zp.cn; location / { root /app/dist; index index.html; #转发任何请求到 index.html } } } 然后，添加 HOST：\n127.0.0.1 static.zp.cn\n此时，在本地浏览器访问 static.zp.cn ，就可以访问静态站点了。\n搭建文件服务器 有时候，团队需要归档一些数据或资料，那么文件服务器必不可少。使用 Nginx 可以非常快速便捷的搭建一个简易的文件服务。\nNginx 中的配置要点：\n将 autoindex 开启可以显示目录，默认不开启。 将 autoindex_exact_size 开启可以显示文件的大小。 将 autoindex_localtime 开启可以显示文件的修改时间。 root 用来设置开放为文件服务的根路径。 charset 设置为 charset utf-8,gbk;，可以避免中文乱码问题（windows 服务器下设置后，依然乱码，本人暂时没有找到解决方法）。 一个最简化的配置如下：\nautoindex on;# 显示目录 autoindex_exact_size on;# 显示文件大小 autoindex_localtime on;# 显示文件时间 server { charset utf-8,gbk; # windows 服务器下设置后，依然乱码，暂时无解 listen 9050 default_server; listen [::]:9050 default_server; server_name _; root /share/fs; } 解决跨域问题 web 领域开发中，经常采用前后端分离模式。这种模式下，前端和后端分别是独立的 web 应用程序，例如：后端是 Java 程序，前端是 React 或 Vue 应用。\n各自独立的 web app 在互相访问时，势必存在跨域问题。解决跨域问题一般有两种思路：\nCORS 在后端服务器设置 HTTP 响应头，把你需要允许访问的域名加入 Access-Control-Allow-Origin 中。\njsonp 把后端根据请求，构造 json 数据，并返回，前端用 jsonp 跨域。\n这两种思路，本文不展开讨论。\n需要说明的是，nginx 根据第一种思路，也提供了一种解决跨域的解决方案。\n举例：www.helloworld.com 网站是由一个前端 app ，一个后端 app 组成的。前端端口号为 9000， 后端端口号为 8080。\n前端和后端如果使用 http 进行交互时，请求会被拒绝，因为存在跨域问题。来看看，nginx 是怎么解决的吧：\n首先，在 enable-cors.conf 文件中设置 cors ：\n# allow origin list set $ACAO \u0026#39;*\u0026#39;; # set single origin if ($http_origin ~* (www.helloworld.com)$) { set $ACAO $http_origin; } if ($cors = \u0026#34;trueget\u0026#34;) { add_header \u0026#39;Access-Control-Allow-Origin\u0026#39; \u0026#34;$http_origin\u0026#34;; add_header \u0026#39;Access-Control-Allow-Credentials\u0026#39; \u0026#39;true\u0026#39;; add_header \u0026#39;Access-Control-Allow-Methods\u0026#39; \u0026#39;GET, POST, OPTIONS\u0026#39;; add_header \u0026#39;Access-Control-Allow-Headers\u0026#39; \u0026#39;DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type\u0026#39;; } if ($request_method = \u0026#39;OPTIONS\u0026#39;) { set $cors \u0026#34;${cors}options\u0026#34;; } if ($request_method = \u0026#39;GET\u0026#39;) { set $cors \u0026#34;${cors}get\u0026#34;; } if ($request_method = \u0026#39;POST\u0026#39;) { set $cors \u0026#34;${cors}post\u0026#34;; } ​\n接下来，在你的服务器中 include enable-cors.conf 来引入跨域配置：\n# ---------------------------------------------------- # 此文件为项目 nginx 配置片段 # 可以直接在 nginx config 中 include（推荐） # 或者 copy 到现有 nginx 中，自行配置 # www.helloworld.com 域名需配合 dns hosts 进行配置 # 其中，api 开启了 cors，需配合本目录下另一份配置文件 # ---------------------------------------------------- upstream front_server{ server www.helloworld.com:9000; } upstream api_server{ server www.helloworld.com:8080; } server { listen 80; server_name www.helloworld.com; location ~ ^/api/ { include enable-cors.conf; proxy_pass http://api_server; rewrite \u0026#34;^/api/(.*)$\u0026#34; /$1 break; } location ~ ^/ { proxy_pass http://front_server; } } ​\n","permalink":"https://XianCH.github.io/posts/tech/distributed/nginx%E5%85%A5%E9%97%A8/","summary":"docker部署 拉取镜像 docker pull nginx:latest 运行镜像 docker run --name nginx -p 80:80 -d nginx 创建挂载目录 mkdir -p ~/Documents/dockerdata/nginx/conf / mkdir -p ~/Documents/dockerdata/nginx/conf.d / mkdir -p ~/Documents/dockerdata/nginx/html / mkdir -p ~/Documents/dockerdata/nginx/log / 拷贝容器里面的内容 docker cp nginx:/etc/nginx/nginx.conf ~/Documents/dockerdata/nginx/conf/nginx.conf / docker cp nginx:/etc/nginx/conf.d ~/Documents/dockerdata/nginx / docker cp nginx:/usr/share/nginx/html ~/Documents/dockerdata/nginx / 停止并关闭容器 docker rm -f nginx 重新启动容器 docker run --name nginx -p 80:80 --privileged --restart=always \\ -v ~/Documents/dockerdata/nginx/conf/nginx.conf:/etc/nginx/nginx.conf:rw \\ -v ~/Documents/dockerdata/nginx/conf.d:/etc/nginx/conf.d:rw \\ -v ~/Documents/dockerdata/nginx/html:/usr/share/nginx/html:rw \\ -v ~/Documents/dockerdata/nginx/log:/var/log/nginx \\ -d nginx Nginx 入门 常用命令 nginx -s stop 快速关闭Nginx，可能不保存相关","title":"Nginx"},{"content":" 杂谈 ​\t最近这段时间，总有一种奇怪的想法，感觉自己做了很多事情，但其实又什么都没做，就像我github上面的活动一样，感觉自己好像写了很多东西，相比过去那个写了就不管了得我来说，这不是挺好的的吗，又仔细看看，自己每天push的东西，真的是一坨屎，看看别人写的东西吧，又好多看不懂，看看自己的写的什么垃圾博客吧，真的不知道写的是什么。但是我又很需要这种感觉自己很忙的感觉，这是为什么呢，可能是因为我现在还没有工作（其实是找不到工作），又不想每天无所事事，毕竟我就是很喜欢带着耳机，对着电脑，在自己世界里的感觉，也可以说我4月份找工作的经历，让我真的害怕找工作了，现在想跨出哪一步真的受不了，外面那些很早就出去工作的同龄人，工作经验和能力不比我丰富吗？还没毕业在校的，不必我更有激情吗？在外面工作了很多年的程序员，就更不用说了吗？还有github上面的一众大神\u0026hellip;\u0026hellip;..\n​\t真的进了死循环吗，看着招聘上面的信息，上面需要掌握的技能，我就去学习，又在想，我不是什么聪明人，很多时候我真的不能完全掌握这知识。但是我又不想直接去面试，不想面试的时候感觉自己似懂非懂还要硬着头皮说自己了解，怎么说呢 , 想到这方面的，我又tm的焦虑了，真的受不了。\n还是要改变点什么:\n少抽烟，只是不能把他当成依赖吧 再专注一点 少点在网络上看那些没营养的了（至少不是在我学习的时候），在想不出写什么代码的时候，拿手机出来，看看无聊文章，看看没有营养的视屏，确实让我感觉有无意义的快乐，有一种逃避的快乐，手机点一下就能获得最直接的多巴胺。但是这根只没有思考能力的小白鼠又有何区别呢。我不想这样\u0026hellip;\u0026hellip;. ","permalink":"https://XianCH.github.io/posts/life/%E4%B8%80%E4%BA%9B%E6%83%B3%E6%B3%95/","summary":"杂谈 ​ 最近这段时间，总有一种奇怪的想法，感觉自己做了很多事情，但其实又什么都没做，就像我github上面的活动一样，感觉自己好像写了很多东西，相比过去那个写了就不管了得我来说，这不是挺好的的吗，又仔细看看，自己每天push的东西，真的是一坨屎，看看别人写的东西吧，又好多看不懂，看","title":"一些想法"},{"content":"","permalink":"https://XianCH.github.io/posts/tech/go/golang%E5%AE%9E%E7%8E%B0%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","summary":"","title":"Golang实现消息队列"},{"content":"gin 介绍 Gin is a web framework written in Go. It features a martini-like API with performance that is up to 40 times faster thanks to httprouter. If you need performance and good productivity, you will love Gin.\nThe key features of Gin are:\nZero allocation router Fast Middleware support Crash-free JSON validation Routes grouping Error management Rendering built-in Extendable Gin 与 net/http 的关系 gin是在 Golang HTTP 标准库 net/http 基础之上的再封装\nGin 框架使用示例 func main(){ mux := gin.Default() mux.Use(middleware) mux.Post(\u0026#34;/ping\u0026#34;,xxxhandler) if err :=mux.Run(\u0026#34;:8000\u0026#34;); err != nil { panic(err) } } func xxxhandler(c *gin.context){ c.Json(http.StatusOK,\u0026#34;pong\u0026#34;) } 简易解释（后面会详细解释）：\ngin.Default()返回默认的gin Engine\nUse()函数，添加中间件\nmux.Post()创建一个post\u0026quot;/ping\u0026quot;的路由，路由到xxxhandler方法\n.Run()运行http服务\n用net/http\nfunc main() { http.HandleFunc(\u0026#34;/ping\u0026#34;, func(w http.ResponseWriter, r *http.Request) { if r.Method == http.MethodPost { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) w.WriteHeader(http.StatusOK) w.Write([]byte(`{\u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;}`)) } else { http.Error(w, \u0026#34;Method Not Allowed\u0026#34;, http.StatusMethodNotAllowed) } }) if err := http.ListenAndServe(\u0026#34;:8000\u0026#34;, nil); err != nil { panic(err) } } gin 基础概念 路由 中间件 请求和响应对象 参数解析 静态文件处理 创建第一个Gin应用 创建一个简单的Hello World应用 定义路由 处理HTTP请求 返回JSON响应 路由与控制器\n路由的定义与使用 参数传递和路由参数 控制器的创建与使用 中间件\n什么是中间件 内置中间件（Logger、Recovery） 自定义中间件 请求与响应处理\n获取请求数据（GET、POST、Query参数） 发送响应数据（JSON、HTML、文件） 错误处理与状态码 数据库集成\n连接数据库 ORM（如果使用） CRUD操作 身份验证与授权\n用户认证 基于角色的授权 JSON Web Tokens (JWT)的使用 性能优化\nGolang和Gin的性能特点 常见性能问题与优化策略 部署与维护\n部署Gin应用 日志管理 安全性考虑 最佳实践\n代码结构组织 测试方法 文档编写 进阶主题\nWebSocket支持 服务器推送（Server-Sent Events） 使用第三方库 ","permalink":"https://XianCH.github.io/posts/tech/go/gin%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/","summary":"gin 介绍 Gin is a web framework written in Go. It features a martini-like API with performance that is up to 40 times faster thanks to httprouter. If you need performance and good productivity, you will love Gin. The key features of Gin are: Zero allocation router Fast Middleware support Crash-free JSON validation Routes grouping Error management Rendering built-in Extendable Gin 与 net/http 的关系 gin是在 Golang HTTP 标准库 net/http 基础之上的再封装 Gin 框架使用示例 func main(){ mux := gin.Default() mux.Use(middleware) mux.Post(\u0026#34;/ping\u0026#34;,xxxhandler) if err :=mux.Run(\u0026#34;:8000\u0026#34;); err != nil { panic(err) } } func xxxhandler(c *gin.context){ c.Json(http.StatusOK,\u0026#34;pong\u0026#34;) } 简易解释（后面会详细解释）： gin.Default","title":"Gin框架学习"},{"content":"WebSocket简介 服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。\n（1）建立在 TCP 协议之上，服务器端的实现比较容易。\n（2）与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。\n（3）数据格式比较轻量，性能开销小，通信高效。\n（4）可以发送文本，也可以发送二进制数据。\n（5）没有同源限制，客户端可以与任意服务器通信。\n（6）协议标识符是ws（如果加密，则为wss），服务器网址就是 URL。\n请求示例 客户端:\nGET /chat HTTP/1.1 Host: server.example.com Upgrade: websocket Connection: Upgrade Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw== Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 Origin: http://example.com 服务端：\nHTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk= Sec-WebSocket-Protocol: chat 观察报文中的参数websocket像是http的升级，但是准确来说他不是建立在http之上的，只是通过http握手之后进行服务的升级\n建立连接的步骤建立\n客户端发起WebSocket连接：客户端通过HTTP协议向服务器发起WebSocket连接请求。这是一个普通的HTTP GET请求，但包含特定的WebSocket头信息，例如升级协议（Upgrade）为\u0026quot;websocket\u0026quot;、连接方式（Connection）为\u0026quot;Upgrade\u0026quot;，以及一个随机生成的Sec-WebSocket-Key头部。客户端还可以附加其他WebSocket特定的头部信息。 服务器接受WebSocket连接请求：服务器接收客户端的HTTP连接请求，并检查头部信息以确保其包含了WebSocket相关的信息。如果一切正常，服务器将向客户端发送HTTP 101切换协议（HTTP 101 Switching Protocols）响应，表示接受了WebSocket连接。 WebSocket握手：在接受WebSocket连接后，服务器和客户端进行握手。服务器会计算客户端发送的Sec-WebSocket-Key的哈希值，并与一个固定的GUID（\u0026ldquo;258EAFA5-E914-47DA-95CA-C5AB0DC85B11\u0026rdquo;）一起计算SHA-1哈希值，然后将结果转换为Base64编码。这个Base64编码的值将作为响应头部Sec-WebSocket-Accept返回给客户端，以证明WebSocket连接已成功建立。 WebSocket连接建立：一旦客户端收到HTTP 101切换协议响应，并验证Sec-WebSocket-Accept头部，连接被视为成功建立。此时，WebSocket连接可以用于双向通信。 传输数据帧 握手成功完成后，您的应用程序可以从客户端读取数据或向客户端写入数据。WebSocket 规范定义了的一个客户机和服务器之间使用的特定帧格式。这是框架的位模式：\nhttp和websocket 共同点\n都是基于tcp协议的，所以都是可靠传 都在应用层 不同\nwebsocket是双向通讯的协议，模拟socket协议，可以双向发送和接受信息，而http是单向的 都需要握手建立连接，但是http每次都需要进行握手，而websocket在握手之后再发送数据无需进行握手， websocket没有header websocket 握手过程 浏览器和服务端建立tcp三次握手，这是通讯的基础，传输控制层，若失败了就不继续了 tcp握手完成后，浏览器通过http协议向服务端发送websocket支持的版本号等信息（开始前的http握手） 服务器收到客户端的握手请求后，同样采用http协议回馈数据。 当收到了连接成功的信息后，通过tcp通道进行传输通讯 在GO语言使用websocket 要基于 Go 语言内置的 net/http 库编写 WebSocket 服务器，你需要：\n发起握手 从客户端接收数据帧 发送数据帧给客户端 关闭握手 建立发起握手 首先，让我们创建一个带有 WebSocket 端点的 HTTP 处理程序：\n// HTTP server with WebSocket endpoint func Server() { http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { ws, err := NewHandler(w, r) if err != nil { // handle error } if err = ws.Handshake(); err != nil { // handle error } … 然后初始化 WebSocket 结构。\n初始握手请求始终来自客户端。服务器确定了 WebSocket 请求后，需要使用握手响应进行回复。\n请记住，你无法使用 http.ResponseWriter 编写响应，因为一旦开始发送响应，它将关闭其基础的 TCP 连接（这是 HTTP 协议的运行机制决定的，发送响应后即关闭连接）。\n因此，您需要使用 HTTP 劫持 (hijack)。通过劫持，可以接管基础的 TCP 连接处理程序和 bufio.Writer。这使可以在不关闭 TCP 连接的情况下读取和写入数据。\n// NewHandler initializes a new handler func NewHandler(w http.ResponseWriter, req *http.Request) (*WS, error) { hj, ok := w.(http.Hijacker) if !ok { // handle error } ..... } 要完成握手，服务器必须使用适当的头进行响应。\n// Handshake creates a handshake header func (ws *WS) Handshake() error { hash := func(key string) string { h := sha1.New() h.Write([]byte(key)) h.Write([]byte(\u0026#34;258EAFA5-E914-47DA-95CA-C5AB0DC85B11\u0026#34;)) return base64.StdEncoding.EncodeToString(h.Sum(nil)) }(ws.header.Get(\u0026#34;Sec-WebSocket-Key\u0026#34;)) ..... } 客户端发起 WebSocket 连接请求时用的 Sec-WebSocket-key 是随机生成的，并且是 Base64 编码的。接受请求后，服务器需要将此密钥附加到固定字符串。假设秘钥是 x3JJHMbDL1EzLkh9GBhXDw==。在这个例子中，可以使用 SHA-1 计算二进制值，并使用 Base64 对其进行编码。得到 HSmrc0sMlYUkAGmm5OPpG2HaGWk=。然后使用它作为 Sec-WebSocket-Accept 响应头的值。\n使用第三方库快速构建 WebSocket 服务 ","permalink":"https://XianCH.github.io/posts/tech/go/websocket%E5%AD%A6%E4%B9%A0/","summary":"WebSocket简介 服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。 （1）建立在 TCP 协议之上，服务器端的实现比较容易。 （2）与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容","title":"Websocket学习"},{"content":"os os 包是 Go 语言标准库的一部分，主要用于与操作系统进行交互，提供了访问操作系统底层功能的功能。下面是关于 os 包的一些重要功能和用法：\n文件和目录操作： os.Create：创建文件。 os.Open：打开文件。 os.OpenFile：以指定模式打开文件。 os.Remove：删除文件或目录。 os.Rename：重命名文件或目录。 os.Mkdir：创建目录。 os.MkdirAll：递归创建目录。 os.Chdir：改变工作目录。 os.Getwd：获取当前工作目录。 os.Stat：获取文件或目录的信息。 文件描述符： os.Stdin、os.Stdout、os.Stderr：标准输入、标准输出和标准错误的文件描述符。 os.File：表示文件的结构，包括文件描述符、文件名等信息。 环境变量： os.Getenv：获取环境变量的值。 os.Setenv：设置环境变量的值。 os.Unsetenv：删除环境变量。 进程控制： os.Args：命令行参数。 os.Getpid：获取当前进程的 PID。 os.Getppid：获取父进程的 PID。 os.Exit：退出当前进程。 信号处理： os.Signal：表示操作系统信号的类型。 os.Notify：用于接收指定的操作系统信号。 用户和组信息： os.User：表示用户的结构。 os.LookupEnv：根据环境变量名查找环境变量值。 os.Hostname：获取主机名。 权限和文件信息： os.Chmod：改变文件或目录的权限。 os.Chtimes：改变文件或目录的访问和修改时间。 os.Symlink：创建符号链接。 os.Readlink：读取符号链接目标路径。 os.Lstat：获取符号链接信息，而不是目标文件信息。 文件路径操作： os.PathSeparator：表示文件路径中的路径分隔符。 os.Join：连接路径元素以创建有效的文件路径。 os.Split：分割文件路径为目录和文件名。 os.IsExist：判断错误是否表示文件已存在。 os.IsNotExist：判断错误是否表示文件不存在。 执行外部命令： os.Exec：执行外部命令并获取其输出。 os.StartProcess：以指定的属性启动新进程。 文件锁： os.FileLock：文件锁结构，用于文件的读写锁定。 平台相关功能： os.Environ：获取当前进程的所有环境变量。 os.Hostname：获取主机名。 io io 包是 Go 语言标准库中的一个核心包，提供了对输入和输出操作的抽象和通用接口。这个包包含了许多接口和类型，用于处理文件、网络连接、内存缓冲、压缩、解压缩等 I/O 相关的操作。以下是一些 io 包的重要接口和类型：\nReader 接口：\nReader 接口定义了读取数据的方法，允许实现该接口的类型从不同的数据源读取数据。\nRead(p []byte) (n int, err error)：从数据源读取数据并将其存储到 p 中，返回读取的字节数和可能的错误。 标准库中的一些类型实现了 Reader 接口，例如 os.File、strings.Reader 等。\nWriter 接口：\nWriter 接口定义了写入数据的方法，允许实现该接口的类型将数据写入不同的目标。\nWrite(p []byte) (n int, err error)：将 p 中的数据写入目标，返回写入的字节数和可能的错误。 标准库中的一些类型实现了 Writer 接口，例如 os.File、bytes.Buffer 等。\nCloser 接口：\nCloser 接口定义了关闭资源的方法，通常用于释放资源，如文件句柄、网络连接等。\nClose() error：关闭资源并返回可能的错误。 例如，os.File 实现了 Closer 接口，可以用来关闭文件。\nSeeker 接口：\nSeeker 接口定义了在数据源中定位的方法，通常用于随机访问文件或其他数据源。\nSeek(offset int64, whence int) (int64, error)：根据 whence 指定的方式定位到 offset 处，返回新的偏移量和可能的错误。 例如，os.File 实现了 Seeker 接口，可以用来在文件中定位。\nReadWriter 接口：\nReadWriter 接口组合了 Reader 和 Writer 接口，表示同时支持读和写操作的对象。\nReadCloser 和 WriteCloser 接口：\n这些接口组合了 Reader 或 Writer 接口和 Closer 接口，表示同时支持读或写和关闭的对象。\nMultiReader 和 MultiWriter：\n这些类型实现了多个 Reader 或 Writer 的复合操作，允许多个数据源进行串联。\nio.Copy 函数：\nio.Copy 函数用于将数据从一个 Reader 复制到一个 Writer 中，通常用于文件复制、网络传输等操作。\nio/ioutil 包：\nio/ioutil 包提供了一些便捷的函数，用于简化文件读写、临时文件创建等操作。例如，ioutil.ReadFile 用于读取整个文件到内存中，ioutil.WriteFile 用于将数据写入文件。\nio.Pipe 类型：\nio.Pipe 类型用于在不同的 goroutine 之间创建一个管道，允许一个 goroutine 写入数据，另一个 goroutine 读取数据。\nio.Reader 和 io.Writer 的适配器：\nio 包还提供了许多适配器类型，用于将其他类型（例如字符串、字节数组）转换为 Reader 或 Writer 接口，以便进行 I/O 操作\n","permalink":"https://XianCH.github.io/posts/tech/go/go%E5%9F%BA%E7%A1%80%E6%A0%87%E5%87%86%E5%BA%93/","summary":"os os 包是 Go 语言标准库的一部分，主要用于与操作系统进行交互，提供了访问操作系统底层功能的功能。下面是关于 os 包的一些重要功能和用法： 文件和目录操作： os.Create：创建文件。 os.Open：打开文件。 os.OpenFile：以指定模式打开文件。 os.Remove：删除文件或目录。","title":"Go基础标准库"},{"content":"","permalink":"https://XianCH.github.io/posts/tech/go/go%E6%93%8D%E4%BD%9Credis/","summary":"","title":"Go操作redis"},{"content":"基础数据类型及运用场景 String 常用命令 普通字符串的基本操作：\n# 设置 key-value 类型的值 \u0026gt; SET name lin OK # 根据 key 获得对应的 value \u0026gt; GET name \u0026#34;lin\u0026#34; # 判断某个 key 是否存在 \u0026gt; EXISTS name (integer) 1 # 返回 key 所储存的字符串值的长度 \u0026gt; STRLEN name (integer) 3 # 删除某个 key 对应的值 \u0026gt; DEL name (integer) 1 批量设置 :\n# 批量设置 key-value 类型的值 \u0026gt; MSET key1 value1 key2 value2 OK # 批量获取多个 key 对应的 value \u0026gt; MGET key1 key2 1) \u0026#34;value1\u0026#34; 2) \u0026#34;value2\u0026#34; 计数器（字符串的内容为整数的时候可以使用）：\n# 设置 key-value 类型的值 \u0026gt; SET number 0 OK # 将 key 中储存的数字值增一 \u0026gt; INCR number (integer) 1 # 将key中存储的数字值加 10 \u0026gt; INCRBY number 10 (integer) 11 # 将 key 中储存的数字值减一 \u0026gt; DECR number (integer) 10 # 将key中存储的数字值键 10 \u0026gt; DECRBY number 10 (integer) 0 过期（默认为永不过期）：\n# 设置 key 在 60 秒后过期（该方法是针对已经存在的key设置过期时间） \u0026gt; EXPIRE name 60 (integer) 1 # 查看数据还有多久过期 \u0026gt; TTL name (integer) 51 #设置 key-value 类型的值，并设置该key的过期时间为 60 秒 \u0026gt; SET key value EX 60 OK \u0026gt; SETEX key 60 value OK 不存在就插入：\n# 不存在就插入（not exists） \u0026gt;SETNX key value (integer) 1 应用场景 缓存对象 使用 String 来缓存对象有两种方式：\n直接缓存整个对象的 JSON，命令例子： SET user:1 '{\u0026quot;name\u0026quot;:\u0026quot;xiaolin\u0026quot;, \u0026quot;age\u0026quot;:18}'。 采用将 key 进行分离为 user:ID:属性，采用 MSET 存储，用 MGET 获取各属性值，命令例子： MSET user:1:name xiaolin user:1:age 18 user:2:name xiaomei user:2:age 20。 常规计数 阅读量计数：\n# 初始化文章的阅读量 \u0026gt; SET aritcle:readcount:1001 0 OK #阅读量+1 \u0026gt; INCR aritcle:readcount:1001 (integer) 1 #阅读量+1 \u0026gt; INCR aritcle:readcount:1001 (integer) 2 #阅读量+1 \u0026gt; INCR aritcle:readcount:1001 (integer) 3 # 获取对应文章的阅读量 \u0026gt; GET aritcle:readcount:1001 \u0026#34;3\u0026#34; 分布式锁：\nSET 命令中有个NX参数 ，当key不存在的时候才插入根据这个功能\nnx 如key不存在的话，则插入，可以表示成加锁成功 nx如果key存在的话，则插入失败，可以表示加锁失败 SET lock_key unique_value NX PX 10000 #px 表示过期时间，为了防止死锁 存储用户登录信息：\n如果是单一系统，用户信息或者说session则key存储在服务器中，但是如果是分布式系统，用户的登录信息或者其他登录或者更新的其他用户信息，如果只存在A服务器中，B服务器没有共享这些信息，则会出现要求用户再次登录。这时候如何将这些相信息存储在redis中，服务器A 和服务器B 都到redis中获取信息就解决了相关问题。\nList 介绍 ​\tlist是简单的字符串列表，根据插入顺序排序，可以从头部和尾部插入数据，列表最大长度是2^32 - 1\n内部实现 在但是在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表\nquicklist(待补充\u0026hellip;.)\nquicklistNode\ntypedef struct quicklistNode { struct quicklistNode *prev; //前一个quicklistNode struct quicklistNode *next; //后一个quicklistNode unsigned char *zl; //quicklistNode指向的ziplist unsigned int sz; //ziplist的字节大小 unsigned int count : 16; //ziplist中的元素个数 unsigned int encoding : 2; //编码格式，原生字节数组或压缩存储 unsigned int container : 2; //存储方式 unsigned int recompress : 1; //数据是否被压缩 unsigned int attempted_compress : 1; //数据能否被压缩 unsigned int extra : 10; //预留的bit位 } quicklistNode; typedef struct quicklist { quicklistNode *head; // quicklist的链表头 quicklistNode *tail; // quicklist的链表尾 unsigned long count; // 所有ziplist中的总元素个数 unsigned long len; // quicklistNodes的个数 int fill : QL_FILL_BITS; // 单独解释 unsigned int compress : QL_COMP_BITS; // 具体含义是两端各有compress个节点不压缩 ... } quicklist; 常用命令 # 将一个或多个值value插入到key列表的表头(最左边)，最后的值在最前面 LPUSH key value [value ...] # 将一个或多个值value插入到key列表的表尾(最右边) RPUSH key value [value ...] # 移除并返回key列表的头元素 LPOP key # 移除并返回key列表的尾元素 RPOP key # 返回列表key中指定区间内的元素，区间以偏移量start和stop指定，从0开始 LRANGE key start stop # 从key列表表头弹出一个元素，没有就阻塞timeout秒，如果timeout=0则一直阻塞 BLPOP key [key ...] timeout # 从key列表表尾弹出一个元素，没有就阻塞timeout秒，如果timeout=0则一直阻塞 BRPOP key [key ...] timeout 应用场景 消息队列\nredis中的List是先进先出的，满足使用场景。\nproducer通过LPUSH key value [value\u0026hellip;]向List集合中存放消息 consumer通过 RPOP key 从集合中获取消息 如何producer没有生成消息，消息集合中也没有数据，而consumer还是一直读取消息，会造成cpu不必要的cpu占用，这时候consumer可以用BRPOP(blocking right pop )，BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据\n如何处理重复的消息？\n消费者要实现重复消息的判断，需要 2 个方面的要求：\n每个消息都有一个全局的 ID。 消费者要记录已经处理过的消息的 ID 因为list不会生成id，所以我们要自行生成id\n我们执行以下命令，就把一条全局 ID 为 111000102、库存量为 99 的消息插入了消息队列：\n\u0026gt; LPUSH mq \u0026#34;111000102:stock:99\u0026#34; (integer) 1 List 作为消息队列有什么缺陷？\nList 不支持多个消费者消费同一条消息，因为一旦消费者拉取一条消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费。\n要实现一条消息可以被多个消费者消费，那么就要将多个消费者组成一个消费组，使得多个消费者可以消费同一条消息，但是 List 类型并不支持消费组的实现。\nhash 介绍 hash是键值对集合(key-value) eg: value[{fields:,value},\u0026hellip;.]\nstring和hash对比，hash更适合用来存储对象\n内部实现 Hash类型是通过压缩列表和哈希表实现的在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。\n如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用压缩列表作为 Hash 类型的底层数据结构； 如果哈希类型元素不满足上面条件，Redis 会使用哈希表作为 Hash 类型的 底层数据结构。 常用命令 # 存储一个哈希表key的键值 HSET key field value # 获取哈希表key对应的field键值 HGET key field # 在一个哈希表key中存储多个键值对 HMSET key field value [field value...] # 批量获取哈希表key中多个field键值 HMGET key field [field ...] # 删除哈希表key中的field键值 HDEL key field [field ...] # 返回哈希表key中field的数量 HLEN key # 返回哈希表key中所有的键值 HGETALL key # 为哈希表key中field键的值加上增量n HINCRBY key field n 应用场景 购物车\nfield(商品id) 数量(value) 增加数量（HINCRBY） key(用户id) 购物车数量(hlen) 全选(hgetall) 用户id [{商品id，数量}\u0026hellip;.,{商品id,数量} ]\nset zset ","permalink":"https://XianCH.github.io/posts/tech/database/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","summary":"基础数据类型及运用场景 String 常用命令 普通字符串的基本操作： # 设置 key-value 类型的值 \u0026gt; SET name lin OK # 根据 key 获得对应的 value \u0026gt; GET name \u0026#34;lin\u0026#34; # 判断某个 key 是否存在 \u0026gt; EXISTS name (integer) 1 # 返回 key 所储存的字符串值的长度 \u0026gt; STRLEN name (integer) 3 # 删除某个 key 对应的值 \u0026gt; DEL name (integer) 1 批量设置 : # 批量设置 key-value 类型的值 \u0026gt; MSET key1 value1 key2 value2 OK # 批量获取多个 key 对应的 value \u0026gt; MGET","title":"Redis基础知识回顾(更新中)"},{"content":"docker常用命令 容器 进入容器 docker exec -it contaionName /bin/bash 查看容器日志 docker logs -f contaionName # 停止运行的容器 docker stop [容器ID] # 杀死容器进程 docker kill [容器ID] 镜像 导出镜像\ndocker save 导入镜像\ndocker load docker安装相关软件 redis 运行容器\ndocker run -itd --name redis-test -p 6379:6379 redis docker run --restart=always --log-opt max-size=100m --log-opt max-file=2 -p 6379:6379 --name myredis -v /home/redis/myredis/myredis.conf:/etc/redis/redis.conf -v /home/redis/myredis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes --requirepass 000415 参数说明\n--restart=always 总是开机启动 --log是日志方面的 -p 6379:6379 将6379端口挂载出去 --name 给这个容器取一个名字 -v 数据卷挂载 –appendonly yes 开启redis 持久化 –requirepass 000415 设置密码 （ nacos 下载镜像\ndocker pull nacos/nacos-server:2.0.3 挂载目录\nmkdir -p /usr/local/docker/nacos/conf mkdir -p /usr/local/docker/nacos/data mkdir -p /usr/local/docker/nacos/logs chmod a+w /usr/local/docker/nacos 在/usr/local/docker/nacos/conf目录下新建application.properties文件\n在`/usr/local/docker/nacos/conf`目录下新建`application.properties`文件 server.servlet.contextPath=/nacos server.port=8848 spring.datasource.platform=mysql ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://192.168.164.101:3306/nacos?characterEncoding=utf8\u0026amp;connectTimeout=1000\u0026amp;socketTimeout=3000\u0026amp;autoReconnect=true\u0026amp;useUnicode=true\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC db.user.0=root db.password.0=root ### Connection pool configuration: hikariCP db.pool.config.connectionTimeout=30000 db.pool.config.validationTimeout=10000 db.pool.config.maximumPoolSize=20 db.pool.config.minimumIdle=2 nacos.naming.empty-service.auto-clean=true nacos.naming.empty-service.clean.initial-delay-ms=50000 nacos.naming.empty-service.clean.period-time-ms=30000 server.tomcat.accesslog.enabled=true ### The access log pattern: server.tomcat.accesslog.pattern=%h %l %u %t \u0026#34;%r\u0026#34; %s %b %D %{User-Agent}i %{Request-Source}i nacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-ui/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/** ### The auth system to use, currently only \u0026#39;nacos\u0026#39; and \u0026#39;ldap\u0026#39; is supported: nacos.core.auth.system.type=nacos ### If turn on auth system: nacos.core.auth.enabled=false ### The token expiration in seconds: nacos.core.auth.default.token.expire.seconds=18000 ### The default token: nacos.core.auth.default.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789 nacos.core.auth.caching.enabled=true nacos.core.auth.enable.userAgentAuthWhite=false nacos.core.auth.server.identity.key=serverIdentity nacos.core.auth.server.identity.value=security nacos.istio.mcp.server.enabled=false 初始化nacos数据库nacos.sql\n放到conf目录下\n/* * Copyright 1999-2018 Alibaba Group Holding Ltd. * * Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info */ /******************************************/ CREATE TABLE `config_info` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(255) DEFAULT NULL, `content` longtext NOT NULL COMMENT \u0026#39;content\u0026#39;, `md5` varchar(32) DEFAULT NULL COMMENT \u0026#39;md5\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;修改时间\u0026#39;, `src_user` text COMMENT \u0026#39;source user\u0026#39;, `src_ip` varchar(50) DEFAULT NULL COMMENT \u0026#39;source ip\u0026#39;, `app_name` varchar(128) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;租户字段\u0026#39;, `c_desc` varchar(256) DEFAULT NULL, `c_use` varchar(64) DEFAULT NULL, `effect` varchar(64) DEFAULT NULL, `type` varchar(64) DEFAULT NULL, `c_schema` text, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;config_info\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_aggr */ /******************************************/ CREATE TABLE `config_info_aggr` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(255) NOT NULL COMMENT \u0026#39;group_id\u0026#39;, `datum_id` varchar(255) NOT NULL COMMENT \u0026#39;datum_id\u0026#39;, `content` longtext NOT NULL COMMENT \u0026#39;内容\u0026#39;, `gmt_modified` datetime NOT NULL COMMENT \u0026#39;修改时间\u0026#39;, `app_name` varchar(128) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;租户字段\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfoaggr_datagrouptenantdatum` (`data_id`,`group_id`,`tenant_id`,`datum_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;增加租户字段\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_beta */ /******************************************/ CREATE TABLE `config_info_beta` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(128) NOT NULL COMMENT \u0026#39;group_id\u0026#39;, `app_name` varchar(128) DEFAULT NULL COMMENT \u0026#39;app_name\u0026#39;, `content` longtext NOT NULL COMMENT \u0026#39;content\u0026#39;, `beta_ips` varchar(1024) DEFAULT NULL COMMENT \u0026#39;betaIps\u0026#39;, `md5` varchar(32) DEFAULT NULL COMMENT \u0026#39;md5\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;修改时间\u0026#39;, `src_user` text COMMENT \u0026#39;source user\u0026#39;, `src_ip` varchar(50) DEFAULT NULL COMMENT \u0026#39;source ip\u0026#39;, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;租户字段\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfobeta_datagrouptenant` (`data_id`,`group_id`,`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;config_info_beta\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_tag */ /******************************************/ CREATE TABLE `config_info_tag` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(128) NOT NULL COMMENT \u0026#39;group_id\u0026#39;, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;tenant_id\u0026#39;, `tag_id` varchar(128) NOT NULL COMMENT \u0026#39;tag_id\u0026#39;, `app_name` varchar(128) DEFAULT NULL COMMENT \u0026#39;app_name\u0026#39;, `content` longtext NOT NULL COMMENT \u0026#39;content\u0026#39;, `md5` varchar(32) DEFAULT NULL COMMENT \u0026#39;md5\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;修改时间\u0026#39;, `src_user` text COMMENT \u0026#39;source user\u0026#39;, `src_ip` varchar(50) DEFAULT NULL COMMENT \u0026#39;source ip\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfotag_datagrouptenanttag` (`data_id`,`group_id`,`tenant_id`,`tag_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;config_info_tag\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_tags_relation */ /******************************************/ CREATE TABLE `config_tags_relation` ( `id` bigint(20) NOT NULL COMMENT \u0026#39;id\u0026#39;, `tag_name` varchar(128) NOT NULL COMMENT \u0026#39;tag_name\u0026#39;, `tag_type` varchar(64) DEFAULT NULL COMMENT \u0026#39;tag_type\u0026#39;, `data_id` varchar(255) NOT NULL COMMENT \u0026#39;data_id\u0026#39;, `group_id` varchar(128) NOT NULL COMMENT \u0026#39;group_id\u0026#39;, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;tenant_id\u0026#39;, `nid` bigint(20) NOT NULL AUTO_INCREMENT, PRIMARY KEY (`nid`), UNIQUE KEY `uk_configtagrelation_configidtag` (`id`,`tag_name`,`tag_type`), KEY `idx_tenant_id` (`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;config_tag_relation\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = group_capacity */ /******************************************/ CREATE TABLE `group_capacity` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键ID\u0026#39;, `group_id` varchar(128) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;Group ID，空字符表示整个集群\u0026#39;, `quota` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;配额，0表示使用默认值\u0026#39;, `usage` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;使用量\u0026#39;, `max_size` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;单个配置大小上限，单位为字节，0表示使用默认值\u0026#39;, `max_aggr_count` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;聚合子配置最大个数，，0表示使用默认值\u0026#39;, `max_aggr_size` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值\u0026#39;, `max_history_count` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;最大变更历史数量\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;修改时间\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_group_id` (`group_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;集群、各Group容量信息表\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = his_config_info */ /******************************************/ CREATE TABLE `his_config_info` ( `id` bigint(64) unsigned NOT NULL, `nid` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `data_id` varchar(255) NOT NULL, `group_id` varchar(128) NOT NULL, `app_name` varchar(128) DEFAULT NULL COMMENT \u0026#39;app_name\u0026#39;, `content` longtext NOT NULL, `md5` varchar(32) DEFAULT NULL, `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP, `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP, `src_user` text, `src_ip` varchar(50) DEFAULT NULL, `op_type` char(10) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;租户字段\u0026#39;, PRIMARY KEY (`nid`), KEY `idx_gmt_create` (`gmt_create`), KEY `idx_gmt_modified` (`gmt_modified`), KEY `idx_did` (`data_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;多租户改造\u0026#39;; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = tenant_capacity */ /******************************************/ CREATE TABLE `tenant_capacity` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键ID\u0026#39;, `tenant_id` varchar(128) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;Tenant ID\u0026#39;, `quota` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;配额，0表示使用默认值\u0026#39;, `usage` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;使用量\u0026#39;, `max_size` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;单个配置大小上限，单位为字节，0表示使用默认值\u0026#39;, `max_aggr_count` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;聚合子配置最大个数\u0026#39;, `max_aggr_size` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值\u0026#39;, `max_history_count` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;最大变更历史数量\u0026#39;, `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;修改时间\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_id` (`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;租户容量信息表\u0026#39;; CREATE TABLE `tenant_info` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `kp` varchar(128) NOT NULL COMMENT \u0026#39;kp\u0026#39;, `tenant_id` varchar(128) default \u0026#39;\u0026#39; COMMENT \u0026#39;tenant_id\u0026#39;, `tenant_name` varchar(128) default \u0026#39;\u0026#39; COMMENT \u0026#39;tenant_name\u0026#39;, `tenant_desc` varchar(256) DEFAULT NULL COMMENT \u0026#39;tenant_desc\u0026#39;, `create_source` varchar(32) DEFAULT NULL COMMENT \u0026#39;create_source\u0026#39;, `gmt_create` bigint(20) NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `gmt_modified` bigint(20) NOT NULL COMMENT \u0026#39;修改时间\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_info_kptenantid` (`kp`,`tenant_id`), KEY `idx_tenant_id` (`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\u0026#39;tenant_info\u0026#39;; CREATE TABLE `users` ( `username` varchar(50) NOT NULL PRIMARY KEY, `password` varchar(500) NOT NULL, `enabled` boolean NOT NULL ); CREATE TABLE `roles` ( `username` varchar(50) NOT NULL, `role` varchar(50) NOT NULL, UNIQUE INDEX `idx_user_role` (`username` ASC, `role` ASC) USING BTREE ); CREATE TABLE `permissions` ( `role` varchar(50) NOT NULL, `resource` varchar(255) NOT NULL, `action` varchar(8) NOT NULL, UNIQUE INDEX `uk_role_permission` (`role`,`resource`,`action`) USING BTREE ); INSERT INTO users (username, password, enabled) VALUES (\u0026#39;nacos\u0026#39;, \u0026#39;$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu\u0026#39;, TRUE); INSERT INTO roles (username, role) VALUES (\u0026#39;nacos\u0026#39;, \u0026#39;ROLE_ADMIN\u0026#39;); 运行\ndocker run -it --name nacos \\ -p 8848:8848 \\ -e MODE=standalone \\ -v /usr/local/docker/nacos/conf/application.properties:/home/nacos/conf/application.properties \\ -v /usr/local/docker/nacos/conf/data:/home/nacos/conf/data \\ -v /usr/local/docker/nacos/conf/logs:/home/nacos/conf/logs \\ -d nacos/nacos-server:2.0.3 mysql docker run -d --name=mysql-server -p 3306:3306 -v mysql-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=your_password mysql docker run -d --name=mysql-server -p 3306:3306 -e MYSQL_ROOT_PASSWORD=your_password mysql nginx Nginx 配置文件：你通常会想要自定义 Nginx 的配置。你可以将自定义的 Nginx 配置文件挂载到容器内，以覆盖默认配置。你可以使用 -v 标志来挂载主机上的配置文件到容器内，就像上面的示例所示。这样，你可以在主机上编辑配置文件，然后容器将使用你的自定义配置。\ndocker run -d -p 80:80 -v /host/path/nginx.conf:/etc/nginx/nginx.conf:ro nginx 网站内容：如果你要提供静态网页或其他文件，你可以将这些文件挂载到容器内的 Nginx 根目录中。这通常发生在挂载一个目录，其中包含你的网站文件。\ndocker run -d -p 80:80 -v /host/path/html:/usr/share/nginx/html nginx SSL 证书：如果你使用 HTTPS，你需要提供 SSL 证书和密钥。你可以将 SSL 证书挂载到容器内的适当位置，以便 Nginx 可以使用它们。\ndocker run -d -p 443:443 -v /host/path/certs:/etc/nginx/certs nginx 日志文件：如果你想在主机上保存 Nginx 的访问日志和错误日志，你可以挂载一个目录以便容器可以将日志文件写入该目录。\ndocker run -d -p 80:80 -v /host/path/logs:/var/log/nginx nginx 拉取镜像\ndocker pull nginx:latest 运行镜像\ndocker run --name nginx -p 80:80 -d nginx 创建挂载目录\nmkdir -p ~/Documents/dockerdata/nginx/conf / mkdir -p ~/Documents/dockerdata/nginx/conf.d / mkdir -p ~/Documents/dockerdata/nginx/html / mkdir -p ~/Documents/dockerdata/nginx/log / 拷贝容器里面的内容\ndocker cp nginx:/etc/nginx/nginx.conf ~/Documents/dockerdata/nginx/conf/nginx.conf / docker cp nginx:/etc/nginx/conf.d ~/Documents/dockerdata/nginx / docker cp nginx:/usr/share/nginx/html ~/Documents/dockerdata/nginx / 停止并关闭容器\ndocker rm -f nginx 重新启动容器\ndocker run --name nginx -p 80:80 --privileged --restart=always \\ -v ~/Documents/dockerdata/nginx/conf/nginx.conf:/etc/nginx/nginx.conf:rw \\ -v ~/Documents/dockerdata/nginx/conf.d:/etc/nginx/conf.d:rw \\ -v ~/Documents/dockerdata/nginx/html:/usr/share/nginx/html:rw \\ -v ~/Documents/dockerdata/nginx/log:/var/log/nginx \\ -d nginx ","permalink":"https://XianCH.github.io/posts/tech/tool/docker%E5%A4%87%E5%BF%98%E5%BD%95/","summary":"docker常用命令 容器 进入容器 docker exec -it contaionName /bin/bash 查看容器日志 docker logs -f contaionName # 停止运行的容器 docker stop [容器ID] # 杀死容器进程 docker kill [容器ID] 镜像 导出镜像 docker save 导入镜像 docker load docker安装相关软件 redis 运行容器 docker run -itd --name redis-test -p 6379:6379 redis docker run --restart=always --log-opt max-size=100m --log-opt max-file=2 -p 6379:6379 --name myredis -v /home/redis/myredis/myredis.conf:/etc/redis/redis.conf -v /home/redis/myredis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes --requirepass 000415 参数说明 --restart=always 总是开机启动 --log","title":"Docker备忘录"},{"content":"go基础学习笔记 1. 命令 $ go Go is a tool for managing Go source code. Usage: go command [arguments] The commands are: build compile packages and dependencies clean remove object files doc show documentation for package or symbol env print Go environment information bug start a bug report fix run go tool fix on packages fmt run gofmt on package sources generate generate Go files by processing source get download and install packages and dependencies install compile and install packages and dependencies list list packages run compile and run Go program test test packages tool run specified go tool version print Go version vet run go tool vet on packages Use \u0026#34;go help [command]\u0026#34; for more information about a command. Additional help topics: c calling between Go and C buildmode description of build modes filetype file types gopath GOPATH environment variable environment environment variables importpath import path syntax packages description of package lists testflag description of testing flags testfunc description of testing functions Use \u0026#34;go help [topic]\u0026#34; for more information about that topic. go env用于打印Go语言的环境信息。\ngo run命令可以编译并运行命令源码文件。\ngo get可以根据要求和实际情况从互联网上下载或更新指定的代码包及其依赖包，并对它们进行编译和安装。\ngo build命令用于编译我们指定的源码文件或代码包以及它们的依赖包。\ngo install用于编译并安装指定的代码包及它们的依赖包。\ngo clean命令会删除掉执行其它命令时产生的一些文件和目录。\ngo doc命令可以打印附于Go语言程序实体上的文档。我们可以通过把程序实体的标识符作为该命令的参数来达到查看其文档的目的。\ngo test命令用于对Go语言编写的程序进行测试。\ngo list命令的作用是列出指定的代码包的信息。\ngo fix会把指定代码包的所有Go语言源码文件中的旧版本代码修正为新版本的代码。\ngo vet是一个用于检查Go语言源码中静态错误的简单工具。\ngo tool pprof命令来交互式的访问概要文件的内容。\n2. 运算符 1.算数运算符\n运算符 作用 + 相加 - 减 * 乘 / 除 % 求余 2.逻辑运算符\n运算符 描述 \u0026amp;\u0026amp; 逻辑 AND 运算符。 如果两边的操作数都是 True，则为 True，否则为 False。 ll 逻辑 OR 运算符。 如果两边的操作数有一个 True，则为 True，否则为 False。 ! 逻辑 NOT 运算符。 如果条件为 True，则为 False，否则为 True 3.位运算符\n运算符 描述 \u0026amp; 参与运算的两数各对应的二进位相与。（两位均为1才为1） l 参与运算的两数各对应的二进位相或。（两位有一个为1就为1） ^ 参与运算的两数各对应的二进位相异或，当两对应的二进位相异时，结果为1。（两位不一样则为1） \u0026laquo; 左移n位就是乘以2的n次方。“a\u0026laquo;b”是把a的各二进位全部左移b位，高位丢弃，低位补0。 \u0026gt;\u0026gt; 右移n位就是除以2的n次方。“a\u0026raquo;b”是把a的各二进位全部右移b位。 4.赋值运算符\n运算符 描述 = 简单的赋值运算符，将一个表达式的值赋给一个左值 += 相加后再赋值 -= 相减后再赋值 *= 相乘后再赋值 /= 相除后再赋值 %= 求余后再赋值 \u0026laquo;= 左移后赋值 \u0026gt;\u0026gt;= 右移后赋值 \u0026amp;= 按位与后赋值 l= 按位或后赋值 ^= 按位异或后赋值 3. init 和 main函数 init函数\ngo语言中init函数用于包(package)的初始化，该函数是go语言的一个重要特性。\n有下面的特征：\n1 init函数是用于程序执行前做包的初始化的函数，比如初始化包里的变量等 2 每个包可以拥有多个init函数 3 包的每个源文件也可以拥有多个init函数 4 同一个包中多个init函数的执行顺序go语言没有明确的定义(说明) 5 不同包的init函数按照包导入的依赖关系决定该初始化函数的执行顺序 6 init函数不能被其他函数调用，而是在main函数执行之前，自动被调用 1.2. main函数\nGo语言程序的默认入口函数(主函数)：func main() 函数体用｛｝一对括号包裹。 func main(){ //函数体 } 1.3. init函数和main函数的异同\n相同点： 两个函数在定义时不能有任何的参数和返回值，且Go程序自动调用。 不同点： init可以应用于任意包中，且可以重复定义多个。 main函数只能用于main包中，且只能定义一个。 两个函数的执行顺序：\n对同一个go文件的init()调用顺序是从上到下的。\n对同一个package中不同文件是按文件名字符串比较从小到大顺序调用各文件中的init()函数。\n对于不同的package，如果不相互依赖的话，按照main包中\u0026quot;先import的后调用\u0026quot;的顺序调用其包中的init()，如果package存在依赖，则先调用最早被依赖的package中的init()，最后调用main函数。\n如果init函数中使用了println()或者print()你会发现在执行过程中这两个不会按照你想象中的顺序执行。这两个函数官方只推荐在测试环境中使用，对于正式环境不要使用。\n4. 变量和常量 变量 标准声明\nvar 变量名 变量类型\nvar name string var age int var isOk bool 批量声明\nvar ( a string b int c bool d float32 ) 变量初始化\nvar 变量名 类型 = 表达式\nvar name string = \u0026#34;pprof.cn\u0026#34; var sex int = 1 3.1 变量推倒声明\nvar name = \u0026#34;pprof.cn\u0026#34; var sex = 1 3.2 短变量声明\npackage main import ( \u0026#34;fmt\u0026#34; ) // 全局变量m var m = 100 func main() { n := 10 m := 200 // 此处声明局部变量m fmt.Println(m, n) } 3.3 匿名变量\n在使用多重赋值时，如果想要忽略某个值，可以使用\n匿名变量（anonymous variable） 。 匿名变量用一个下划线_表示，例如：\nfunc foo() (int, string) { return 10, \u0026#34;Q1mi\u0026#34; } func main() { x, _ := foo() _, y := foo() fmt.Println(\u0026#34;x=\u0026#34;, x) fmt.Println(\u0026#34;y=\u0026#34;, y) } 匿名变量不占用命名空间，不会分配内存，所以匿名变量之间不存在重复声明。 (在Lua等编程语言里，匿名变量也被叫做哑元变量。)\n注意事项：\n函数外的每个语句都必须以关键字开始（var、const、func等） :=不能使用在函数外。 _多用于占位，表示忽略值。 常量 标准常量声明\nconst pi = 1415 const e = 7182 批量\nconst ( pi = 1415 e = 7182 ) const ( n1 = 100 n2 n3 ) iota iota是go语言的常量计数器，只能在常量的表达式中使用。 iota在const关键字出现时将被重置为0。const中每新增一行常量声明将使iota计数一次(iota可理解为const语句块中的行索引)。 使用iota能简化定义，在定义枚举时很有用。\nconst ( n1 = iota //0 n2 //1 n3 //2 n4 //3 ) 几个常见的iota示例:\n使用_跳过某些值\nconst ( n1 = iota //0 n2 //1 _ n4 //3 ) iota声明中间插队\nconst ( n1 = iota //0 n2 = 100 //100 n3 = iota //2 n4 //3 ) const n5 = iota //0 定义数量级 （这里的\u0026lt;\u0026lt;表示左移操作，1\u0026lt;\u0026lt;10表示将1的二进制表示向左移10位，也就是由1变成了10000000000，也就是十进制的1024。同理2\u0026lt;\u0026lt;2表示将2的二进制表示向左移2位，也就是由10变成了1000，也就是十进制的8。）\nconst ( _ = iota KB = 1 \u0026lt;\u0026lt; (10 * iota) MB = 1 \u0026lt;\u0026lt; (10 * iota) GB = 1 \u0026lt;\u0026lt; (10 * iota) TB = 1 \u0026lt;\u0026lt; (10 * iota) PB = 1 \u0026lt;\u0026lt; (10 * iota) ) 多个iota定义在一行\nconst ( a, b = iota + 1, iota + 2 //1,2 c, d //2,3 e, f //3,4 ) 5. 基本类型 基础类型介绍 类型 长度(字节) 默认值 说明 bool 1 false byte 1 0 uint8 rune 4 0 Unicode Code Point, int32 int, uint 4或8 0 32 或 64 位 int8, uint8 1 0 -128 ~ 127, 0 ~ 255，byte是uint8 的别名 int16, uint16 2 0 -32768 ~ 32767, 0 ~ 65535 int32, uint32 4 0 -21亿~ 21亿, 0 ~ 42亿，rune是int32 的别名 int64, uint64 8 0 float32 4 0.0 float64 8 0.0 complex64 8 complex128 16 uintptr 4或8 以存储指针的 uint32 或 uint64 整数 array 值类型 struct 值类型 string \u0026quot;\u0026quot; UTF-8 字符串 slice nil 引用类型 map nil 引用类型 channel nil 引用类型 interface nil 接口 function nil 函数 6. 数组Array 数组：是同一种数据类型的固定长度的序列。 数组定义：var a [len]int，比如：var a [5]int，数组长度必须是常量，且是类型的组成部分。一旦定义，长度不能变。 长度是数组类型的一部分，因此，var a[5] int和var a[10]int是不同的类型。 数组可以通过下标进行访问，下标是从0开始，最后一个元素下标是：len-1 for i := 0; i \u0026lt; len(a); i++ { } for index, v := range a { } 访问越界，如果下标在数组合法范围之外，则触发访问越界，会panic 数组是值类型，赋值和传参会复制整个数组，而不是指针。因此改变副本的值，不会改变本身的值。 支持 \u0026#34;==\u0026#34;、\u0026#34;!=\u0026#34; 操作符，因为内存总是被初始化过的。 指针数组 [n]*T，数组指针 *[n]T。 数组初始化 一维数组\n全局： var arr0 [5]int = [5]int{1, 2, 3} var arr1 = [5]int{1, 2, 3, 4, 5} var arr2 = [...]int{1, 2, 3, 4, 5, 6} var str = [5]string{3: \u0026#34;hello world\u0026#34;, 4: \u0026#34;tom\u0026#34;} 局部： a := [3]int{1, 2} // 未初始化元素值为 0。 b := [...]int{1, 2, 3, 4} // 通过初始化值确定数组长度。 c := [5]int{2: 100, 4: 200} // 使用索引号初始化元素。 d := [...]struct { name string age uint8 }{ {\u0026#34;user1\u0026#34;, 10}, // 可省略元素类型。 {\u0026#34;user2\u0026#34;, 20}, // 别忘了最后一行的逗号。 }package main import ( \u0026#34;fmt\u0026#34; ) var arr0 [5]int = [5]int{1, 2, 3} var arr1 = [5]int{1, 2, 3, 4, 5} var arr2 = [...]int{1, 2, 3, 4, 5, 6} var str = [5]string{3: \u0026#34;hello world\u0026#34;, 4: \u0026#34;tom\u0026#34;} func main() { a := [3]int{1, 2} // 未初始化元素值为 0。 b := [...]int{1, 2, 3, 4} // 通过初始化值确定数组长度。 c := [5]int{2: 100, 4: 200} // 使用引号初始化元素。 d := [...]struct { name string age uint8 }{ {\u0026#34;user1\u0026#34;, 10}, // 可省略元素类型。 {\u0026#34;user2\u0026#34;, 20}, // 别忘了最后一行的逗号。 } fmt.Println(arr0, arr1, arr2, str) fmt.Println(a, b, c, d) } 代码：\npackage main import ( \u0026#34;fmt\u0026#34; ) var arr0 [5]int = [5]int{1, 2, 3} var arr1 = [5]int{1, 2, 3, 4, 5} var arr2 = [...]int{1, 2, 3, 4, 5, 6} var str = [5]string{3: \u0026#34;hello world\u0026#34;, 4: \u0026#34;tom\u0026#34;} func main() { a := [3]int{1, 2} // 未初始化元素值为 0。 b := [...]int{1, 2, 3, 4} // 通过初始化值确定数组长度。 c := [5]int{2: 100, 4: 200} // 使用引号初始化元素。 d := [...]struct { name string age uint8 }{ {\u0026#34;user1\u0026#34;, 10}, // 可省略元素类型。 {\u0026#34;user2\u0026#34;, 20}, // 别忘了最后一行的逗号。 } fmt.Println(arr0, arr1, arr2, str) fmt.Println(a, b, c, d) } 结果：\n[1 2 3 0 0] [1 2 3 4 5] [1 2 3 4 5 6] [ hello world tom] [1 2 0] [1 2 3 4] [0 0 100 0 200] [{user1 10} {user2 20}] 多维数组\npackage main import ( \u0026#34;fmt\u0026#34; ) var arr0 [5][3]int var arr1 [2][3]int = [...][3]int{{1, 2, 3}, {7, 8, 9}} func main() { a := [2][3]int{{1, 2, 3}, {4, 5, 6}} b := [...][2]int{{1, 1}, {2, 2}, {3, 3}} // 第 2 纬度不能用 \u0026#34;...\u0026#34;。 fmt.Println(arr0, arr1) fmt.Println(a, b) } 结果\n[[0 0 0] [0 0 0] [0 0 0] [0 0 0] [0 0 0]] [[1 2 3] [7 8 9]] [[1 2 3] [4 5 6]] [[1 1] [2 2] [3 3]] 内置函数 len 和 cap 都返回数组长度 (元素数量)。\npackage main func main() { a := [2]int{} println(len(a), cap(a)) } 输出结果：\n2 2\n值拷贝行为会造成性能问题，通常会建议使用 slice，或数组指针。\npackage main import ( \u0026#34;fmt\u0026#34; ) func test(x [2]int) { fmt.Printf(\u0026#34;x: %p\\\\n\u0026#34;, \u0026amp;x) x[1] = 1000 } func main() { a := [2]int{} fmt.Printf(\u0026#34;a: %p\\\\n\u0026#34;, \u0026amp;a) test(a) fmt.Println(a) } 输出结果:\na: 0xc42007c010 x: 0xc42007c030 [0 0] # 多维数组遍历： package main import ( \u0026#34;fmt\u0026#34; ) func main() { var f [2][3]int = [...][3]int{{1, 2, 3}, {7, 8, 9}} for k1, v1 := range f { for k2, v2 := range v1 { fmt.Printf(\u0026#34;(%d,%d)=%d \u0026#34;, k1, k2, v2) } fmt.Println() } } (0,0)=1 (0,1)=2 (0,2)=3 (1,0)=7 (1,1)=8 (1,2)=9 数组拷贝和传参\npackage main import \u0026#34;fmt\u0026#34; func printArr(arr *[5]int) { arr[0] = 10 for i, v := range arr { fmt.Println(i, v) } } func main() { var arr1 [5]int printArr(\u0026amp;arr1) fmt.Println(arr1) arr2 := [...]int{2, 4, 6, 8, 10} printArr(\u0026amp;arr2) fmt.Println(arr2) } 7.切片Slice 介绍：\nslice 并不是数组或者指针。它是通过内部指针和相关属性引用数组片段，以实现变长方案\n7.1 创建切片的各种方式 // 声明切片\nvar s1 []int\n// :=\ns2 := []int{}\n// make\nvar slice []type = make([]type, len) slice := make([]type, len) slice := make([]type, len, cap) // 初始化赋值\ns := []int{1,2,3}\n7.2切片初始化 //全局 var arr = [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} var slice0 []int = arr[start:end] var slice1 []int = arr[:end] var slice2 []int = arr[start:] var slice3 []int = arr[:] var slice4 = arr[:len(arr)-1] //去掉切片的最后一个元素 //局部 arr2 := [...]int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} slice5 := arr[start:end] slice6 := arr[:end] slice7 := arr[start:] slice8 := arr[:] slice9 := arr[:len(arr)-1] //去掉切片的最后一个元素 操作 含义 s[n] 切片s中索引位置为n的项目 s[:] 0到len(s)-1 s[low:] low 到len(s)-1 s[:high] 0 到hight,len=high s[low:high] len = hight-low len(s) 切片长度 ，总是\u0026lt;=cap(s) cap(s) 切片容量，总是\u0026gt;=len(s) 7.3 切片基础操作 append\nvar a = []int{1, 2, 3} var b = []int{4, 5, 6} c := append(a, b...) fmt.Printf(\u0026#34;slice c : %v\\\\n\u0026#34;, c) slice c : [1 2 3 4 5 6] 超出原 slice.cap 限制，就会重新分配底层数组，即便原数组并未填满\ndata := [...]int{0, 1, 2, 3, 4, 10: 0} s := data[:2:3] s = append(s, 100, 200) // 一次 append 两个值，超出 s.cap 限制。 fmt.Println(s, data) // 重新分配底层数组，与原数组无关。 fmt.Println(\u0026amp;s[0], \u0026amp;data[0]) // 比对底层数组起始指针。 [0 1 100 200] [0 1 2 3 4 0 0 0 0 0 0] 0xc4200160f0 0xc420070060 切片拷贝\ns1 := []int{1, 2, 3, 4, 5} fmt.Printf(\u0026#34;slice s1 : %v\\\\n\u0026#34;, s1) s2 := make([]int, 10) fmt.Printf(\u0026#34;slice s2 : %v\\\\n\u0026#34;, s2) copy(s2, s1) fmt.Printf(\u0026#34;copied slice s1 : %v\\\\n\u0026#34;, s1) fmt.Printf(\u0026#34;copied slice s2 : %v\\\\n\u0026#34;, s2) s3 := []int{1, 2, 3} fmt.Printf(\u0026#34;slice s3 : %v\\\\n\u0026#34;, s3) s3 = append(s3, s..) fmt.Printf(\u0026#34;appended slice s3 : %v\\\\n\u0026#34;, s3) s3 = append(s3, 4, 5, 6) fmt.Printf(\u0026#34;last slice s3 : %v\\\\n\u0026#34;, s3) slice s1 : [1 2 3 4 5] slice s2 : [0 0 0 0 0 0 0 0 0 0] copied slice s1 : [1 2 3 4 5] copied slice s2 : [1 2 3 4 5 0 0 0 0 0] slice s3 : [1 2 3] appended slice s3 : [1 2 3 1 2 3 4 5 0 0 0 0 0] last slice s3 : [1 2 3 1 2 3 4 5 0 0 0 0 0 4 5 6] copy ：函数 copy 在两个 slice 间复制数据，复制长度以 len 小的为准。两个 slice 可指向同一底层数组，允许元素区间重叠。\ndata := [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} fmt.Println(\u0026#34;array data : \u0026#34;, data) s1 := data[8:] s2 := data[:5] fmt.Printf(\u0026#34;slice s1 : %v\\\\n\u0026#34;, s1) fmt.Printf(\u0026#34;slice s2 : %v\\\\n\u0026#34;, s2) copy(s2, s1) fmt.Printf(\u0026#34;copied slice s1 : %v\\\\n\u0026#34;, s1) fmt.Printf(\u0026#34;copied slice s2 : %v\\\\n\u0026#34;, s2) fmt.Println(\u0026#34;last array data : \u0026#34;, data) array data : [0 1 2 3 4 5 6 7 8 9] slice s1 : [8 9] slice s2 : [0 1 2 3 4] copied slice s1 : [8 9] copied slice s2 : [8 9 2 3 4] last array data : [8 9 2 3 4 5 6 7 8 9] slice遍历\ndata := [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} slice := data[:] for index, value := range slice { fmt.Printf(\u0026#34;inde : %v , value : %v\\\\n\u0026#34;, index, value) } 切片调整大小\nfmt.Printf(\u0026#34;slice a : %v , len(a) : %v\\\\n\u0026#34;, a, len(a)) b := a[1:2] fmt.Printf(\u0026#34;slice b : %v , len(b) : %v\\\\n\u0026#34;, b, len(b)) c := b[0:3] fmt.Printf(\u0026#34;slice c : %v , len(c) : %v\\\\n\u0026#34;, c, len(c)) slice a : [1 3 4 5] , len(a) : 4 slice b : [3] , len(b) : 1 slice c : [3 4 5] , len(c) : 3 字符串和切片\nstring底层就是一个byte的数组，因此，也可以进行切片操作。\nstr := \u0026#34;hello world\u0026#34; s1 := str[0:5] fmt.Println(s1) s2 := str[6:] fmt.Println(s2) hello world\n8. map 语法\nmap[KeyType]ValueType scoreMap := make(map[string]int, 8) 判断key是否存在\nvalue, ok := map[key] map的遍历\nfor k, v := range scoreMap { fmt.Println(k, v) } 删除键值对\ndelete(map, key) 元素为map类型的切片\nvar mapSlice = make([]map[string]string, 3) for index, value := range mapSlice { fmt.Printf(\u0026#34;index:%d value:%v\\\\n\u0026#34;, index, value) } fmt.Println(\u0026#34;after init\u0026#34;) // 对切片中的map元素进行初始化 mapSlice[0] = make(map[string]string, 10) mapSlice[0][\u0026#34;name\u0026#34;] = \u0026#34;王五\u0026#34; mapSlice[0][\u0026#34;password\u0026#34;] = \u0026#34;123456\u0026#34; mapSlice[0][\u0026#34;address\u0026#34;] = \u0026#34;红旗大街\u0026#34; for index, value := range mapSlice { fmt.Printf(\u0026#34;index:%d value:%v\\\\n\u0026#34;, index, value) } 值为切片类型的map\nvar sliceMap = make(map[string][]string, 3) fmt.Println(sliceMap) fmt.Println(\u0026#34;after init\u0026#34;) key := \u0026#34;中国\u0026#34; value, ok := sliceMap[key] if !ok { value = make([]string, 0, 2) } value = append(value, \u0026#34;北京\u0026#34;, \u0026#34;上海\u0026#34;) sliceMap[key] = value fmt.Println(sliceMap) 9.流程控制 if if 布尔表达式 { /* 在布尔表达式为 true 时执行 */ } else { /* 在布尔表达式为 false 时执行 */ } switch switch var1 { case val1: ... case val2: ... default: ... } type switch\nswitch x.(type){ case type: statement(s) case type: statement(s) /* 你可以定义任意个数的case */ default: /* 可选 */ statement(s) } select select 语句类似于 switch 语句，但是select会随机执行一个可运行的case。如果没有case可运行，它将阻塞，直到有case可运行。\nselect { case communication clause : statement(s); case communication clause : statement(s); /* 你可以定义任意数量的 case */ default : /* 可选 */ statement(s); } tips:\n每个case都必须是一个通信\n​ 所有channel表达式都会被求值\n​ 所有被发送的表达式都会被求值\n​ 如果任意某个通信可以进行，它就执行；其他被忽略。\n​ 如果有多个case都可以运行，Select会随机公平地选出一个执行。其他不会执行。\n​ 否则：\n​ 如果有default子句，则执行该语句。\n​ 如果没有default字句，select将阻塞，直到某个通信可以运行；Go不会重新对channel或值进行求值。\nvar c1, c2, c3 chan int var i1, i2 int select { case i1 = \u0026lt;-c1: fmt.Printf(\u0026#34;received \u0026#34;, i1, \u0026#34; from c1\\\\n\u0026#34;) case c2 \u0026lt;- i2: fmt.Printf(\u0026#34;sent \u0026#34;, i2, \u0026#34; to c2\\\\n\u0026#34;) case i3, ok := (\u0026lt;-c3): // same as: i3, ok := \u0026lt;-c3 if ok { fmt.Printf(\u0026#34;received \u0026#34;, i3, \u0026#34; from c3\\\\n\u0026#34;) } else { fmt.Printf(\u0026#34;c3 is closed\\\\n\u0026#34;) } default: fmt.Printf(\u0026#34;no communication\\\\n\u0026#34;) 基本使用\nselect是Go中的一个控制结构，类似于switch语句，用于处理异步IO操作。select会监听case语句中channel的读写操作，当case中channel读写操作为非阻塞状态（即能读写）时，将会触发相应的动作。 select中的case语句必须是一个channel操作\nselect中的default子句总是可运行的。\n1, 如果有多个case都可以运行，select会随机公平地选出一个执行，其他不会执行。\n2, 如果没有可运行的case语句，且有default语句，那么就会执行default的动作。\n3, 如果没有可运行的case语句，且没有default语句，select将阻塞，直到某个case通信可以运行\n典型用法 1.超时判断\n//比如在下面的场景中，使用全局resChan来接受response，如果时间超过3S,resChan中还没有数据返回，则第二条case将执行 var resChan = make(chan int) // do request func test() { select { case data := \u0026lt;-resChan: doData(data) case \u0026lt;-time.After(time.Second * 3): fmt.Println(\u0026#34;request time out\u0026#34;) } } func doData(data int) { //... } 2.退出\n//主线程（协程）中如下： var shouldQuit=make(chan struct{}) fun main(){ { //loop } //...out of the loop select { case \u0026lt;-c.shouldQuit: cleanUp() return default: } //... } //再另外一个协程中，如果运行遇到非法操作或不可处理的错误，就向shouldQuit发送数据通知程序停止运行 close(shouldQuit) 3.判断是否堵塞\n//在某些情况下是存在不希望channel缓存满了的需求的，可以用如下方法判断 ch := make (chan int, 5) //... data：=0 select { case ch \u0026lt;- data: default: //做相应操作，比如丢弃data。视需求而定 } for 1, for init; condition; post { } 2, for condition { } 3, for { } range for key, value := range oldMap { newMap[key] = value } goto,break,continue ","permalink":"https://XianCH.github.io/posts/tech/go/golang%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/","summary":"go基础学习笔记 1. 命令 $ go Go is a tool for managing Go source code. Usage: go command [arguments] The commands are: build compile packages and dependencies clean remove object files doc show documentation for package or symbol env print Go environment information bug start a bug report fix run go tool fix on packages fmt run gofmt on package sources generate generate Go files by processing source get download and install packages and dependencies install compile and install packages and dependencies list list packages run compile and run Go program test test packages tool run specified go tool version print Go version vet run go tool vet on packages Use \u0026#34;go help [command]\u0026#34; for more information about a command. Additional help topics: c calling between Go and C buildmode description of build","title":"Golang基础学习(更新中）"},{"content":"(F)数据结构 1,数组和队列 稀疏数组 介绍\n当一个素组中大部分为0或者都是同一个数时，可以使用稀疏数组来保存该数组，就像是五子棋游戏一样，把整个五子棋棋盘定义成一个二位数组，大部分为0.\n处理方式\n1.记录一个数组一共有几行几列，有多少个不同的值\n2.把具有 不同值的元素 的 行列及值 记录在一个 小规模的数组 中，从而缩小程序的规模\n实际应用\n以围棋为例，假设一个10x10的棋盘可以用个二维数组表示int[10] [10],数组全是零，红方和黑方分别用1和2表示，如下图：\n代码实现\npackage main import \u0026#34;fmt\u0026#34; type SparseElement struct { row, col, value int } type SparseArray struct { row, col int data []SparseElement } func NewSparseArray(row, col int) *SparseArray { return \u0026amp;SparseArray{ row: row, col: col, data: []SparseElement{}, } } func (sa *SparseArray) Set(row, col, value int) { element := \u0026amp;SparseElement{ row: row, col: col, value: value, } sa.data = append(sa.data, *element) } func (sa *SparseArray) Get(row, col int) int { for _, data := range sa.data { if row == data.row \u0026amp;\u0026amp; col == data.col { return data.value } } return 0 } func main() { sparseArray := NewSparseArray(10, 10) sparseArray.Set(1, 3, 1) sparseArray.Set(4, 2, 2) for i := 0; i \u0026lt; 10; i++ { for j := 0; j \u0026lt; 10; j++ { fmt.Printf(\u0026#34;%d \u0026#34;, sparseArray.Get(i, j)) } fmt.Println() } } 队列 队列暂时没有什么想法，先进先出？下面是自己写的代码\npackage main import ( \u0026#34;sync\u0026#34; ) type Queen struct { Size int items []interface{} mutex sync.Mutex } func (queen *Queen) SetMaxSize(size int) { queen.Size = size } func (queen *Queen) IsFull() bool { return len(queen.items) == queen.Size } func (queen *Queen) EnQueen(item interface{}) { queen.mutex.Lock() defer queen.mutex.Unlock() if !queen.IsFull() { queen.items = append(queen.items, item) } } func (queen *Queen) Fornt() interface{} { return queen.items[0] } func (queen *Queen) IsEmpty() bool { return len(queen.items) == 0 } func main() { queen := \u0026amp;Queen{ Size: 20, } go func() { for i := 0; i \u0026lt; 20; i++ { } }() } 2,链表 介绍 链表是以 节点 的方式来存储，是 链式存储 每个节点包含 data 域、next 域，指向下一个节点 链表的各个节点 不一定是连续存储，如上图所示 链表还分：带头节点、不带头节点，根据实际需求来确定 链表的优势\n删除和插入数据比较方便，时间复杂度为O1,但是查找不方便，都是要从第一个节点一直找next指针，直到找到为止，如果数字的话，直接找到数组的index就可以了\n单链表 下图是单链表的逻辑结构，每个节点都包含下一个节点的指针，当某个节点的next为nil的时候，就到了尾节点\n单链表应用实战 用单链表实现对足球明星排名的存储（个人喜好，不供参考）\n完成对球星人物的 增删改查 操作 根据排名对球星排名进行排序 双向链表 单向环形链表 单向环形链表-Josephu 问题 3,栈 4,哈希表 介绍 散列表（Hash table），也叫哈希表。是根据 关键码值（key value） 而直接进行访问的数据结构。\n哈希表在内存中的结构就如下图所示：\n如上所述：\n左侧有 15 个元素的数组（可以用数组实现），就是一个表\n该表中存放的是一个链表\n通过 散列函数，计算出一个位置，然后在把数据存储到这个链表上\n比如上面有 15 个，可以计算出散列值后，再取模。 111 % 15 ，就定位在了某一个元素位置上。\n代码实现 package main import \u0026#34;fmt\u0026#34; type Employee struct { ID int Name string Sal int Next *Employee } type EmpHashTable struct { Table []*Employee Size int } func NewTable(size int) *EmpHashTable { return \u0026amp;EmpHashTable{ Table: make([]*Employee, size), Size: size, } } // 插入 func (ht *EmpHashTable) Insert(emp *Employee) { Index := int(emp.ID) % ht.Size if ht.Table[Index] == nil { ht.Table[Index] = emp } else { current := ht.Table[Index] for current.Next != nil { current = current.Next } current.Next = emp } } // 查找 func (ht *EmpHashTable) search(id int) (emp *Employee) { Index := id % ht.Size if ht.Table[Index].ID == id { return ht.Table[Index] } else { current := ht.Table[Index] for current != nil { if current.ID == id { return current } current = current.Next } } return nil } // 删除 func (ht *EmpHashTable) del(id int) bool { Index := id % ht.Size current := ht.Table[Index] var prev *Employee for current != nil { if current.ID == id { if prev == nil { //删除的是第一个元素 ht.Table[Index] = current.Next } else { //中间或者末尾 prev.Next = current.Next } return true } prev = current current = current.Next } return false } // 修改 func (ht *EmpHashTable) change(id int, newEmp *Employee) bool { Index := id % ht.Size current := ht.Table[Index] for current != nil { if current.ID == id { current.Name = newEmp.Name current.Sal = newEmp.Sal return true } current = current.Next } return false } // 遍历 func (ht *EmpHashTable) DisPlayAll() { for _, emp := range ht.Table { current := emp for current != nil { fmt.Printf(\u0026#34;ID:%d,Name:%s,sal:%d\\n\u0026#34;, current.ID, current.Name, current.Sal) current = current.Next } } } func main() { empTable := NewTable(5) empTable.Insert(\u0026amp;Employee{ID: 101, Name: \u0026#34;x14n\u0026#34;, Sal: 3000}) empTable.Insert(\u0026amp;Employee{ID: 102, Name: \u0026#34;x14n\u0026#34;, Sal: 3000}) empTable.Insert(\u0026amp;Employee{ID: 103, Name: \u0026#34;x14n\u0026#34;, Sal: 3000}) empTable.Insert(\u0026amp;Employee{ID: 104, Name: \u0026#34;x14n\u0026#34;, Sal: 3000}) empTable.Insert(\u0026amp;Employee{ID: 105, Name: \u0026#34;x14n\u0026#34;, Sal: 3000}) empTable.Insert(\u0026amp;Employee{ID: 106, Name: \u0026#34;x14n\u0026#34;, Sal: 3000}) empTable.Insert(\u0026amp;Employee{ID: 107, Name: \u0026#34;x14n\u0026#34;, Sal: 3000}) empTable.Insert(\u0026amp;Employee{ID: 108, Name: \u0026#34;x14n\u0026#34;, Sal: 3000}) empTable.Insert(\u0026amp;Employee{ID: 109, Name: \u0026#34;x14n\u0026#34;, Sal: 3000}) emp := empTable.search(101) if emp == nil { fmt.Println(\u0026#34;no found\u0026#34;) } else { fmt.Println(\u0026#34;find\u0026#34;) fmt.Printf(\u0026#34;ID:%d,Name:%s,sal:%d\\n\u0026#34;, emp.ID, emp.Name, emp.Sal) } empTable.DisPlayAll() fmt.Println(\u0026#34;//删除\u0026#34;) empTable.del(102) fmt.Println(\u0026#34;//修改\u0026#34;) empTable.change(101, \u0026amp;Employee{Name: \u0026#34;ahahah\u0026#34;, Sal: 10000000}) fmt.Println(\u0026#34;////////\u0026#34;) empTable.search(101) fmt.Println(\u0026#34;////////\u0026#34;) empTable.DisPlayAll() } 5,树基础 二叉树 介绍 简单来说就是左子节点小于root，右节点大于root\n遍历 前序遍历：先输出父节点，在遍历左节点（递归），再遍历右节点（递归）\n中序遍历：先遍历左子树（递归），再输出父节点，再遍历右子树（递归）\n后序遍历：先遍历左子树（递归），再右子树（递归），再父节点\n前： a -\u0026gt; b -\u0026gt; d -\u0026gt;e -\u0026gt;c\n中: d -\u0026gt; b -\u0026gt; e -\u0026gt; a -\u0026gt;c\n后： d-\u0026gt;e -\u0026gt; b-\u0026gt; c -\u0026gt;a\n删除 // 插入原始 func (bt *binaryTree) insert(key int) { if bt.root == nil { bt.root = \u0026amp;node{key: key} } bt.insertRecursively(bt.root, key) } func (bt *binaryTree) insertRecursively(root *node, key int) { if key \u0026lt; root.key { if root.LeftChild == nil { root.LeftChild = \u0026amp;node{key: key} } else { bt.insertRecursively(root.LeftChild, key) } } else { if root.RightChild == nil { root.RightChild = \u0026amp;node{key: key} } else { bt.insertRecursively(root.RightChild, key) } } } // 搜索元素 func (bt *binaryTree) search(key int) bool { return bt.searchRecurisively(bt.root, key) } func (bt *binaryTree) searchRecurisively(root *node, key int) bool { if root == nil { fmt.Println(\u0026#34;root is nil\u0026#34;) return false } if root.key == key { return true } if root.key \u0026gt; key { return bt.searchRecurisively(root.LeftChild, key) } else { return bt.searchRecurisively(root.RightChild, key) } } // 前序遍历 func (bt *binaryTree) PerOrderTraversal(node *node) { if node != nil { fmt.Printf(\u0026#34;%d\u0026#34;, node.key) bt.PerOrderTraversal(node.LeftChild) bt.PerOrderTraversal(node.RightChild) } } // 中序遍历 func (bt *binaryTree) InOrderTraversal(root *node) { if root != nil { bt.InOrderTraversal(root.LeftChild) fmt.Printf(\u0026#34;%d\u0026#34;, root.key) bt.InOrderTraversal(root.RightChild) } } // 后序遍历 func (bt *binaryTree) PostOrderTraversal(root *node) { if root != nil { bt.PostOrderTraversal(root.RightChild) bt.PostOrderTraversal(root.LeftChild) fmt.Printf(\u0026#34;%d\u0026#34;, root.key) } } 顺序查找二叉树 顺序二叉树 通常只考虑 完全二叉树 第 n 个元素的 左子节点 为 2*n+1 第 n 个元素的 右子节点 为 2*n+2 第 n 个元素的 父节点 为 (n-1)/2 线索化二叉树 6,树实际 堆排序 介绍 堆是具有以下性质的完全二叉树：\n大顶堆：每个节点的值都 大于或等于 其左右孩子节点的值\n注：没有要求左右值的大小关系\n小顶堆：每个节点的值都 小于或等于 其左右孩子节点的值\n大顶堆\n对堆中的节点按层进行编号，映射到数组中如下图\n小顶堆（反之）\n堆排序思路\u0026mdash;- package main import ( \u0026#34;fmt\u0026#34; ) func heapSort(arr []int) { n := len(arr) // 构建最大堆 for i := n/2 - 1; i \u0026gt;= 0; i-- { heapify(arr, n, i) } // 依次取出堆顶元素，交换位置，重新堆化 for i := n - 1; i \u0026gt; 0; i-- { // 交换堆顶和当前堆的最后一个元素 arr[i], arr[0] = arr[0], arr[i] // 对交换后的堆顶执行堆化 heapify(arr, i, 0) } } func heapify(arr []int, n, i int) { largest := i left := 2*i + 1 right := 2*i + 2 // 找出左子节点和右子节点中的最大值 if left \u0026lt; n \u0026amp;\u0026amp; arr[left] \u0026gt; arr[largest] { largest = left } if right \u0026lt; n \u0026amp;\u0026amp; arr[right] \u0026gt; arr[largest] { largest = right } // 如果最大值不是父节点，交换父节点和最大值，然后递归堆化 if largest != i { arr[i], arr[largest] = arr[largest], arr[i] heapify(arr, n, largest) } } func main() { arr := []int{4, 10, 3, 5, 1} fmt.Println(\u0026#34;Unsorted array:\u0026#34;, arr) heapSort(arr) fmt.Println(\u0026#34;Sorted array:\u0026#34;, arr) } 关于堆排序的思考 最开始我认为堆排序为什么不直接 将二叉树中的叶子节点的值存到一个数组中，然后对数组的值进行从小到大进行\t排序，然后根据数组的索引和索引的值创建一个新的二叉树，这样不是更简单吗，仔细想想这不是更简单吗。\n堆排序之所以高效的原因：\n不需要额外的数据结构： 堆排序直接在原始数组上进行操作，不需要额外的数据结构来存储节点的值。这节省了空间，并减少了复杂性。 原地排序： 堆排序是一种原地排序算法，它不需要额外的内存来存储中间结果，因此空间复杂度为 O(1)。 时间复杂度： 堆排序的时间复杂度是 O(n log n)，其中 n 是要排序的元素数量。这是一种非常高效的排序算法，特别适用于大型数据集。 如果按照原来的思路会带来的问题：\n创建了额外的数据结构，增加了空间复杂度 增加了时间复杂度 ​\n赫夫曼树 介绍 权路径长度最小（wpl）的二叉树称为最优二叉树也被成为赫夫曼树。\n赫夫曼树是带全路径长度最短的树，权值较大的节点离根节点较近\n相关概念 路径 和 路径长度：\n在一颗树中，从一个节点往下可以到达的孩子或孙子节点之间的通路，称为 路径。\n通路中分支的数目称为路径长度。若规定根节点的层数为 1，则从根节点到第 L 层节点的路径长度为 L-1\n节点的权 及 带权路径长度\n若将树中节点赋给一个有着某种函数的数值，则这个数值称为该节点的 权。\n节点的带权路径长度为：从根节点到该节点之间的路径长度与该节点的权的乘积。\n树的带权路径长度\n所有叶子节点的带权路径长度之和，记为 WPL（weighted path length），权值越大的节点离根节点越近的二叉树才是最优二叉树\n赫夫曼树实现\u0026mdash;\u0026mdash; 二叉排序树 介绍 对于二叉排序树的任何一个 非叶子节点，要求如下：\n左节点，比父节点小 右节点，比父节点大 完整平衡二叉树（AVL树） 介绍 平衡二叉树也叫 平衡二叉搜索树（Self-balancing binary search tree），又被称为 AVL 树，可以保证 查询效率较高。它是解决 二叉排序 可能出现的查询问题。\n它的特点：是一颗空树或它的 左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一颗平衡二叉树。\n如下所述，哪些是平衡二叉树？\n是平衡二叉树：\n左子树高度为 2 右子树高度为 1 他们差值为 1\n也是平衡二叉树\n不是平衡二叉树\n左子树高度为 3 右子树高度为 1 他们差值为 2，所以不是\n平衡二叉树的常用实现方法有： 红黑树\nAVL（算法）\n替罪羊树\nTreap\n伸展树\n7,多路查找树 二叉树与B树 B树,B+树,B*树 8,图 (S)算法 1,递归 2,排序算法 冒泡排序 func bubbleSort(arrs []int) { len := len(arrs) for i := 0; i \u0026lt; len-1; i++ { for j := 0; j \u0026lt; len-i-1; j++ { if arrs[j] \u0026gt; arrs[j+1] { arrs[j], arrs[j+1] = arrs[j+1], arrs[j] } } } } 选择排序 func selectSort(arr []int) { n := len(arr) for i := 0; i \u0026lt; n-1; i++ { minIndex := i for j := i + 1; j \u0026lt; n; j++ { if arr[j] \u0026lt; arr[minIndex] { minIndex = j } } if minIndex != i { arr[i], arr[minIndex] = arr[minIndex], arr[i] // 交换元素 } } } 插入排序 package main import \u0026#34;fmt\u0026#34; func InsertSort(array []int) { n := len(array) for i := 1; i \u0026lt; n; i++ { for js := i; js \u0026gt; 0; js-- { if array[js] \u0026lt; array[js-1] { array[js], array[js-1] = array[js-1], array[js] } } } } func main() { array := []int{7, 6, 4, 5, 3, 2} InsertSort(array) fmt.Println(array) } 希尔排序 快速排序 归并排序 基数排序 常用排序算法总结对比 3,查找算法 4,十种常用算法 二分查找(非递归) 分治算法 动态规划算法 KMP算法 贪心算法 普利姆算法 迪杰斯特拉算法 马踏棋算法 普洛伊德算法 ","permalink":"https://XianCH.github.io/posts/tech/basic/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","summary":"(F)数据结构 1,数组和队列 稀疏数组 介绍 当一个素组中大部分为0或者都是同一个数时，可以使用稀疏数组来保存该数组，就像是五子棋游戏一样，把整个五子棋棋盘定义成一个二位数组，大部分为0. 处理方式 1.记录一个数组一共有几行几列，有多少个不同的值 2.把具有 不同值的元素 的 行列及值 记录在一个","title":"go数据结构与算法（更新中）"},{"content":" 基础相关 var和:=来定义变量有什么不同？new和make初始化变量有什么不同呢？\n#var 用来定义单个或者多个变量变量,:=一般用来创建变量并且用来给变量复赋值 var a int a =5 a :=5 #new 用来创建一个指向新分配零值对象的指针，并返回指向该实例的指针，new返回的是指针对象 #make 用来创建切片，通道和映射等内置数据结构，并初始化 p := new(int) slience := make([]int,0,10) defer是做什么用的，如果一个程序里面有多个defer会怎么样？\n延迟的函数推送执行，先进先出，一般用来关闭文件资源。第一个defer一般是在整个程序运行结束后第一个执行，然后才到执行下一个 切片的底层是怎么实现的？interface的两种用法了解吗？了解interface的底层实现吗？\n如上图切片其实是应用类型，有三个字段：1.指向应用数组的指针，长度，和容量。当对某个切片进行slien[1:3]其实是创建了新的切片。 1.类型断言\tvalue, ok := someInterface.(SomeType) 2.类型查询\tswitch v := someInterface.(type) { case SomeType1: // 处理 SomeType1 类型 case SomeType2: // 处理 SomeType2 类型 default: // 默认处理 } 怎么用的map，会有并发问题吗？怎么求一个map的长度（len就可以，害）。sync.Map可以用len来求长度吗？（应该是想要问sync.Map的底层吧）\n//make示例 myMap = make(map[string]int) len(map) 关于并发问题，标准的 Go map 不是并发安全的，也就是说，如果多个 goroutine 同时读写一个 map，可能会导致数据竞争和不确定的结果。为了在并发环境下安全使用 map，你可以使用互斥锁（sync.Mutex）来保护 map，或者使用 sync.Map，后者是 Go 1.9 引入的并发安全的映射类型。 //用互斥锁来保护标准的\u0026#39;map\u0026#39;： package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { myMap := make(map[string]int) var mu sync.Mutex var wg sync.WaitGroup for i := 0; i \u0026lt; 100; i++ { wg.Add(1) go func(n int) { defer wg.Done() mu.Lock() myMap[\u0026#34;key\u0026#34;] = n mu.Unlock() }(i) } fmt.Println(\u0026#34;Waiting for goroutines to finish...\u0026#34;) wg.Wait() mu.Lock() fmt.Println(\u0026#34;Map:\u0026#34;, myMap) mu.Unlock() } 然而，在 sync.Map 中，你不能直接使用 len() 函数来获取长度。sync.Map 不提供获取长度的方法。这是因为 sync.Map 的设计目标是在并发环境下进行读写操作，而不是频繁获取长度等操作。如果你需要跟踪 sync.Map 的长度，可以自己实现一个计数器，在每次插入或删除键值对时进行递增或递减操作来维护长度信息。但要注意，在多个并发操作中，你需要正确地处理计数器的增减，以避免竞态条件。 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var myMap sync.Map for i := 0; i \u0026lt; 100; i++ { key := fmt.Sprintf(\u0026#34;key%d\u0026#34;, i) myMap.Store(key, i) } fmt.Println(\u0026#34;wating all gonrint down....\u0026#34;) myMap.Range(func(key, value interface{}) bool { fmt.Printf(\u0026#34;Key: %v, Value: %v\\n\u0026#34;, key, value) return true }) } 有缓冲和无缓冲channel的区别\n无缓冲(\u0026lt;-)：表示如果向通道中输入数据，但是该通道没有输出方，则会堵塞,直到双方都准备好 有缓冲：在缓冲值没有满之前可以一直向通道输入数据 select中如果没有default会出现什么情况？（select会阻塞，直到有case可以执行）case中的通道被关闭了会出现什么情况？（只有这一个的话会死循环，可以用,ok判断一下）\nmap是有序的吗？map底层实现怎么处理hash碰撞的问题？\nrecover和panic的实现原理\n是否了解反射\n普通的map加锁使用与直接用sync.map有什么区别？（分别说了使用上和性能上）\n并发相关 golang协程的调度，聊聊对GMP模型的理解 怎么实现并发？ 怎么让协程等待？ 聊聊goroutine泄漏？怎么避免和排查goroutine泄漏的问题？ goroutine的状态机 聊聊channel的特性，从nil的channel中取数据会发生什么？ 其他 哪些情况下会panic？所有的panic都可以recover吗？recover函数的使用过程，是怎么捕获的？ context是做什么用的？ 有什么办法可以获得函数调用的链路？ 怎么处理协程运行的超时问题？ 怎么优雅地关闭通道？ 从面向对象的角度聊聊java和golang的区别 golang的GC golang的http路由实现懂吗，可以描述一下吗？ golang程序hang住了可能是什么原因（说了可能死循环导致无法GC，golang1.13），怎么排查（可以用pprof） 数据结构 数组查找的时间复杂度是多少，为什么？ 了解跳表吗？ 你知道哪些树结构，各自的优缺点分别是什么？（回答的时候再回答一下应用场景就更好了） 操作系统 用过锁吗？读写锁加读锁的时候会阻塞写操作吗？会阻塞读操作吗？（用过，会，不会） Linux 用过ps命令解决过什么问题吗？查询出来的结果各个字段有什么含义？ 了解僵尸进程吗？怎么避免？ 怎么根据pid获取父进程的pid（回答说去/proc下面），怎么根据pid找执行路径呢？怎么根据端口号找pid（回答说lsof -i，用netstat也可以但是我不知道，面试官补充的） 数据库 Redis和MySQL的区别，什么时候用Redis，什么时候用MySQL（这里我说了下我们服务用到的场景）？如果让你设计一个秒杀系统，要怎么设计？（面试官后来提示了一下说redis又一个自增key） MySQL 有几种隔离级别？默认级别是什么？可重复读是怎么解决幻读的？了解mvcc嘛？下面几种mysql哪个会用到联合索引 linked：https://juejin.cn/post/6967618371844046856\n","permalink":"https://XianCH.github.io/posts/tech/go/golang%E7%9B%B8%E5%85%B3%E7%BB%83%E4%B9%A0%E9%A2%98/","summary":"基础相关 var和:=来定义变量有什么不同？new和make初始化变量有什么不同呢？ #var 用来定义单个或者多个变量变量,:=一般用来创建变量并且用来给变量复赋值 var a int a =5 a :=5 #new 用来创建一个指向新分配零值对象的指针，并返回指向该实例的指针，new返回的是指针对象 #make 用来创建切片，通道和映射","title":"Golang相关练习题"},{"content":"arch安装以及i3wm配置 配置：\nintel\n硬盘处理 lsblk 查看硬盘情况（sda 为机械硬盘，nvme0n1是固态，这里的sda 是u盘)\ncgdisk /dev/nvme0n1\n用于分区表编辑和管理的命令行工具，主要用于处理磁盘的分区表，可以使用cgdisk来创建新的GPT分区表，这将抹去旧的分区表和数据，所以务必谨慎操作\nef00 boot\n8200 swap\n格式化硬盘\n启动分区：\nmkfs.fat -F32 /dev/nvme0n1p1 交换分区：\nmkswap /dev/nvme0n1p2 启动交换分区\nswapon /dev/nvme0n1p2 系统分区：\nmkfs.ext4 /dev/nvme0n1p3 mkfs.ext4 /dev/nvme0n1p4 挂载分区\nmount /dev/nvme0n1p3 /mnt mkdir /mnt/boot mount /dev/nvme0n1p1 /mnt/boot mkdir /mnt/home mount /dev/nvme0n1p4 /mnt/home 然后运行lsblk查看分区情况\n设置pacman服务 通过https://archlinux.org/mirrorlist/ 查看镜像源\n修改镜像源\nvim /etc/pacman.d/mirrorlist 备份镜像源\ncp /etc/pacman.d/mirrorlist /etc/pacman.d/mirrorlist.backup 更新镜像源\nreflector --verbose --latest 15 --sort rate --save /etc/pacman.d/mirrorlist pacman -Sy 安装基本系统以及固件 pacstrap -i /mnt linux-headers linux-firmware base base-devel vim intel-ucode pacstrap /mnt base base-devel linux linux-firmware dhcpcd vim reflector 进入新系统\ngenfstab -U -p /mnt \u0026gt;\u0026gt; /mnt/etc/fstab cat /mnt/etc/fstab arch-chroot /mnt pacman -Syy 设置时区 语言 时区\nls -s /usr/share/zoneinfo/ #点tab ls -s /usr/share/zoneinfo/Asia/ #以此类推 ln -s /usr/share/zoneinfo/Asia/Shanghai \u0026gt; /etc/localtime hwclock --systohc 语言设置\nvim /etc/locale.gen zh_CN.UTF-8 UTF-8 en_US.UTF-8 UTF-8 #选这两个 locale-gen 设置默认语言并更新\n[root@archiso /]# echo LANG=en_US.UTF-8 \u0026gt; /etc/locale.conf [root@archiso /]# vim /etc/locale.conf [root@archiso /]# export LANG=en_US.UTF-8 网络设置 [root@archiso /]# vim /etc/hostname [root@archiso /]# vim /etc/hosts 添加用户 useradd -m -g users -G wheel,storage,power -s /bin/bash x14n EDITOR=vim visudo 在文件中取消%wheel ALL=(ALL:ALL) 的 #\n添加Defaults rootpw\n安装系统引导工具grub, 并生成引导文件 pacman -S os-prober ntfs-3g grub efibootmgr # 这里的/dev/sda1是前面boot所在的分区 #grub-install --efi-directory=/mnt/boot/efi --bootloader-id=Arch --recheck grub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=grub # 生成默认配置文件 grub-mkconfig -o /boot/grub/grub.cfg 安装基础包 pacman -S networkManager systemctl disable netctl systemctl enable NetworkManager pacman -S mtools dosfstools bluez bluez-utils cups xdg-utils xdg-user-dirs alsa-utils pulseaudio pulseaudio-bluetooth reflector openssh pacman -S xf86-video-intel mesa lib32-mesa 基础配置 修改**/etc/pacman.conf**，在文件最后添加如下内容：\n[archlinuxcn] Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch 然后是更新源及安装yay：\npacman -Syyu //更新源，期间会自动下载archlinuxcn的源数据库 pacman -S yay //安装yay pacman -S archlinuxcn-keyring //archlinuxcn相关GPG key，如果不安装这个包会导致后续部分包无法成功安装 i配置 pacman -S xorg-server //sddm安装，如果通过startx命令登录i3wm也可不安装此项 pacman -S sddm //i3wm安装 pacman -S i3wm //或者安装i3gaps，二选一 yay -S i3-gaps //picom、rofi及feh pacman -S rofi picom feh 终端应用\npacman -S alacritty 安装字体文件\npacman -S noto-fonts-cjk powerline-fonts wqy-microhei adobe-source-code-pro-fonts yay -S ttf-apple-emoji 安装字体之后，可以通过如下命令查看系统中安装的字体信息：\nfc-cat | less 安装完成之后启动SDDM，应该就能通过图形化界面进行登录了：\nsystemctl enable sddm systemctl start sddm i3wm配置 i3wm默认的快捷键我不打算一一列出了，查看i3wm的默认配置文件就能看到，i3wm默认配置文件地址：\n~/.config/i3/config 如果此配置文件不存在，或者被修改出错，可以通过如下命令复制一份新的：\nmkdir ~/.config/i3 cp /etc/i3/config ~/.config/i3/config i3wm的配置文件分为两步，分别是修改原有配置及新增配置。\n先是修改原有配置，下列部分是删除或者注释：\n#font pango:monospace 8 #bindsym $mod+d exec --no-startup-id dmenu #bar { # status_command i3status #} 然后是新增部分配置：\n//设置字体及字体大小 font pango:Source Code Pro 12,DejaVu Sans Mono 12 //设置$MOD+d为启动rofi bindsym $mod+d exec --no-startup-id \u0026#34;rofi -modi drun,run -show drun\u0026#34; //启动picom exec --no-startup-id picom -b //使用feh设置壁纸，注意壁纸文件必须存在且路径正确 exec --no-startup-id feh --bg-scale ~/zocoxx/wallpaper.jpeg //锁屏，因Win+L快捷键在i3wm默认被占用，我设置的是$MOD+Ctrl+l为锁屏快捷键 bindsym $mod+Ctrl+l exec --no-startup-id i3lock //去除窗口的标题栏，有利有弊，好处是窗口少了额头，坏处是去除标题栏之后部分窗口无法进行鼠标拖动 for_window [class=\u0026#34;^.*\u0026#34;] border pixel 0 //设置边框为1像素 new_window pixel 1 //如果安装了输入法，可以使用此命令进行启动输入法 exec --no-startup-id fcitx \u0026amp; 配置完成之后，按$MOD+Shift+r可以快速重启i3wm，如果配置没问题的话，可以看到新的效果了。\nalacritty配置 选择alacritty就是看重其可定制，自然不会选择默认配置了。\nalacritty可选配置文件路径有很多，为了方便，我选择将配置文件放到~/.config目录里面。完整配置文件内容如下：\n# ~/.config/alacritty.yml font: normal: family: Source Code Pro bold: family: Source Code Pro italic: family: Source Code Pro size: 12 window: opacity: 0.7 env: TERM: xterm-256color 我选择配置alacritty使用Source Code Pro字体，且字号大小为12。\n特别提醒一下，alacritty背景透明度设置不是网络流传的window.opacity或者background_opacity，要设置透明度的话建议参考我上述的格式。\n保存即可看到效果。\npolybar设置及启动 polybar需要有默认的配置文件才能启动，所以，创建目录并设置配置文件：\nmkdir ~/.config/polybar cp /etc/polybar/config.ini ~/.config/polybar 不知道是polybar更新版本之后配置文件名称改变还是网上的教程以讹传讹，很多都不带**.ini**后缀，这里建议带上。\n上述config.ini默认包含了一个example的配置，命令行执行如下命令即可看到效果：\npolybar example 要在启动i3wm之后默认启动polybar，需要有个启动脚本，文件名称、路径及内容如下：\n# ~/.config/polybar/launch.sh #!/bin/bash # 终端可能已经有在运行的实例 killall -q polybar # 等待进程被终止 while pgrep -u $UID -x polybar \u0026gt;/dev/null; do sleep 1; done # 运行Polybar，使用默认的配置文件路径 ~/.config/polybar/config.ini polybar example \u0026amp; echo \u0026#34;Polybar launched...\u0026#34; 然后给与启动脚本可执行权限：\nchmod +x ~/.config/polybar/launch.sh 然后i3wm配置文件新加一行：\n# ~/.config/i3/config exec --no-startup-id ~/.config/polybar/launch.sh sudo systemctl restart display-manager\ni3-msg restart\n安装完成后配置 xorg-xrandr 分辨率调整\nxrandr --output your_display_name --mode 1600x900 xrandr --output eDP1 --scale 1.25x1.25 安装中文输入法 配置中文输入法首先需要安装 fcitx 包与 fcitx-im 集合包，还有配置工具 fcitx-configtool：\n1 $ sudo pacman -S fcitx fcitx-im fcitx-configtool 然后编辑 /etc/profile 文件，末尾加入：\n1234 # Fcitxexport GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport XMODIFIERS=\u0026quot;@im=fcitx\u0026quot; 再到Fcitx#中文选择一个中文输入法包安装：\n1 $ sudo pacman -S fcitx-googlepinyin zsh 1、安装zsh\nsudo pacman -S zsh 2、更改默认终端\nchsh -s /bin/zsh 3、安装oh-my-zsh-git\nsudo pacman -S oh-my-zsh-git 4、默认配置\ncp /usr/share/oh-my-zsh/zshrc ~/.zshrc 5、安装插件 跳转目录、命令高亮、自动建议补全\nsudo pacman -S autojump zsh-syntax-highlighting zsh-autosuggestions oh-my-zsh 找不到插件路径，做下链接 没有目录自己建 mkdir -p /usr/share/oh-my-zsh/custom/plugins/\nsudo ln -s /usr/share/zsh/plugins/zsh-syntax-highlighting /usr/share/oh-my-zsh/custom/plugins/ sudo ln -s /usr/share/zsh/plugins/zsh-autosuggestions /usr/share/oh-my-zsh/custom/plugins/ 6、配置 ~/.zshrc\nplugins=( git autojump zsh-syntax-highlighting zsh-autosuggestions ) Xresources sddm https://github.com/MarianArlt/sddm-chili\nneovim https://taoshu.in/vim/go-vim.html\nHIDPI屏幕 polybar 使用github主题hack\nmpd brightness volume speed battery temperature\nhtop资源监控 管理配置\nrander 文件窗口 https://wiki.archlinux.org/title/ranger\n生成配置文件\nranger --copy-config=all 了解一些基本的 python 知识可能对定制 ranger 会有帮助。\nrc.conf - 选项设置和快捷键 commands.py - 能通过 : 执行的命令 rifle.conf - 指定不同类型的文件的默认打开程序。 scope.sh - 文件预览相关配置 图片预览功能\npacman -S w3m #图片预览工具 移动到回收站 如果想添加一个把文件移动到目录 ~/.local/share/Trash/files/ 的快捷键 DD，把以下这一行添加到 ~/.config/ranger/rc.conf：\nmap DD shell mv %s /home/${USER}/.local/share/Trash/files/ 关联文件打开应用\n文件解压\n锁屏电源 rofi 设置默认应用 粘贴板copyq 音量调节ALSA sudo pacman -S alsa-utils\nsudo pacman -S alsa-plug\nsudo pacman -S pulseaudio-alsa\nsudo pacman -S pavucontrol-qt\nsudo pacman -S pavucontrol\n启用：amixer sset Master unmute\nsudo lspci -v\nlspci | grep Audio\nmpd音乐播放器 常用快捷键\nq ： 退出 ranger\rR : 重新刷新目录\rS : 执行 shell 命令\r: 或者 ; : 控制台\rW : 显示日志\rk : 向上\rj : 向下\rh : 向左\rl : 向右\rg : 到顶部\rG : 到底部\rJ : 半页向下\rK : 半页向上\rgh : 相当于 cd ~\rge : 相当于 cd /etc\rgu : cd /usr\rdd : 剪切\ryy : 复制\rpp : 粘贴\r截图工具 多屏幕显示 xrandr --output HDMI-1 --auto --left-of DP-1 在 i3wm 中配置多屏显示通常需要一些特定的设置。以下是在 Arch Linux 上配置 i3wm 的多屏显示的一般步骤：\n检测和识别显示器： 打开终端并运行以下命令，以检测和识别连接的显示器：\nxrandr 这将列出所有已连接的显示器以及它们的名称（例如：HDMI-1、DP-1 等）。\n配置显示器布局： 使用 xrandr 命令来配置显示器布局。例如，如果你想将两个显示器设置为左右扩展模式，可以运行：\nxrandr --output HDMI-1 --auto --left-of DP-1 打开 `~/.config/i3/config` 文件，添加以下行来配置多屏显示： exec --no-startup-id xrandr --output HDMI-1 --auto --left-of DP-1 exec --no-startup-id xrandr --output HDMI-1 --auto --right-of DP-1 设置屏幕\nxrandr --output HDMI-1 --mode 1920x1080 --scale 0.95x0.95 ","permalink":"https://XianCH.github.io/posts/tech/archlinux/archlinux%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8Ai3wm%E9%85%8D%E7%BD%AE/","summary":"arch安装以及i3wm配置 配置： intel 硬盘处理 lsblk 查看硬盘情况（sda 为机械硬盘，nvme0n1是固态，这里的sda 是u盘) cgdisk /dev/nvme0n1 用于分区表编辑和管理的命令行工具，主要用于处理磁盘的分区表，可以使用cgdisk来创建新的GPT分区表，这将抹去旧的分区表和数据，所以务必谨慎操作 ef00 boot 8200 swap 格","title":"arch安装以及i3wm配置"},{"content":"tmux常用命令 终端中使用 Tmux 命令 启动 tmux 使用 -s 命令指定会话名称，使用 -n 命令指定窗口名称 $ tmux new -s sessionName -n window 退出会话(tmux会话内命令) $ tmux detach 退出并关闭会话（窗口,窗格） $ exit 结束后台的会话 #通过会话编号 $ tmux kill-session -t 0 #通过会话名称 $ tmux kill-session -t sessionName 查看所有会话 $ tmux ls 激活会话 $ tmux attach -t sessionName Tmux 内使用前缀 Ctrl+b 然后对应快捷键执行命令 会话常用快捷操作 快捷键 说明 ? 所有快捷键，q退出 :new sessionName 创建新会话 s 切换会话 $ 重命名当前会话 d 离开会话返回shell（与tmux detach功能相同） Ctrl+z 挂起会话，返回shell 窗口常用快捷操作 快捷键 说明 c 创建新窗口 w 显示窗口 数字键 选择对应窗口 p 前一个窗口 n 后一个窗口 f 查找窗口 , 重命名窗口 \u0026amp; 关闭窗口（带提示） 窗格常用快捷键 快捷键 说明 % 垂直分割 ” 水平分割 o 切换窗格 x 关闭窗格 space 切换窗格布局 q 显示窗格编号，按对应数字选择窗格 { 与上一个窗格调换位置 } 与下一个窗格调换位置 z 当前窗格最大化 ! 取消所有窗口保留当前窗口 Ctrl+方向键 以1个单元格为单位移动边缘以调整当前窗格大小 Alt+方向键 以5个单元格为单位移动边缘以调整当前窗格大小 vim 使用技巧 [#](https://pengfeixc.com/blogs/developer-handbook/vim-shortcuts#vim 使用技巧) 下面的命令是我常用的一些快捷键操作，我使用的编辑器是 vscode，安装了 vim 插件。\n如何在 vscode 中使用 vim？可以看看我的 vscode 配置\n光标移动 # hjkl：左下上右 gj 和 gk：移动至下一个或者上一个物理行，当一行出现 linewrap 时，使用 j 和 k 并不能按照视觉看到的一行进行移动 {：跳转至向上寻找的第一个段落首部的前一行 }：跳转至向下寻找的第一个段落尾部的后一行 (：跳转至向上寻找的第一个段落首部的所在行 )：跳转至向下寻找的第一个段落尾部的所在行 w：下一个单词开头 b：上一个单词开头 e：下一个单词结尾 ge：上一个单词结尾 gg：跳转到第一行 G：跳转到最后一行 \u0026lt;number\u0026gt; + gg：跳转到第 number 行 :\u0026lt;number\u0026gt;：跳转到第 number 行 %：匹配对应括号，并进行跳转 * 和 #：匹配当前光标所在的单词，移动光标到下一个或上一个 f、F、 t 和 T，行内光标跳转 [#](https://pengfeixc.com/blogs/developer-handbook/vim-shortcuts#f、F、 t 和 T，行内光标跳转) f：当前行跳转到光标后的指定字符，按 ; 跳转到下一个指定字符 F：当前行跳转到光标前的指定字符，按 ; 跳转到下一个指定字符 t：当前行跳转到光标后的指定字符前的一个字符，按 ; 跳转到下一个指定字符前一个字符 T：当前行跳转到光标前的指定字符后的一个字符，按 ; 跳转到下一个指定字符后一个字符 一般，我只用 f 和 F。\n模式切换 # v：normal 模式进入 visual 模式 V: normal 模式进入 visual 模式，并选中当前行 i: normal 模式进入 insert 模式，光标出现在当前选中字符前 I: normal 模式进入 insert 模式，光标出现在行首 a: normal 模式进入 insert 模式，光标出现在当前选中字符后 A: normal 模式进入 insert 模式，光标出现在行尾 esc: 从 visual 和 insert 模式退回到 normal 模式 o：在当前行下方插入一行，并进入 insert 模式 O：在当前行上方插入一行，并进入 insert 模式\n插入、删除、复制、粘贴 # 在模式切换中已经包含了插入的相关快捷键。\ngi：在上一个做出变化的地方进入插入模式 x：删除当前光标所在的字符 dd：删除当前行 cc：删除当前行，并进入 insert 模式 D：删除从当前光标至行尾的内容 C：删除从当前贯标至行尾的内容，并进入 insert 模式 yy：复制当前行 Y：与 yy 相同 yl：复制当前光标下的字符 yas：复制一个句子 yap：复制一个段落 p: 粘贴剪切板至光标后 P：粘贴剪切板至光标前 gP: 与 P 相同，只不过将光标置于粘贴内容的后面 gp: 与 p 相同，只不过将光标置于粘贴内容的后面 cw：删除从光标所在位置后到一个单词的结尾，并进入 insert 模式（同理可以用 dw 删除，但是不进入 insert 模式） c$：删除从光标所在位置后到本行结尾，并进入 insert 模式（同理可以用 d$ 删除，但是不进入 insert 模式） r：替换当前光标下的字符，按下 r，然后输入一个字符，用来替换当前字符 v + \u0026lt;select area\u0026gt; + \u0026lt;action\u0026gt;：可以使用 v 进入 visual 模式，然后选中区域，最后使用 y、c、d 和 r 对选中区域进行操作。 \u0026lt;command\u0026gt;\u0026lt;pos\u0026gt; 模式：\u0026lt;command\u0026gt; 可以是 y、d、c等，（可以用于光标跳转的一系列字符） 可以是 w（一个单词的结尾）、$（行尾）、^（行首第一个非空字符）、b（单词的开头）、0(行首) 等等。\n\u0026lt;verbs\u0026gt;\u0026lt;adjectives\u0026gt;\u0026lt;objects\u0026gt; 模式：你可以将 operator（y，d，c）作为 verbs，count、a 和 i 作为 adjectives，移动（hjkl、w、$、^、b、0等）作为 objects，例如:\nd3l: 删除光标右侧三个字符 dl：adjectives 可以省略，所以 dl 等价于 d1l diw：删除光标下的单词不包括周围的空格 代码折叠 # zc：折叠代码 zo: 展开代码 zM: 全部折叠 zR: 全部展开 窗口移动 # （1）移动当前所在行的位置\nzz：将当前光标所在行移动到窗口中间 zt: 将当前光标所在行移动到窗口顶部 zb: 将当前光标所在行移动到窗口底部 （2）行移动\nctrl + e：一行一行向下移动 ctrl + d：向下移动窗口显示行数的一半 ctrl + y: 一行一行向上移动 ctrl + u: 向上移动窗口显示行数的一半 分屏操作 # （1）创建分屏\n使用命令：\n:split [file] 或者 :sp [file]：添加一个横屏 :vsplit [file] 或者 :vsp [file]：添加一个竖屏\n使用快捷键：\nctrl + w s：以当前文件添加一个横屏 ctrl + w v：以当前文件添加一个竖屏\n（2）分屏切换\nctrl + w \u0026lt;arrow\u0026gt; 或者 ctrl + w \u0026lt;hjkl\u0026gt; ：将光标移动到指定方向的分屏\n（3）关闭屏幕和分屏\n:only：只保留当前分屏，关闭其他分屏 ctrl + w c：关闭当前窗口 ctrl + w q: 关闭当前窗口，若只有一个分屏，则退出 vim ctrl + w o: 关闭其他窗口\n（4）增加屏幕高度\ncrtrl + w +：增加高度 ctrl + w -：减小高度\n多光标操作（块操作） # 使用 ctrl + v 进入块操作 可以使用 hkjl、$ 等来插入多光标和移动光标 使用 I 和 A 进入编辑 同样可以使用 v 进入 visual 模式，选中一些行，然后按 A 在每行结尾插入光标进行编辑。\nvisual 模式下的格式化操作 [#](https://pengfeixc.com/blogs/developer-handbook/vim-shortcuts#visual 模式下的格式化操作) v 进入 visual 模式，进入 visual 模式后，可以通过 hjkl 选中一些行。可以对选中的行做如下操作。\nJ：把所有行连接起来变成一行 \u0026lt; 或 \u0026gt;：左右缩进 =：自动缩进，格式化代码（非常 nice） 查找和替换 # 替换格式如下，支持正则表达式。\n:[range]s/\u0026lt;pattern\u0026gt;/[string]/[flags] [count] 该命令表示在 range 的每一行中搜索pattern，并将其替换为 string。 count是一个乘以命令的正整数。\n（1）查找\n/\u0026lt;pattern\u0026gt;：高亮查找到的内容 /\\C\u0026lt;pattern\u0026gt;：大小写敏感 /\\c\u0026lt;pattern\u0026gt;: 忽略大小写 /\\\u0026lt;\u0026lt;pattern\u0026gt;\\\u0026gt;: 整词匹配，注意这里前面是修饰符 \\\u0026lt;，后面是修饰符 \\\u0026gt;，两个组合表示整词匹配（whole word match） *：向下查找当前光标下的 word #：向上查找当前光标下的 word n：跳转到下一个查找到的内容 :nohl：取消高亮 （2）当前行替换\n:s/foo/bar/`：替换当前行查到的**第一个** `foo`，并将其替换为 `bar` `:s/foo/bar/g`：替换当前行查到的所有 `foo`，并将其替换为 `bar （3）全文件替换\n:%s/foo/bar/`：替换当前文件中所有行的**第一个** `foo`，将它们替换为 `bar` `:%s/foo/bar/g`：替换当前文件中所有行的 `foo`，将它们替换为 `bar （4）c flag\n:%s/foo/bar/gc使用 c 标记可以依次确认每个替换。会弹出 replace with foo(y/n/a/q/l)? 确认对话框，按 y 替换匹配项，或按 l 替换匹配项并退出。 按 n 跳过当前匹配，按 q 或 Esc 退出替换。 a 选项替换匹配项和所有剩余匹配项。\n（5）i flag 开启大小写敏感\n:s/foo/bar/gc`: `foo` 不会匹配 `Foo （6）指定查询范围\n:3,10s/foo/bar/g：查询范围为第三行到第十行，将该范围内的 foo 替换为 bar :.,$s/foo/bar/：查询范围为当前行到最后一行，将该范围内的 foo 替换为 bar，. 表示当前行，$ 表示最后一行 :.,+4s/foo/bar/g：查询范围为从当前行开始往下数四行（总共四行），将该范围内的 foo 替换为 bar，. 表示当前行，+4 表示接下来的四行\n\u0026lt;start position\u0026gt;\u0026lt;command\u0026gt;\u0026lt;end position\u0026gt; # 例如 0y$，表示拷贝当前行。\n0：先到行首 y: 从 \u0026lt;start position\u0026gt; 开始拷贝，这里是行首 $：表示一直拷贝到行尾 \u0026quot; hello \u0026quot;\n\u0026lt;command\u0026gt;\u0026lt;a | i | s\u0026gt;\u0026lt;obj\u0026gt; # s 需要插件支持，vscode-vim 自带这个功能\na 表示 around，i 表示 inner，s 表示 surround，command 可以是 d c y，obj 可以是引号、双引号、w 和 t，t 表示 tag，对 html 这种标记语言比较有用\ndiw：删除单词，不包括单词周围的符号，例如 \u0026quot; word \u0026quot;，光标在 w,删除后变成了 \u0026quot; \u0026quot; daw：删除当前单词，包括周围的空白字符，例如 \u0026quot; word \u0026quot;，光标在 w,删除后变成了 \u0026quot;\u0026quot; da\u0026quot;: 删除双引号中间的内容，包括双引号本身，例如 \u0026quot; word \u0026quot;，光标在 w,删除后变成了 `` di\u0026quot;: 删除双引号中间的内容，不包括双引号本身，例如 \u0026quot; word \u0026quot;，光标在 w,删除后变成了 \u0026quot;\u0026quot; ds\u0026quot;：删除当前单词周围的双引号，例如 \u0026quot; word \u0026quot;，光标在 w,删除后变成了 w 如果把上面的 command d 换成 c，那么删除后会进入到插入模式。\ns` 对写 html 这种标记语言非常有用，例如将下面的 `div` 改成 `p`，可以使用 `cstt`，然后输入 `p`，`c` 表示 `change \u0026lt;div\u0026gt; 这是一个段落 \u0026lt;/div\u0026gt; i3 wm ","permalink":"https://XianCH.github.io/posts/tech/tool/%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/","summary":"tmux常用命令 终端中使用 Tmux 命令 启动 tmux 使用 -s 命令指定会话名称，使用 -n 命令指定窗口名称 $ tmux new -s sessionName -n window 退出会话(tmux会话内命令) $ tmux detach 退出并关闭会话（窗口,窗格） $ exit 结束后台的会话 #通过会话编号 $ tmux kill-session -t 0 #通过会话名称 $ tmux kill-session -t sessionName 查看所有会话 $ tmux ls 激活会话 $ tmux attach -t sessionName Tmux 内使用前缀 Ctrl+b 然","title":"常用快捷键"},{"content":"这个是elon发布的架构图\n因为很多字看不清我在twitter上找了位架构师alex xu整理的图 https://twitter.com/alexxubyte/status/1594008281340530688\n1，首先对安卓和iphone用户做了不同的处理，可以说这两个系统是两个应用把，安卓系统是一个原生应用程序，这意味着它是专门为安卓操作系统编写的应用程序，能够直接访问设备硬件和系统资源，安卓用户拥有更高的性能和体验。而 iphone版 twitter感觉就是像是网站web端吧，，它需要依赖浏览器来加载和渲染内容，相对于原生应用程序，它可能会具有一些限制和性能上的劣势。如果twitter的ui代码出问题了，安卓用户应该会直接收到报错吧，这里都针对不同系统的用户有不同的拦截器吧。\n他们两个用到访问数据的方式不一样安卓用TLS API，TLS 是一种安全协议，可以很好的保护互联网中的安全信息，安全性相对高，缺点应该就是性能开销大吧，iphone用户用的是GraphQL是一种数据查询语言，可以精确的获取指定的资源，减少服务端响应的数量，提高性能和数量。\n2，Timeline Mixer这个模块根据用户向外输出的数据做获取，处理用户的时间线数据，用户时间线数据应该是指用户在Twitter上发布的推文(Tweet转发回复等内容组成的时间序列。在twitter中，每个用户都有自己的时间线，根据用户关注了谁，点进了什么广告，评论过的推文，发布过的推文做分析。这里的onboarding我不是很清楚什么意思。cursoring | pagination 通过cusoring 分页技术提高查询用户的时间线数据。tweet deduplication处理时间线数据的去重，避免同一条推文在用户时间线中出现多次。served data logging记录数据查询和处理的日志信息，以便后续的数据分析和性能优化。最后在把收集的信息提供给”用户发现用户“，”广告推送“，”用户引导“等服务\n3，Home Mixer主要负责为用户推荐相关的内容，包括主页上显示的推文、热门话题、推荐用户等。通过分析用户的社交关系、兴趣爱好、历史行为等信息，为用户推荐适合的内容。混合在一起，生成用户的个性化主页\n4,timeline mixer和home mixer的数据传到homeranker中，然后它为用户个性化地排序和推荐主页上显示的内容，包括推文、热门话题、推荐用户等。感觉homeranker是个很复杂的算法模型\n5,感觉这是机械学系的领域了，homeranker通过某种算法得到homescorer ，而 feature hydration 则是指将这些提取出来的特征与相应的推文信息进行关联，数据会从存储在 memcache 中的缓存中，后期计算的时可以使用？。Home Scorer 会将计算得分后的数据发送到 Manhattan \u0026hellip;.\n","permalink":"https://XianCH.github.io/posts/tech/other/%E5%85%B3%E4%BA%8Etwitter%E6%9E%B6%E6%9E%84%E5%9B%BE%E7%9A%84%E6%80%9D%E8%80%83/","summary":"这个是elon发布的架构图 因为很多字看不清我在twitter上找了位架构师alex xu整理的图 https://twitter.com/alexxubyte/status/1594008281340530688 1，首先对安卓和iphone用户做了不同的处理，可以说这两个系统是两个应用把，安卓系统是一个原生应用程序，这意味着它是专门为安卓操作系统编写的应用程序，能够直接访问设备硬件和系统资源，","title":"关于twitter架构图的思考"},{"content":"异常 常见异常：\nIOException,NullPointerException,IndexOutOfBoundsException,SQLException,ArithmeticException\n","permalink":"https://XianCH.github.io/posts/tech/java/java%E5%A4%8D%E4%B9%A0/","summary":"异常 常见异常： IOException,NullPointerException,IndexOutOfBoundsException,SQLException,ArithmeticException","title":"java基础复习"},{"content":"包含的模块 十九个模块，分别是： Java 基础、容器、多线程、反射、对象拷贝、Java Web 、异常、网络、设计模式、 Spring/Spring MVC、Spring Boot/Spring Cloud、Hibernate、MyBatis、RabbitMQ、Kafka、Zookeeper、 MySQL、Redis、JVM ，如下图所示：\nJava 基础 1. JDK 和 JRE 有什么区别？ JDK：Java Development Kit 的简称，Java 开发工具包，提供了 Java 的开发环境和运行环境。 JRE：Java Runtime Environment 的简称，Java 运行环境，为 Java 的运行提供了所需环境。 具体来说 JDK 其实包含了 JRE，同时还包含了编译 Java 源码的编译器 Javac，还包含了很多 Java 程序调试和分析的 工具。简单来说：如果你需要运行 Java 程序，只需安装 JRE 就可以了，如果你需要编写 Java 程序，需要安装 JDK。\n2. == 和 equals 的区别是什么？ == 解读 对于基本类型和引用类型 == 的作用效果是不同的，如下所示： 基本类型：比较的是值是否相同； 引用类型：比较的是引用是否相同； 代码示例： String x = \u0026#34;string\u0026#34;; String y = \u0026#34;string\u0026#34;; String z = new String(\u0026#34;string\u0026#34;); System.out.println(x==y); // true System.out.println(x==z); // false System.out.println(x.equals(y)); // true System.out.println(x.equals(z)); // true 代码解读：因为 x 和 y 指向的是同一个引用，所以 == 也是 true，而 new String()方法则重写开辟了内存空间，所以 == 结果为 false，而 equals 比较的一直是值，所以结果都为 true。\nequals 解读\nequals 本质上就是 ==，只不过 String 和 Integer 等重写了 equals 方法，把它变成了值比较。看下面的代码就明白 了。\n首先来看默认情况下 equals 比较一个有相同值的对象，代码如下：\nString x = \u0026#34;string\u0026#34;; String y = \u0026#34;string\u0026#34;; String z = new String(\u0026#34;string\u0026#34;); System.out.println(x==y); // true System.out.println(x==z); // false System.out.println(x.equals(y)); // true System.out.println(x.equals(z)); // true class Cat { public Cat(String name) { this.name = name; } private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } } Cat c1 = new Cat(\u0026#34;王磊\u0026#34;); Cat c2 = new Cat(\u0026#34;王磊\u0026#34;); System.out.println(c1.equals(c2)); // false 输出结果出乎我们的意料，竟然是 false？这是怎么回事，看了 equals 源码就知道了，源码如下：\n原来 equals 本质上就是 ==。\n那问题来了，两个相同值的 String 对象，为什么返回的是 true？代码如下：\n同样的，当我们进入 String 的 equals 方法，找到了答案，代码如下：\n原来是 String 重写了 Object 的 equals 方法，把引用比较改成了值比较。\n总结 ：== 对于基本类型来说是值比较，对于引用类型来说是比较的是引用；而 equals 默认情况下是引用比较，只 是很多类重新了 equals 方法，比如 String、Integer 等把它变成了值比较，所以一般情况下 equals 比较的是值是否 相等。\n3. 两个对象的 hashCode() 相同，则 equals() 也一定为 true，对吗？ 不对，两个对象的 hashCode() 相同，equals() 不一定 true。\n代码示例：\npublic boolean equals(Object obj) { return (this == obj); } String s1 = new String(\u0026#34;老王\u0026#34;); String s2 = new String(\u0026#34;老王\u0026#34;); System.out.println(s1.equals(s2)); // true public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0 ; while (n-- != 0 ) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false; } 执行的结果： 代码解读：很显然“通话”和“重地”的 hashCode() 相同，然而 equals() 则为 false，因为在散列表中，hashCode() 相 等即两个键值对的哈希值相等，然而哈希值相等，并不一定能得出键值对相等。\n4. final 在 Java 中有什么作用？ final 修饰的类叫最终类，该类不能被继承。 final 修饰的方法不能被重写。 final 修饰的变量叫常量，常量必须初始化，初始化之后值就不能被修改。 5. Java 中的 Math. round(-1. 5) 等于多少？ 等于 -1，因为在数轴上取值时，中间值（0.5）向右取整，所以正 0.5 是往上取整，负 0.5 是直接舍弃。 6. String 属于基础的数据类型吗？ String 不属于基础类型，基础类型有 8 种：byte、boolean、char、short、int、float、long、double，而 String 属于对象。\n7. Java 中操作字符串都有哪些类？它们之间有什么区别？ 操作字符串的类有：String、StringBuffer、StringBuilder。\nString 和 StringBuffer、StringBuilder 的区别在于 String 声明的是不可变的对象，每次操作都会生成新的 String 对 象，然后将指针指向新的 String 对象，而 StringBuffer、StringBuilder 可以在原有对象的基础上进行操作，所以在 经常改变字符串内容的情况下最好不要使用 String。\nStringBuffer 和 StringBuilder 最大的区别在于，StringBuffer 是线程安全的，而 StringBuilder 是非线程安全的，但 StringBuilder 的性能却高于 StringBuffer，所以在单线程环境下推荐使用 StringBuilder，多线程环境下推荐使用 StringBuffer。\n8. String str=\u0026ldquo;i\u0026quot;与 String str=new String(\u0026ldquo;i\u0026rdquo;)一样吗？ 不一样，因为内存的分配方式不一样。String str=\u0026ldquo;i\u0026quot;的方式，Java 虚拟机会将其分配到常量池中；而 String str=new String(\u0026ldquo;i\u0026rdquo;) 则会被分到堆内存中。\n9. 如何将字符串反转？ 使用 StringBuilder 或者 stringBuffer 的 reverse() 方法。\n示例代码：\nString str1 = \u0026#34;通话\u0026#34;; String str2 = \u0026#34;重地\u0026#34;; System. out. println(String. format(\u0026#34;str1：%d | str2：%d\u0026#34;, str1. hashCode(),str2. hashCode())); System. out. println(str1. equals(str2)); str1： 1179395 | str2： 1179395 false 10. String 类的常用方法都有那些？ indexOf()：返回指定字符的索引。 charAt()：返回指定索引处的字符。 replace()：字符串替换。 trim()：去除字符串两端空白。 split()：分割字符串，返回一个分割后的字符串数组。 getBytes()：返回字符串的 byte 类型数组。 length()：返回字符串长度。 toLowerCase()：将字符串转成小写字母。 toUpperCase()：将字符串转成大写字符。 substring()：截取字符串。 equals()：字符串比较。 11. 抽象类必须要有抽象方法吗？ 不需要，抽象类不一定非要有抽象方法。 示例代码： 上面代码，抽象类并没有抽象方法但完全可以正常运行。 12. 普通类和抽象类有哪些区别？ 普通类不能包含抽象方法，抽象类可以包含抽象方法。 抽象类不能直接实例化，普通类可以直接实例化。 13. 抽象类能使用 final 修饰吗？ 不能，定义抽象类就是让其他类继承的，如果定义为 final 该类就不能被继承，这样彼此就会产生矛盾，所以 final 不 能修饰抽象类，如下图所示，编辑器也会提示错误信息：\n// StringBuffer reverse StringBuffer stringBuffer = new StringBuffer(); stringBuffer. append(\u0026#34;abcdefg\u0026#34;); System. out. println(stringBuffer. reverse()); // gfedcba // StringBuilder reverse StringBuilder stringBuilder = new StringBuilder(); stringBuilder. append(\u0026#34;abcdefg\u0026#34;); System. out. println(stringBuilder. reverse()); // gfedcba abstract class Cat { public static void sayHi() { System. out. println(\u0026#34;hi~\u0026#34;); } } 14. 接口和抽象类有什么区别？ 实现：抽象类的子类使用 extends 来继承；接口必须使用 implements 来实现接口。 构造函数：抽象类可以有构造函数；接口不能有。 main 方法：抽象类可以有 main 方法，并且我们能运行它；接口不能有 main 方法。 实现数量：类可以实现很多个接口；但是只能继承一个抽象类。 访问修饰符：接口中的方法默认使用 public 修饰；抽象类中的方法可以是任意访问修饰符。 15. Java 中 IO 流分为几种？ 按功能来分：输入流（input）、输出流（output）。\n按类型来分：字节流和字符流。\n字节流和字符流的区别是：字节流按 8 位传输以字节为单位输入输出数据，字符流按 16 位传输以字符为单位输入输 出数据。\n16. BIO、NIO、AIO 有什么区别？ BIO：Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力 低。 NIO：New IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路 复用。 AIO：Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调 机制。 17. Files的常用方法都有哪些？ Files. exists()：检测文件路径是否存在。 Files. createFile()：创建文件。 Files. createDirectory()：创建文件夹。 Files. delete()：删除一个文件或目录。 Files. copy()：复制文件。 Files. move()：移动文件。 Files. size()：查看文件个数。 Files. read()：读取文件。 Files. write()：写入文件。 容器 18. Java 容器都有哪些？ Java 容器分为 Collection 和 Map 两大类，其下又有很多子类，如下所示：\nCollection List ArrayList LinkedList Vector Stack Set HashSet LinkedHashSet TreeSet Map HashMap LinkedHashMap TreeMap ConcurrentHashMap Hashtable 19. Collection 和 Collections 有什么区别？ Collection 是一个集合接口，它提供了对集合对象进行基本操作的通用接口方法，所有集合都是它的子类，比 如 List、Set 等。 Collections 是一个包装类，包含了很多静态方法，不能被实例化，就像一个工具类，比如提供的排序方法： Collections. sort(list)。 20. List、Set、Map 之间的区别是什么？ List、Set、Map 的区别主要体现在两个方面：元素是否有序、是否允许元素重复。\n三者之间的区别，如下表：\n21. HashMap 和 Hashtable 有什么区别？ 存储：HashMap 运行 key 和 value 为 null，而 Hashtable 不允许。 线程安全：Hashtable 是线程安全的，而 HashMap 是非线程安全的。 推荐使用：在 Hashtable 的类注释可以看到，Hashtable 是保留类不建议使用，推荐在单线程环境下使用 HashMap 替代，如果需要多线程使用则用 ConcurrentHashMap 替代。 22. 如何决定使用 HashMap 还是 TreeMap？ 对于在 Map 中插入、删除、定位一个元素这类操作，HashMap 是最好的选择，因为相对而言 HashMap 的插入会 更快，但如果你要对一个 key 集合进行有序的遍历，那 TreeMap 是更好的选择。\n23. 说一下 HashMap 的实现原理？ HashMap 基于 Hash 算法实现的，我们通过 put(key,value)存储，get(key)来获取。当传入 key 时，HashMap 会根 据 key. hashCode() 计算出 hash 值，根据 hash 值将 value 保存在 bucket 里。当计算出的 hash 值相同时，我们称 之为 hash 冲突，HashMap 的做法是用链表和红黑树存储相同 hash 值的 value。当 hash 冲突的个数比较少时，使 用链表否则使用红黑树。\n24. 说一下 HashSet 的实现原理？ HashSet 是基于 HashMap 实现的，HashSet 底层使用 HashMap 来保存所有元素，因此 HashSet 的实现比较简 单，相关 HashSet 的操作，基本上都是直接调用底层 HashMap 的相关方法来完成，HashSet 不允许重复的值。\n25. ArrayList 和 LinkedList 的区别是什么？ 数据结构实现：ArrayList 是动态数组的数据结构实现，而 LinkedList 是双向链表的数据结构实现。 随机访问效率：ArrayList 比 LinkedList 在随机访问的时候效率要高，因为 LinkedList 是线性的数据存储方式， 所以需要移动指针从前往后依次查找。 增加和删除效率：在非首尾的增加和删除操作，LinkedList 要比 ArrayList 效率要高，因为 ArrayList 增删操作 要影响数组内的其他数据的下标。 综合来说，在需要频繁读取集合中的元素时，更推荐使用 ArrayList，而在插入和删除操作较多时，更推荐使用 LinkedList。\n26. 如何实现数组和 List 之间的转换？ 数组转 List：使用 Arrays. asList(array) 进行转换。 List 转数组：使用 List 自带的 toArray() 方法。 代码示例：\n27. ArrayList 和 Vector 的区别是什么？ 线程安全：Vector 使用了 Synchronized 来实现线程同步，是线程安全的，而 ArrayList 是非线程安全的。 性能：ArrayList 在性能方面要优于 Vector。 扩容：ArrayList 和 Vector 都会根据实际的需要动态的调整容量，只不过在 Vector 扩容每次会增加 1 倍，而 ArrayList 只会增加 50%。 28. Array 和 ArrayList 有何区别？ Array 可以存储基本数据类型和对象，ArrayList 只能存储对象。 Array 是指定固定大小的，而 ArrayList 大小是自动扩展的。 // list to array List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list. add(\u0026#34;王磊\u0026#34;); list. add(\u0026#34;的博客\u0026#34;); list. toArray(); // array to list String[] array = new String[]{\u0026#34;王磊\u0026#34;,\u0026#34;的博客\u0026#34;}; Arrays. asList(array); Array 内置方法没有 ArrayList 多，比如 addAll、removeAll、iteration 等方法只有 ArrayList 有。 29. 在 Queue 中 poll()和 remove()有什么区别？ 相同点：都是返回第一个元素，并在队列中删除返回的对象。 不同点：如果没有元素 poll()会返回 null，而 remove()会直接抛出 NoSuchElementException 异常。 代码示例：\n30. 哪些集合类是线程安全的？ Vector、Hashtable、Stack 都是线程安全的，而像 HashMap 则是非线程安全的，不过在 JDK 1.5 之后随着 Java. util. concurrent 并发包的出现，它们也有了自己对应的线程安全类，比如 HashMap 对应的线程安全类就是 ConcurrentHashMap。\n31. 迭代器 Iterator 是什么？ Iterator 接口提供遍历任何 Collection 的接口。我们可以从一个 Collection 中使用迭代器方法来获取迭代器实例。迭 代器取代了 Java 集合框架中的 Enumeration，迭代器允许调用者在迭代过程中移除元素。\n32. Iterator 怎么使用？有什么特点？ Iterator 使用代码如下：\nIterator 的特点是更加安全，因为它可以确保，在当前遍历的集合元素被更改的时候，就会抛出 ConcurrentModificationException 异常。\n33. Iterator 和 ListIterator 有什么区别？ Iterator 可以遍历 Set 和 List 集合，而 ListIterator 只能遍历 List。 Iterator 只能单向遍历，而 ListIterator 可以双向遍历（向前/后遍历）。 ListIterator 从 Iterator 接口继承，然后添加了一些额外的功能，比如添加一个元素、替换一个元素、获取前面 或后面元素的索引位置。 34. 怎么确保一个集合不能被修改？ 可以使用 Collections. unmodifiableCollection(Collection c) 方法来创建一个只读集合，这样改变集合的任何操作都 会抛出 Java. lang. UnsupportedOperationException 异常。\n示例代码如下：\nQueue\u0026lt;String\u0026gt; queue = new LinkedList\u0026lt;String\u0026gt;(); queue. offer(\u0026#34;string\u0026#34;); // add System. out. println(queue. poll()); System. out. println(queue. remove()); System. out. println(queue. size()); List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Iterator\u0026lt;String\u0026gt; it = list. iterator(); while(it. hasNext()){ String obj = it. next(); System. out. println(obj); } 多线程 35. 并行和并发有什么区别？ 并行：多个任务在同一个 CPU 核上，按细分的时间片轮流(交替)执行，从逻辑上来看那些任务是同时执行。 并发：多个处理器或多核处理器同时处理多个任务。 如下图： 并发 = 两个队列和一台咖啡机。 并行 = 两个队列和两台咖啡机。 36. 线程和进程的区别？ 一个程序下至少有一个进程，一个进程下至少有一个线程，一个进程下也可以有多个线程来增加程序的执行速度。 37. 守护线程是什么？ 守护线程是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。 在 Java 中垃圾回收线程就是特殊的守护线程。\n38. 创建线程有哪几种方式？ List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list. add(\u0026#34;x\u0026#34;); Collection\u0026lt;String\u0026gt; clist = Collections. unmodifiableCollection(list); clist. add(\u0026#34;y\u0026#34;); // 运行时此行报错 System. out. println(list. size()); 创建线程有三种方式： 继承 Thread 重新 run 方法； 实现 Runnable 接口； 实现 Callable 接口。 39. 说一下 runnable 和 callable 有什么区别？ runnable 没有返回值，callable 可以拿到有返回值，callable 可以看作是 runnable 的补充。\n40. 线程有哪些状态？ 线程的状态： NEW 尚未启动 RUNNABLE 正在执行中 BLOCKED 阻塞的（被同步锁或者IO锁阻塞） WAITING 永久等待状态 TIMED_WAITING 等待指定的时间重新被唤醒的状态 TERMINATED 执行完成 41. sleep() 和 wait() 有什么区别？ 类的不同：sleep() 来自 Thread，wait() 来自 Object。 释放锁：sleep() 不释放锁；wait() 释放锁。 用法不同：sleep() 时间到会自动恢复；wait() 可以使用 notify()/notifyAll()直接唤醒。 42. notify()和 notifyAll()有什么区别？ notifyAll()会唤醒所有的线程，notify()之后唤醒一个线程。notifyAll() 调用后，会将全部线程由等待池移到锁池，然 后参与锁的竞争，竞争成功则继续执行，如果不成功则留在锁池等待锁被释放后再次参与竞争。而 notify()只会唤醒 一个线程，具体唤醒哪一个线程由虚拟机控制。\n43. 线程的 run() 和 start() 有什么区别？ start() 方法用于启动线程，run() 方法用于执行线程的运行时代码。run() 可以重复调用，而 start() 只能调用一次。\n44. 创建线程池有哪几种方式？ 线程池创建有七种方式，最核心的是最后一种： newSingleThreadExecutor()：它的特点在于工作线程数目被限制为 1 ，操作一个无界的工作队列，所以它保证 了所有任务的都是被顺序执行，最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可 以避免其改变线程数目； newCachedThreadPool()：它是一种用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓 存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置的时间超过 60 秒，则被终止并移 出缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用 SynchronousQueue 作为工作队列； newFixedThreadPool(int nThreads)：重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列， 任何时候最多有 nThreads 个工作线程是活动的。这意味着，如果任务数量超过了活动队列数目，将在工作队 列中等待空闲线程出现；如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目 nThreads； newSingleThreadScheduledExecutor()：创建单线程池，返回 ScheduledExecutorService，可以进行定时或 周期性的工作调度； newScheduledThreadPool(int corePoolSize)：和newSingleThreadScheduledExecutor()类似，创建的是个 ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程； newWorkStealingPool(int parallelism)：这是一个经常被人忽略的线程池，Java 8 才加入这个创建方法，其内 部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序； ThreadPoolExecutor()：是最原始的线程池创建，上面1-3创建方式都是对ThreadPoolExecutor的封装。 45. 线程池都有哪些状态？ RUNNING：这是最正常的状态，接受新的任务，处理等待队列中的任务。 SHUTDOWN：不接受新的任务提交，但是会继续处理等待队列中的任务。 STOP：不接受新的任务提交，不再处理等待队列中的任务，中断正在执行任务的线程。 TIDYING：所有的任务都销毁了，workCount 为 0 ，线程池的状态在转换为 TIDYING 状态时，会执行钩子方法 terminated()。 TERMINATED：terminated()方法结束后，线程池的状态就会变成这个。 46. 线程池中 submit() 和 execute() 方法有什么区别？ execute()：只能执行 Runnable 类型的任务。 submit()：可以执行 Runnable 和 Callable 类型的任务。 Callable 类型的任务可以获取执行的返回值，而 Runnable 执行无返回值。\n47. 在 Java 程序中怎么保证多线程的运行安全？ 方法一：使用安全类，比如 Java. util. concurrent 下的类。 方法二：使用自动锁 synchronized。 方法三：使用手动锁 Lock。 手动锁 Java 示例代码如下：\n48. 多线程中 synchronized 锁升级的原理是什么？ synchronized 锁升级原理：在锁对象的对象头里面有一个 threadid 字段，在第一次访问的时候 threadid 为空，jvm 让其持有偏向锁，并将 threadid 设置为其线程 id，再次进入的时候会先判断 threadid 是否与其线程 id 一致，如果 一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次 数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。\n锁的升级的目的：锁升级是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏 向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。\nLock lock = new ReentrantLock(); lock. lock(); try { System. out. println(\u0026#34;获得锁\u0026#34;); } catch (Exception e) { // TODO: handle exception } finally { System. out. println(\u0026#34;释放锁\u0026#34;); lock. unlock(); } 49. 什么是死锁？ 当线程 A 持有独占锁a，并尝试去获取独占锁 b 的同时，线程 B 持有独占锁 b，并尝试获取独占锁 a 的情况下，就会 发生 AB 两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。\n50. 怎么防止死锁？ 尽量使用 tryLock(long timeout, TimeUnit unit)的方法(ReentrantLock、ReentrantReadWriteLock)，设置超 时时间，超时可以退出防止死锁。 尽量使用 Java. util. concurrent 并发类代替自己手写锁。 尽量降低锁的使用粒度，尽量不要几个功能用同一把锁。 尽量减少同步的代码块。 51. ThreadLocal 是什么？有哪些使用场景？ ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会 影响其它线程所对应的副本。\nThreadLocal 的经典使用场景是数据库连接和 session 管理等。\n52. 说一下 synchronized 底层实现原理？ synchronized 是由一对 monitorenter/monitorexit 指令实现的，monitor 对象是同步的基本实现单元。在 Java 6 之前，monitor 的实现完全是依靠操作系统内部的互斥锁，因为需要进行用户态到内核态的切换，所以同步操作是一 个无差别的重量级操作，性能也很低。但在 Java 6 的时候，Java 虚拟机 对此进行了大刀阔斧地改进，提供了三种不 同的 monitor 实现，也就是常说的三种不同的锁：偏向锁（Biased Locking）、轻量级锁和重量级锁，大大改进了 其性能。\n53. synchronized 和 volatile 的区别是什么？ volatile 是变量修饰符；synchronized 是修饰类、方法、代码段。 volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子 性。 volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。 54. synchronized 和 Lock 有什么区别？ synchronized 可以给类、方法、代码块加锁；而 lock 只能给代码块加锁。 synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；而 lock 需要自 己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。 55. synchronized 和 ReentrantLock 区别是什么？ synchronized 早期的实现比较低效，对比 ReentrantLock，大多数场景性能都相差较大，但是在 Java 6 中对 synchronized 进行了非常多的改进。\n主要区别如下：\nReentrantLock 使用起来比较灵活，但是必须有释放锁的配合动作； ReentrantLock 必须手动获取与释放锁，而 synchronized 不需要手动释放和开启锁； ReentrantLock 只适用于代码块锁，而 synchronized 可用于修饰方法、代码块等。 volatile 标记的变量不会被编译器优化；synchronized 标记的变量可以被编译器优化。 56. 说一下 atomic 的原理？ atomic 主要利用 CAS (Compare And Wwap) 和 volatile 和 native 方法来保证原子操作，从而避免 synchronized 的 高开销，执行效率大为提升。\n反射 57. 什么是反射？ 反射是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的 任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 Java 语言的反射机制。\n58. 什么是 Java 序列化？什么情况下需要序列化？ Java 序列化是为了保存各种对象在内存中的状态，并且可以把保存的对象状态再读出来。\n以下情况需要使用 Java 序列化：\n想把的内存中的对象状态保存到一个文件中或者数据库中时候； 想用套接字在网络上传送对象的时候； 想通过RMI（远程方法调用）传输对象的时候。 59. 动态代理是什么？有哪些应用？ 动态代理是运行时动态生成代理类。 动态代理的应用有 spring aop、hibernate 数据查询、测试框架的后端 mock、rpc，Java注解对象获取等。\n60. 怎么实现动态代理？ JDK 原生动态代理和 cglib 动态代理。JDK 原生动态代理是基于接口实现的，而 cglib 是基于继承当前类的子类实现 的。\n对象拷贝 61. 为什么要使用克隆？ 克隆的对象可能包含一些已经修改过的属性，而 new 出来的对象的属性都还是初始化时候的值，所以当需要一个新 的对象来保存当前对象的“状态”就靠克隆方法了。\n62. 如何实现对象克隆？ 实现 Cloneable 接口并重写 Object 类中的 clone() 方法。 实现 Serializable 接口，通过对象的序列化和反序列化实现克隆，可以实现真正的深度克隆。 63. 深拷贝和浅拷贝区别是什么？ 浅克隆：当对象被复制时只复制它本身和其中包含的值类型的成员变量，而引用类型的成员对象并没有复制。 深克隆：除了对象本身被复制外，对象所包含的所有成员变量也将复制。 Java Web 64. JSP 和 servlet 有什么区别？ JSP 是 servlet 技术的扩展，本质上就是 servlet 的简易方式。servlet 和 JSP 最主要的不同点在于，servlet 的应用逻 辑是在 Java 文件中，并且完全从表示层中的 html 里分离开来，而 JSP 的情况是 Java 和 html 可以组合成一个扩展名 为 JSP 的文件。JSP 侧重于视图，servlet 主要用于控制逻辑。\n65. JSP 有哪些内置对象？作用分别是什么？ JSP 有 9 大内置对象： request：封装客户端的请求，其中包含来自 get 或 post 请求的参数； response：封装服务器对客户端的响应； pageContext：通过该对象可以获取其他对象； session：封装用户会话的对象； application：封装服务器运行环境的对象； out：输出服务器响应的输出流对象； config：Web 应用的配置对象； page：JSP 页面本身（相当于 Java 程序中的 this）； exception：封装页面抛出异常的对象。 66. 说一下 JSP 的 4 种作用域？ page：代表与一个页面相关的对象和属性。 request：代表与客户端发出的一个请求相关的对象和属性。一个请求可能跨越多个页面，涉及多个 Web 组 件；需要在页面显示的临时数据可以置于此作用域。 session：代表与某个用户与服务器建立的一次会话相关的对象和属性。跟某个用户相关的数据应该放在用户自 己的 session 中。 application：代表与整个 Web 应用程序相关的对象和属性，它实质上是跨越整个 Web 应用程序，包括多个页 面、请求和会话的一个全局作用域。 67. session 和 cookie 有什么区别？ 存储位置不同：session 存储在服务器端；cookie 存储在浏览器端。 安全性不同：cookie 安全性一般，在浏览器存储，可以被伪造和修改。 容量和个数限制：cookie 有容量限制，每个站点下的 cookie 也有个数限制。 存储的多样性：session 可以存储在 Redis 中、数据库中、应用程序中；而 cookie 只能存储在浏览器中。 68. 说一下 session 的工作原理？ session 的工作原理是客户端登录完成之后，服务器会创建对应的 session，session 创建完之后，会把 session 的 id 发送给客户端，客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着 sessionid，服务器拿到 sessionid 之后，在内存找到与之对应的 session 这样就可以正常工作了。\n69. 如果客户端禁止 cookie 能实现 session 还能用吗？ 可以用，session 只是依赖 cookie 存储 sessionid，如果 cookie 被禁用了，可以使用 url 中添加 sessionid 的方式保 证 session 能正常使用。\n70. spring mvc 和 struts 的区别是什么？ 拦截级别：struts2 是类级别的拦截；spring mvc 是方法级别的拦截。 数据独立性：spring mvc 的方法之间基本上独立的，独享 request 和 response 数据，请求数据通过参数获 取，处理结果通过 ModelMap 交回给框架，方法之间不共享变量；而 struts2 虽然方法之间也是独立的，但其 所有 action 变量是共享的，这不会影响程序运行，却给我们编码和读程序时带来了一定的麻烦。 拦截机制：struts2 有以自己的 interceptor 机制，spring mvc 用的是独立的 aop 方式，这样导致struts2 的配 置文件量比 spring mvc 大。 对 ajax 的支持：spring mvc 集成了ajax，所有 ajax 使用很方便，只需要一个注解 @ResponseBody 就可以实 现了；而 struts2 一般需要安装插件或者自己写代码才行。 71. 如何避免 SQL 注入？ 使用预处理 PreparedStatement。 使用正则表达式过滤掉字符中的特殊字符。 72. 什么是 XSS 攻击，如何避免？ XSS 攻击：即跨站脚本攻击，它是 Web 程序中常见的漏洞。原理是攻击者往 Web 页面里插入恶意的脚本代码（css 代码、Javascript 代码等），当用户浏览该页面时，嵌入其中的脚本代码会被执行，从而达到恶意攻击用户的目的， 如盗取用户 cookie、破坏页面结构、重定向到其他网站等。\n预防 XSS 的核心是必须对输入的数据做过滤处理。\n73. 什么是 CSRF 攻击，如何避免？ CSRF：Cross-Site Request Forgery（中文：跨站请求伪造），可以理解为攻击者盗用了你的身份，以你的名义发送 恶意请求，比如：以你名义发送邮件、发消息、购买商品，虚拟货币转账等。\n防御手段：\n验证请求来源地址； 关键操作添加验证码； 在请求地址添加 token 并验证。 异常 74. throw 和 throws 的区别？ throw：是真实抛出一个异常。 throws：是声明可能会抛出一个异常。 75. final、finally、finalize 有什么区别？ final：是修饰符，如果修饰类，此类不能被继承；如果修饰方法和变量，则表示此方法和此变量不能在被改 变，只能使用。 finally：是 try{} catch{} finally{} 最后一部分，表示不论发生任何情况都会执行，finally 部分可以省略，但如果 finally 部分存在，则一定会执行 finally 里面的代码。 finalize： 是 Object 类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法。 76. try-catch-finally 中哪个部分可以省略？ try-catch-finally 其中 catch 和 finally 都可以被省略，但是不能同时省略，也就是说有 try 的时候，必须后面跟一个 catch 或者 finally。\n77. try-catch-finally 中，如果 catch 中 return 了，finally 还会执行吗？ finally 一定会执行，即使是 catch 中 return 了，catch 中的 return 会等 finally 中的代码执行完之后，才会执行。\n78. 常见的异常类有哪些？ NullPointerException 空指针异常 ClassNotFoundException 指定类不存在 NumberFormatException 字符串转换为数字异常 IndexOutOfBoundsException 数组下标越界异常 ClassCastException 数据类型转换异常 FileNotFoundException 文件未找到异常 NoSuchMethodException 方法不存在异常 IOException IO 异常 SocketException Socket 异常 网络 79. http 响应码 301 和 302 代表的是什么？有什么区别？ 301 ：永久重定向。 302 ：暂时重定向。 它们的区别是， 301 对搜索引擎优化（SEO）更加有利； 302 有被提示为网络拦截的风险。 80. forward 和 redirect 的区别？ forward 是转发 和 redirect 是重定向：\n地址栏 url 显示：foward url 不会发生改变，redirect url 会发生改变； 数据共享：forward 可以共享 request 里的数据，redirect 不能共享； 效率：forward 比 redirect 效率高。 81. 简述 tcp 和 udp的区别？ tcp 和 udp 是 OSI 模型中的运输层中的协议。tcp 提供可靠的通信传输，而 udp 则常被用于让广播和细节控制交给 应用的通信传输。\n两者的区别大致如下：\ntcp 面向连接，udp 面向非连接即发送数据前不需要建立链接； tcp 提供可靠的服务（数据传输），udp 无法保证； tcp 面向字节流，udp 面向报文； tcp 数据传输慢，udp 数据传输快； 82. tcp 为什么要三次握手，两次不行吗？为什么？ 如果采用两次握手，那么只要服务器发出确认数据包就会建立连接，但由于客户端此时并未响应服务器端的请求，那 此时服务器端就会一直在等待客户端，这样服务器端就白白浪费了一定的资源。若采用三次握手，服务器端没有收到 来自客户端的再此确认，则就会知道客户端并没有要求建立请求，就不会浪费服务器的资源。 83. 说一下 tcp 粘包是怎么产生的？ tcp 粘包可能发生在发送端或者接收端，分别来看两端各种产生粘包的原因：\n发送端粘包：发送端需要等缓冲区满才发送出去，造成粘包； 接收方粘包：接收方不及时接收缓冲区的包，造成多个包接收。 84. OSI 的七层模型都有哪些？ 物理层：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。 数据链路层：负责建立和管理节点间的链路。 网络层：通过路由选择算法，为报文或分组通过通信子网选择最适当的路径。 传输层：向用户提供可靠的端到端的差错和流量控制，保证报文的正确传输。 会话层：向两个实体的表示层提供建立和使用连接的方法。 表示层：处理用户信息的表示问题，如编码、数据格式转换和加密解密等。 应用层：直接向用户提供服务，完成用户希望在网络上完成的各种工作。 85. get 和 post 请求有哪些区别？ get 请求会被浏览器主动缓存，而 post 不会。 get 传递参数有大小限制，而 post 没有。 post 参数传输更安全，get 的参数会明文限制在 url 上，post 不会。 86. 如何实现跨域？ 实现跨域有以下几种方案： 服务器端运行跨域 设置 CORS 等于 *； 在单个接口使用注解 @CrossOrigin 运行跨域； 使用 jsonp 跨域； 87. 说一下 JSONP 实现原理？ jsonp：JSON with Padding，它是利用script标签的 src 连接可以访问不同源的特性，加载远程返回的“JS 函数”来执 行的。\n设计模式 88. 说一下你熟悉的设计模式？ 单例模式：保证被创建一次，节省系统开销。 工厂模式（简单工厂、抽象工厂）：解耦代码。 观察者模式：定义了对象之间的一对多的依赖，这样一来，当一个对象改变时，它的所有的依赖者都会收到通 知并自动更新。 外观模式：提供一个统一的接口，用来访问子系统中的一群接口，外观定义了一个高层的接口，让子系统更容 易使用。 模版方法模式：定义了一个算法的骨架，而将一些步骤延迟到子类中，模版方法使得子类可以在不改变算法结 构的情况下，重新定义算法的步骤。 状态模式：允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类。 89. 简单工厂和抽象工厂有什么区别？ 简单工厂：用来生产同一等级结构中的任意产品，对于增加新的产品，无能为力。 工厂方法：用来生产同一等级结构中的固定产品，支持增加任意产品。 抽象工厂：用来生产不同产品族的全部产品，对于增加新的产品，无能为力；支持增加产品族。 Spring/Spring MVC 90. 为什么要使用 spring？ spring 提供 ioc 技术，容器会帮你管理依赖的对象，从而不需要自己创建和管理依赖对象了，更轻松的实现了 程序的解耦。 spring 提供了事务支持，使得事务操作变的更加方便。 spring 提供了面向切片编程，这样可以更方便的处理某一类的问题。 更方便的框架集成，spring 可以很方便的集成其他框架，比如 MyBatis、hibernate 等。 91. 解释一下什么是 aop？ aop 是面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。\n简单来说就是统一处理某一“切面”（类）的问题的编程思想，比如统一处理日志、异常等。\n92. 解释一下什么是 ioc？ ioc：Inversionof Control（中文：控制反转）是 spring 的核心，对于 spring 框架来说，就是由 spring 来负责控制 对象的生命周期和对象间的关系。\n简单来说，控制指的是当前对象对内部成员的控制权；控制反转指的是，这种控制权不由当前对象管理了，由其他 （类,第三方容器）来管理。\n93. spring 有哪些主要模块？ spring core：框架的最基础部分，提供 ioc 和依赖注入特性。 spring context：构建于 core 封装包基础上的 context 封装包，提供了一种框架式的对象访问方法。 spring dao：Data Access Object 提供了JDBC的抽象层。 spring aop：提供了面向切面的编程实现，让你可以自定义拦截器、切点等。 spring Web：提供了针对 Web 开发的集成特性，例如文件上传，利用 servlet listeners 进行 ioc 容器初始化和 针对 Web 的 ApplicationContext。 spring Web mvc：spring 中的 mvc 封装包提供了 Web 应用的 Model-View-Controller（MVC）的实现。 94. spring 常用的注入方式有哪些？ setter 属性注入 构造方法注入 注解方式注入 95. spring 中的 bean 是线程安全的吗？ spring 中的 bean 默认是单例模式，spring 框架并没有对单例 bean 进行多线程的封装处理。\n实际上大部分时候 spring bean 无状态的（比如 dao 类），所有某种程度上来说 bean 也是安全的，但如果 bean 有 状态的话（比如 view model 对象），那就要开发者自己去保证线程安全了，最简单的就是改变 bean 的作用域， 把“singleton”变更为“prototype”，这样请求 bean 相当于 new Bean()了，所以就可以保证线程安全了。\n有状态就是有数据存储功能。 无状态就是不会保存数据。 96. spring 支持几种 bean 的作用域？ spring 支持 5 种作用域，如下：\nsingleton：spring ioc 容器中只存在一个 bean 实例，bean 以单例模式存在，是系统默认值； prototype：每次从容器调用 bean 时都会创建一个新的示例，既每次 getBean()相当于执行 new Bean()操作； Web 环境下的作用域： request：每次 http 请求都会创建一个 bean； session：同一个 http session 共享一个 bean 实例； global-session：用于 portlet 容器，因为每个 portlet 有单独的 session，globalsession 提供一个全局性的 http session。 注意： 使用 prototype 作用域需要慎重的思考，因为频繁创建和销毁 bean 会带来很大的性能开销。\n97. spring 自动装配 bean 有哪些方式？ no：默认值，表示没有自动装配，应使用显式 bean 引用进行装配。 byName：它根据 bean 的名称注入对象依赖项。 byType：它根据类型注入对象依赖项。 构造函数：通过构造函数来注入依赖项，需要设置大量的参数。 autodetect：容器首先通过构造函数使用 autowire 装配，如果不能，则通过 byType 自动装配。 98. spring 事务实现方式有哪些？ 声明式事务：声明式事务也有两种实现方式，基于 xml 配置文件的方式和注解方式（在类上添加 @Transaction 注解）。 编码方式：提供编码的形式管理和维护事务。 99. 说一下 spring 的事务隔离？ spring 有五大隔离级别，默认值为 ISOLATION_DEFAULT（使用数据库的设置），其他四个隔离级别和数据库的隔离 级别一致：\nISOLATION_DEFAULT：用底层数据库的设置隔离级别，数据库设置的是什么我就用什么；\nISOLATIONREADUNCOMMITTED：未提交读，最低隔离级别、事务未提交前，就可被其他事务读取（会出现幻读、 脏读、不可重复读）；\nISOLATIONREADCOMMITTED：提交读，一个事务提交后才能被其他事务读取到（会造成幻读、不可重复读），SQL server 的默认级别；\nISOLATIONREPEATABLEREAD：可重复读，保证多次读取同一个数据时，其值都和事务开始时候的内容是一致，禁止 读取到别的事务未提交的数据（会造成幻读），MySQL 的默认级别；\nISOLATION_SERIALIZABLE：序列化，代价最高最可靠的隔离级别，该隔离级别能防止脏读、不可重复读、幻读。\n脏读 ：表示一个事务能够读取另一个事务中还未提交的数据。比如，某个事务尝试插入记录 A，此时该事务还未提 交，然后另一个事务尝试读取到了记录 A。\n不可重复读 ：是指在一个事务内，多次读同一数据。\n幻读 ：指同一个事务内多次查询返回的结果集不一样。比如同一个事务 A 第一次查询时候有 n 条记录，但是第二次 同等条件下查询却有 n+1 条记录，这就好像产生了幻觉。发生幻读的原因也是另外一个事务新增或者删除或者修改 了第一个事务结果集里面的数据，同一个记录的数据内容被修改了，所有数据行的记录就变多或者变少了。\n100. 说一下 spring mvc 运行流程？ spring mvc 先将请求发送给 DispatcherServlet。 DispatcherServlet 查询一个或多个 HandlerMapping，找到处理请求的 Controller。 DispatcherServlet 再把请求提交到对应的 Controller。 Controller 进行业务逻辑处理后，会返回一个ModelAndView。 Dispathcher 查询一个或多个 ViewResolver 视图解析器，找到 ModelAndView 对象指定的视图对象。 视图对象负责渲染返回给客户端。 101. spring mvc 有哪些组件？ 前置控制器 DispatcherServlet。 映射控制器 HandlerMapping。 处理器 Controller。 模型和视图 ModelAndView。 视图解析器 ViewResolver。 102. @RequestMapping 的作用是什么？ 将 http 请求映射到相应的类/方法上。\n103. @Autowired 的作用是什么？ @Autowired 它可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作，通过@Autowired 的使用来消 除 set/get 方法。\nSpring Boot/Spring Cloud 104. 什么是 spring boot？ spring boot 是为 spring 服务的，是用来简化新 spring 应用的初始搭建以及开发过程的。\n105. 为什么要用 spring boot？ 配置简单 独立运行 自动装配 无代码生成和 xml 配置 提供应用监控 易上手 提升开发效率 106. spring boot 核心配置文件是什么？ spring boot 核心的两个配置文件：\nbootstrap (. yml 或者. properties)：boostrap 由父 ApplicationContext 加载的，比 applicaton 优先加载，且 boostrap 里面的属性不能被覆盖； application (. yml 或者. properties)：用于 spring boot 项目的自动化配置。 107. spring boot 配置文件有哪几种类型？它们有什么区别？ 配置文件有. properties 格式和. yml 格式，它们主要的区别是书法风格不同。\n. properties 配置如下： . yml 配置如下：\nspring. RabbitMQ. port=5672 . yml 格式不支持 @PropertySource 注解导入。\n108. spring boot 有哪些方式可以实现热部署？ 使用 devtools 启动热部署，添加 devtools 库，在配置文件中把 spring. devtools. restart. enabled 设置为 true； 使用 Intellij Idea 编辑器，沟上自动编译或手动重新编译。 109. jpa 和 hibernate 有什么区别？ jpa 全称 Java Persistence API，是 Java 持久化接口规范，hibernate 属于 jpa 的具体实现。\n110. 什么是 spring cloud？ spring cloud 是一系列框架的有序集合。它利用 spring boot 的开发便利性巧妙地简化了分布式系统基础设施的开 发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 spring boot 的开发风格做 到一键启动和部署。\n111. spring cloud 断路器的作用是什么？ 在分布式架构中，断路器模式的作用也是类似的，当某个服务单元发生故障（类似用电器发生短路）之后，通过断路 器的故障监控（类似熔断保险丝），向调用方返回一个错误响应，而不是长时间的等待。这样就不会使得线程因调用 故障服务被长时间占用不释放，避免了故障在分布式系统中的蔓延。 112. spring cloud 的核心组件有哪些？ Eureka：服务注册于发现。 Feign：基于动态代理机制，根据注解和选择的机器，拼接请求 url 地址，发起请求。 Ribbon：实现负载均衡，从一个服务的多台机器中选择一台。 Hystrix：提供线程池，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题。 Zuul：网关管理，由 Zuul 网关转发请求给对应的服务。 Hibernate 113. 为什么要使用 hibernate？ hibernate 是对 jdbc 的封装，大大简化了数据访问层的繁琐的重复性代码。 hibernate 是一个优秀的 ORM 实现，很多程度上简化了 DAO 层的编码功能。 可以很方便的进行数据库的移植工作。 提供了缓存机制，是程序执行更改的高效。 114. 什么是 ORM 框架？ ORM（Object Relation Mapping）对象关系映射，是把数据库中的关系数据映射成为程序中的对象。\n使用 ORM 的优点：提高了开发效率降低了开发成本、开发更简单更对象化、可移植更强。\n115. hibernate 中如何在控制台查看打印的 SQL 语句？ spring: RabbitMQ: port: 5672 在 Config 里面把 hibernate. show_SQL 设置为 true 就可以。但不建议开启，开启之后会降低程序的运行效率。\n116. hibernate 有几种查询方式？ 三种：hql、原生 SQL、条件查询 Criteria。\n117. hibernate 实体类可以被定义为 final 吗？ 实体类可以定义为 final 类，但这样的话就不能使用 hibernate 代理模式下的延迟关联提供性能了，所以不建议定义 实体类为 final。\n118. 在 hibernate 中使用 Integer 和 int 做映射有什么区别？ Integer 类型为对象，它的值允许为 null，而 int 属于基础数据类型，值不能为 null。\n119. hibernate 是如何工作的？ 读取并解析配置文件。 读取并解析映射文件，创建 SessionFactory。 打开 Session。 创建事务。 进行持久化操作。 提交事务。 关闭 Session。 关闭 SessionFactory。 120. get()和 load()的区别？ 数据查询时，没有 OID 指定的对象，get() 返回 null；load() 返回一个代理对象。 load()支持延迟加载；get() 不支持延迟加载。 121. 说一下 hibernate 的缓存机制？ hibernate 常用的缓存有一级缓存和二级缓存：\n一级缓存：也叫 Session 缓存，只在 Session 作用范围内有效，不需要用户干涉，由 hibernate 自身维护，可以通 过：evict(object)清除 object 的缓存；clear()清除一级缓存中的所有缓存；flush()刷出缓存；\n二级缓存：应用级别的缓存，在所有 Session 中都有效，支持配置第三方的缓存，如：EhCache。\n122. hibernate 对象有哪些状态？ 临时/瞬时状态：直接 new 出来的对象，该对象还没被持久化（没保存在数据库中），不受 Session 管理。 持久化状态：当调用 Session 的 save/saveOrupdate/get/load/list 等方法的时候，对象就是持久化状态。 游离状态：Session 关闭之后对象就是游离状态。 123. 在 hibernate 中 getCurrentSession 和 openSession 的区别是什么？ getCurrentSession 会绑定当前线程，而 openSession 则不会。 getCurrentSession 事务是 Spring 控制的，并且不需要手动关闭，而 openSession 需要我们自己手动开启和提 交事务。 124. hibernate 实体类必须要有无参构造函数吗？为什么？ hibernate 中每个实体类必须提供一个无参构造函数，因为 hibernate 框架要使用 reflection api，通过调用 ClassnewInstance() 来创建实体类的实例，如果没有无参的构造函数就会抛出异常。\nMyBatis 125. MyBatis 中 #{}和 ${}的区别是什么？ #{}是预编译处理，${}是字符替换。 在使用 #{}时，MyBatis 会将 SQL 中的 #{}替换成“?”，配合 PreparedStatement 的 set 方法赋值，这样可以有效的防止 SQL 注入，保证程序的运行安全。\n126. MyBatis 有几种分页方式？ 分页方式：逻辑分页和物理分页。 逻辑分页： 使用 MyBatis 自带的 RowBounds 进行分页，它是一次性查询很多数据，然后在数据中再进行检索。\n物理分页： 自己手写 SQL 分页或使用分页插件 PageHelper，去数据库查询指定条数的分页数据的形式。\n127. RowBounds 是一次性查询全部结果吗？为什么？ RowBounds 表面是在“所有”数据中检索数据，其实并非是一次性查询出所有数据，因为 MyBatis 是对 jdbc 的封 装，在 jdbc 驱动中有一个 Fetch Size 的配置，它规定了每次最多从数据库查询多少条数据，假如你要查询更的数 据，它会在你执行 next()的时候，去查询更多的数据。就好比你去自动取款机取 10000 元，但取款机每次最多能取 2500 元，所以你要取 4 次才能把钱取完。只是对于 jdbc 来说，当你调用 next()的时候会自动帮你完成查询工作。这 样做的好处可以有效的防止内存溢出。\nFetch Size 官方相关文档：http://t. cn/EfSE2g3\n128. MyBatis 逻辑分页和物理分页的区别是什么？ 逻辑分页是一次性查询很多数据，然后再在结果中检索分页的数据。这样做弊端是需要消耗大量的内存、有内 存溢出的风险、对数据库压力较大。 物理分页是从数据库查询指定条数的数据，弥补了一次性全部查出的所有数据的种种缺点，比如需要大量的内 存，对数据库查询压力较大等问题。 129. MyBatis 是否支持延迟加载？延迟加载的原理是什么？ MyBatis 支持延迟加载，设置 lazyLoadingEnabled=true 即可。\n延迟加载的原理的是调用的时候触发加载，而不是在初始化的时候就加载信息。比如调用 a. getB(). getName()，这 个时候发现 a. getB() 的值为 null，此时会单独触发事先保存好的关联 B 对象的 SQL，先查询出来 B，然后再调用 a. setB(b)，而这时候再调用 a. getB(). getName() 就有值了，这就是延迟加载的基本原理。\n130. 说一下 MyBatis 的一级缓存和二级缓存？ 一级缓存：基于 PerpetualCache 的 HashMap 本地缓存，它的声明周期是和 SQLSession 一致的，有多个 SQLSession 或者分布式的环境中数据库操作，可能会出现脏数据。当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空，默认一级缓存是开启的。 二级缓存：也是基于 PerpetualCache 的 HashMap 本地缓存，不同在于其存储作用域为 Mapper 级别的，如 果多个SQLSession之间需要共享缓存，则需要使用到二级缓存，并且二级缓存可自定义存储源，如 Ehcache。 默认不打开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现 Serializable 序列化接口(可用来保存对 象的状态)。 开启二级缓存数据查询流程：二级缓存 -\u0026gt; 一级缓存 -\u0026gt; 数据库。\n缓存更新机制：当某一个作用域(一级缓存 Session/二级缓存 Mapper)进行了C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear。\n131. MyBatis 和 hibernate 的区别有哪些？ 灵活性：MyBatis 更加灵活，自己可以写 SQL 语句，使用起来比较方便。 可移植性：MyBatis 有很多自己写的 SQL，因为每个数据库的 SQL 可以不相同，所以可移植性比较差。 学习和使用门槛：MyBatis 入门比较简单，使用门槛也更低。 二级缓存：hibernate 拥有更好的二级缓存，它的二级缓存可以自行更换为第三方的二级缓存。 132. MyBatis 有哪些执行器（Executor）？ MyBatis 有三种基本的Executor执行器：\nSimpleExecutor：每执行一次 update 或 select 就开启一个 Statement 对象，用完立刻关闭 Statement 对 象； ReuseExecutor：执行 update 或 select，以 SQL 作为 key 查找 Statement 对象，存在就使用，不存在就创 建，用完后不关闭 Statement 对象，而是放置于 Map 内供下一次使用。简言之，就是重复使用 Statement 对 象； BatchExecutor：执行 update（没有 select，jdbc 批处理不支持 select），将所有 SQL 都添加到批处理中 （addBatch()），等待统一执行（executeBatch()），它缓存了多个 Statement 对象，每个 Statement 对象都 是 addBatch()完毕后，等待逐一执行 executeBatch()批处理，与 jdbc 批处理相同。 133. MyBatis 分页插件的实现原理是什么？ 分页插件的基本原理是使用 MyBatis 提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 SQL， 然后重写 SQL，根据 dialect 方言，添加对应的物理分页语句和物理分页参数。\n134. MyBatis 如何编写一个自定义插件？ 自定义插件实现原理 MyBatis 自定义插件针对 MyBatis 四大对象（Executor、StatementHandler、ParameterHandler、 ResultSetHandler）进行拦截：\nExecutor：拦截内部执行器，它负责调用 StatementHandler 操作数据库，并把结果集通过 ResultSetHandler 进行自动映射，另外它还处理了二级缓存的操作； StatementHandler：拦截 SQL 语法构建的处理，它是 MyBatis 直接和数据库执行 SQL 脚本的对象，另外它也 实现了 MyBatis 的一级缓存； ParameterHandler：拦截参数的处理； ResultSetHandler：拦截结果集的处理。 自定义插件实现关键\nMyBatis 插件要实现 Interceptor 接口，接口包含的方法，如下：\npublic interface Interceptor { Object intercept(Invocation invocation) throws Throwable; Object plugin(Object target); void setProperties(Properties properties); } setProperties 方法是在 MyBatis 进行配置插件的时候可以配置自定义相关属性，即：接口实现对象的参数配 置； plugin 方法是插件用于封装目标对象的，通过该方法我们可以返回目标对象本身，也可以返回一个它的代理， 可以决定是否要进行拦截进而决定要返回一个什么样的目标对象，官方提供了示例：return Plugin. wrap(target, this)； intercept 方法就是要进行拦截的时候要执行的方法。 自定义插件实现示例\n官方插件实现：\nRabbitMQ 135. RabbitMQ 的使用场景有哪些？ 抢购活动，削峰填谷，防止系统崩塌。 延迟信息处理，比如 10 分钟之后给下单未付款的用户发送邮件提醒。 解耦系统，对于新增的功能可以单独写模块扩展，比如用户确认评价之后，新增了给用户返积分的功能，这个 时候不用在业务代码里添加新增积分的功能，只需要把新增积分的接口订阅确认评价的消息队列即可，后面再 添加任何功能只需要订阅对应的消息队列即可。 136. RabbitMQ 有哪些重要的角色？ RabbitMQ 中重要的角色有：生产者、消费者和代理：\n生产者：消息的创建者，负责创建和推送数据到消息服务器； 消费者：消息的接收方，用于处理数据和确认消息； 代理：就是 RabbitMQ 本身，用于扮演“快递”的角色，本身不生产消息，只是扮演“快递”的角色。 137. RabbitMQ 有哪些重要的组件？ ConnectionFactory（连接管理器）：应用程序与Rabbit之间建立连接的管理器，程序代码中使用。 Channel（信道）：消息推送使用的通道。 Exchange（交换器）：用于接受、分配消息。 @Intercepts({@Signature(type = Executor. class, method = \u0026#34;query\u0026#34;, args = {MappedStatement. class, Object. class, RowBounds. class, ResultHandler. class})}) public class TestInterceptor implements Interceptor { public Object intercept(Invocation invocation) throws Throwable { Object target = invocation. getTarget(); //被代理对象 Method method = invocation. getMethod(); //代理方法 Object[] args = invocation. getArgs(); //方法参数 // do something...... 方法拦截前执行代码块 Object result = invocation. proceed(); // do something....... 方法拦截后执行代码块 return result; } public Object plugin(Object target) { return Plugin. wrap(target, this); } } Queue（队列）：用于存储生产者的消息。 RoutingKey（路由键）：用于把生成者的数据分配到交换器上。 BindingKey（绑定键）：用于把交换器的消息绑定到队列上。 138. RabbitMQ 中 vhost 的作用是什么？ vhost：每个 RabbitMQ 都能创建很多 vhost，我们称之为虚拟主机，每个虚拟主机其实都是 mini 版的RabbitMQ， 它拥有自己的队列，交换器和绑定，拥有自己的权限机制。\n139. RabbitMQ 的消息是怎么发送的？ 首先客户端必须连接到 RabbitMQ 服务器才能发布和消费消息，客户端和 rabbit server 之间会创建一个 tcp 连接， 一旦 tcp 打开并通过了认证（认证就是你发送给 rabbit 服务器的用户名和密码），你的客户端和 RabbitMQ 就创建 了一条 amqp 信道（channel），信道是创建在“真实” tcp 上的虚拟连接，amqp 命令都是通过信道发送出去的，每 个信道都会有一个唯一的 id，不论是发布消息，订阅队列都是通过这个信道完成的。\n140. RabbitMQ 怎么保证消息的稳定性？ 提供了事务的功能。 通过将 channel 设置为 confirm（确认）模式。 141. RabbitMQ 怎么避免消息丢失？ 把消息持久化磁盘，保证服务器重启消息不丢失。 每个集群中至少有一个物理 142. 要保证消息持久化成功的条件有哪些？ 声明队列必须设置持久化 durable 设置为 true. 消息推送投递模式必须设置持久化，deliveryMode 设置为 2 （持久）。 消息已经到达持久化交换器。 消息已经到达持久化队列。 以上四个条件都满足才能保证消息持久化成功。\n143. RabbitMQ 持久化有什么缺点？ 持久化的缺地就是降低了服务器的吞吐量，因为使用的是磁盘而非内存存储，从而降低了吞吐量。可尽量使用 ssd 硬 盘来缓解吞吐量的问题。\n144. RabbitMQ 有几种广播类型？ direct（默认方式）：最基础最简单的模式，发送方把消息发送给订阅方，如果有多个订阅者，默认采取轮询的 方式进行消息发送。 headers：与 direct 类似，只是性能很差，此类型几乎用不到。 fanout：分发模式，把消费分发给所有订阅者。 topic：匹配订阅模式，使用正则匹配到消息队列，能匹配到的都能接收到。 145. RabbitMQ 怎么实现延迟消息队列？ 延迟队列的实现有两种方式： 通过消息过期后进入死信交换器，再由交换器转发到延迟消费队列，实现延迟功能； 使用 RabbitMQ-delayed-message-exchange 插件实现延迟功能。 146. RabbitMQ 集群有什么用？ 集群主要有以下两个用途： 高可用：某个服务器出现问题，整个 RabbitMQ 还可以继续使用； 高容量：集群可以承载更多的消息量。 147. RabbitMQ 节点的类型有哪些？ 磁盘节点：消息会存储到磁盘。 内存节点：消息都存储在内存中，重启服务器消息丢失，性能高于磁盘类型。 148. RabbitMQ 集群搭建需要注意哪些问题？ 各节点之间使用“--link”连接，此属性不能忽略。 各节点使用的 erlang cookie 值必须相同，此值相当于“秘钥”的功能，用于各节点的认证。 整个集群中必须包含一个磁盘节点。 149. RabbitMQ 每个节点是其他节点的完整拷贝吗？为什么？ 不是，原因有以下两个： 存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加 了更多的冗余数据； 性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，最多 是保持和单节点相同的性能甚至是更糟。 150. RabbitMQ 集群中唯一一个磁盘节点崩溃了会发生什么情况？ 如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作： 不能创建队列 不能创建交换器 不能创建绑定 不能添加用户 不能更改权限 不能添加和删除集群节点 唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。 151. RabbitMQ 对集群节点停止顺序有要求吗？ RabbitMQ 对集群的停止的顺序是有要求的，应该先关闭内存节点，最后再关闭磁盘节点。如果顺序恰好相反的话， 可能会造成消息的丢失。\nKafka 152. kafka 可以脱离 zookeeper 单独使用吗？为什么？ kafka 不能脱离 zookeeper 单独使用，因为 kafka 使用 zookeeper 管理和协调 kafka 的节点服务器。\n153. kafka 有几种数据保留的策略？ kafka 有两种数据保存策略：按照过期时间保留和按照存储的消息大小保留。\n154. kafka 同时设置了 7 天和 10G 清除数据，到第五天的时候消息达到了 10G，这个时候 kafka 将如何处理？ 这个时候 kafka 会执行数据清除工作，时间和大小不论那个满足条件，都会清空数据。\n155. 什么情况会导致 kafka 运行变慢？ cpu 性能瓶颈 磁盘读写瓶颈 网络瓶颈 156. 使用 kafka 集群需要注意什么？ 集群的数量不是越多越好，最好不要超过 7 个，因为节点越多，消息复制需要的时间就越长，整个群组的吞吐 量就越低。 集群数量最好是单数，因为超过一半故障集群就不能用了，设置为单数容错率更高。 Zookeeper 157. zookeeper 是什么？ zookeeper 是一个分布式的，开放源码的分布式应用程序协调服务，是 google chubby 的开源实现，是 hadoop 和 hbase 的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式 同步、组服务等。\n158. zookeeper 都有哪些功能？ 集群管理：监控节点存活状态、运行请求等。 主节点选举：主节点挂掉了之后可以从备用的节点开始新一轮选主，主节点选举说的就是这个选举的过程，使 用 zookeeper 可以协助完成这个过程。 分布式锁：zookeeper 提供两种锁：独占锁、共享锁。独占锁即一次只能有一个线程使用资源，共享锁是读锁 共享，读写互斥，即可以有多线线程同时读同一个资源，如果要使用写锁也只能有一个线程使用。zookeeper 可以对分布式锁进行控制。 命名服务：在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提 供者等信息。 159. zookeeper 有几种部署模式？ zookeeper 有三种部署模式：\n单机部署：一台集群上运行； 集群部署：多台集群运行； 伪集群部署：一台集群启动多个 zookeeper 实例运行。 160. zookeeper 怎么保证主从节点的状态同步？ zookeeper 的核心是原子广播，这个机制保证了各个 server 之间的同步。实现这个机制的协议叫做 zab 协议。 zab 协议有两种模式，分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，zab 就进入了恢 复模式，当领导者被选举出来，且大多数 server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保 证了 leader 和 server 具有相同的系统状态。\n161. 集群中为什么要有主节点？ 在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大 减少重复计算，提高性能，所以就需要主节点。 162. 集群中有 3 台服务器，其中一个节点宕机，这个时候 zookeeper 还可以使用吗？ 可以继续使用，单数服务器只要没超过一半的服务器宕机就可以继续使用。 163. 说一下 zookeeper 的通知机制？ 客户端端会对某个 znode 建立一个 watcher 事件，当该 znode 发生变化时，这些客户端会收到 zookeeper 的通 知，然后客户端可以根据 znode 变化来做出业务上的改变。\nMySQL 164. 数据库的三范式是什么？ 第一范式：强调的是列的原子性，即数据库表的每一列都是不可分割的原子数据项。 第二范式：要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性。 第三范式：任何非主属性不依赖于其它非主属性。 165. 一张自增表里面总共有 7 条数据，删除了最后 2 条数据，重启 MySQL 数据库，又插入 了一条数据，此时 id 是几？ 表类型如果是 MyISAM ，那 id 就是 8 。 表类型如果是 InnoDB，那 id 就是 6 。 InnoDB 表只会把自增主键的最大 id 记录在内存中，所以重启之后会导致最大 id 丢失。\n166. 如何获取当前数据库版本？ 使用 select version() 获取当前 MySQL 数据库版本。\n167. 说一下 ACID 是什么？ Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在 中间某个环节。事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来 没有执行过一样。即，事务不可分割、不可约简。 Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必 须完全符合所有的预设约束、触发器、级联回滚等。 Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事 务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 168. char 和 varchar 的区别是什么？ char(n) ：固定长度类型，比如订阅 char(10)，当你输入\u0026#34;abc\u0026#34;三个字符的时候，它们占的空间还是 10 个字 节，其他 7 个是空字节。 chat 优点：效率高；缺点：占用空间；适用场景：存储密码的 md5 值，固定长度的，使用 char 非常合适。\nvarchar(n) ：可变长度，存储的值是每个值占用的字节再加上一个用来记录其长度的字节的长度。 所以，从空间上考虑 varcahr 比较合适；从效率上考虑 char 比较合适，二者使用需要权衡。\n169. float 和 double 的区别是什么？ float 最多可以存储 8 位的十进制数，并在内存中占 4 字节。 double 最可可以存储 16 位的十进制数，并在内存中占 8 字节。 170. MySQL 的内连接、左连接、右连接有什么区别？ 内连接关键字：inner join；左连接：left join；右连接：right join。\n内连接是把匹配的关联数据显示出来；左连接是左边的表全部显示出来，右边的表显示出符合条件的数据；右连接正 好相反。\n171. MySQL 索引是怎么实现的？ 索引是满足某种特定查找算法的数据结构，而这些数据结构会以某种方式指向数据，从而实现高效查找数据。 具体来说 MySQL 中的索引，不同的数据引擎实现有所不同，但目前主流的数据库引擎的索引都是 B+ 树实现的，B+ 树的搜索效率，可以到达二分法的性能，找到数据区域之后就找到了完整的数据结构了，所有索引的性能也是更好 的。\n172. 怎么验证 MySQL 的索引是否满足需求？ 使用 explain 查看 SQL 是如何执行查询语句的，从而分析你的索引是否满足需求。\nexplain 语法：explain select * from table where type=1。\n173. 说一下数据库的事务隔离？ MySQL 的事务隔离是在 MySQL. ini 配置文件里添加的，在文件的最后添加：\ntransaction-isolation = REPEATABLE-READ 可用的配置值：READ-UNCOMMITTED、READ-COMMITTED、REPEATABLE-READ、SERIALIZABLE。\nREAD-UNCOMMITTED：未提交读，最低隔离级别、事务未提交前，就可被其他事务读取（会出现幻读、脏 读、不可重复读）。 READ-COMMITTED：提交读，一个事务提交后才能被其他事务读取到（会造成幻读、不可重复读）。 REPEATABLE-READ：可重复读，默认级别，保证多次读取同一个数据时，其值都和事务开始时候的内容是一 致，禁止读取到别的事务未提交的数据（会造成幻读）。 SERIALIZABLE：序列化，代价最高最可靠的隔离级别，该隔离级别能防止脏读、不可重复读、幻读。 脏读 ：表示一个事务能够读取另一个事务中还未提交的数据。比如，某个事务尝试插入记录 A，此时该事务还未提 交，然后另一个事务尝试读取到了记录 A。\n不可重复读 ：是指在一个事务内，多次读同一数据。\n幻读 ：指同一个事务内多次查询返回的结果集不一样。比如同一个事务 A 第一次查询时候有 n 条记录，但是第二次 同等条件下查询却有 n+1 条记录，这就好像产生了幻觉。发生幻读的原因也是另外一个事务新增或者删除或者修改 了第一个事务结果集里面的数据，同一个记录的数据内容被修改了，所有数据行的记录就变多或者变少了。\n174. 说一下 MySQL 常用的引擎？ InnoDB 引擎：mysql 5.1 后默认的数据库引擎，提供了对数据库 acid 事务的支持，并且还提供了行级锁和外 键的约束，它的设计的目标就是处理大数据容量的数据库系统。MySQL 运行的时候，InnoDB 会在内存中建立 缓冲池，用于缓冲数据和索引。但是该引擎是不支持全文搜索，同时启动也比较的慢，它是不会保存表的行数 的，所以当进行 select count(*) from table 指令的时候，需要进行扫描全表。由于锁的粒度小，写操作是不会 锁定全表的,所以在并发度较高的场景下使用会提升效率的。 MyIASM 引擎：不提供事务的支持，也不支持行级锁和外键。因此当执行插入和更新语句时，即执行写操作的 时候需要锁定这个表，所以会导致效率会降低。不过和 InnoDB 不同的是，MyIASM 引擎是保存了表的行数， 于是当进行 select count(*) from table 语句时，可以直接的读取已经保存的值而不需要进行扫描全表。所以， 如果表的读操作远远多于写操作时，并且不需要事务的支持的，可以将 MyIASM 作为数据库引擎的首选。 175. 说一下 MySQL 的行锁和表锁？ MyISAM 只支持表锁，InnoDB 支持表锁和行锁，默认为行锁。\n表级锁：开销小，加锁快，不会出现死锁。锁定粒度大，发生锁冲突的概率最高，并发量最低。 行级锁：开销大，加锁慢，会出现死锁。锁力度小，发生锁冲突的概率小，并发度最高。 176. 说一下乐观锁和悲观锁？ 乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期 间别人有没有去更新这个数据。 悲观锁：每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据 就会阻止，直到这个锁被释放。 数据库的乐观锁需要自己实现，在表里面添加一个 version 字段，每次修改成功值加 1 ，这样每次修改的时候先对比 一下，自己拥有的 version 和数据库现在的 version 是否一致，如果不一致就不修改，这样就实现了乐观锁。\n177. MySQL 问题排查都有哪些手段？ 使用 show processlist 命令查看当前所有连接信息。 使用 explain 命令查询 SQL 语句执行计划。 开启慢查询日志，查看慢查询的 SQL。 178. 如何做 MySQL 的性能优化？ 为搜索字段创建索引。 避免使用 select *，列出需要查询的字段。 垂直分割分表。 选择正确的存储引擎。 Redis 179. Redis 是什么？都有哪些使用场景？ Redis 是一个使用 C 语言开发的高速缓存数据库。\nRedis 使用场景：\n记录帖子点赞数、点击数、评论数； 缓存近期热帖； 缓存文章详情信息； 记录用户会话信息。 180. Redis 有哪些功能？ 数据缓存功能 分布式锁的功能 支持数据持久化 支持事务 支持消息队列 181. Redis 和 memcache 有什么区别？ 存储方式不同：memcache 把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小；Redis 有部份 存在硬盘上，这样能保证数据的持久性。 数据支持类型：memcache 对数据类型支持相对简单；Redis 有复杂的数据类型。 使用底层模型不同：它们之间底层实现方式，以及与客户端之间通信的应用协议不一样，Redis 自己构建了 vm 机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 value 值大小不同：Redis 最大可以达到 512mb；memcache 只有 1mb。 182. Redis 为什么是单线程的？ 因为 cpu 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且 cpu 又 不会成为瓶颈，那就顺理成章地采用单线程的方案了。\n关于 Redis 的性能，官方网站也有，普通笔记本轻松处理每秒几十万的请求。\n而且单线程并不代表就慢 nginx 和 nodejs 也都是高性能单线程的代表。\n183. 什么是缓存穿透？怎么解决？ 缓存穿透：指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将 导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。 解决方案：最简单粗暴的方法如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们就把这个空 结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 184. Redis 支持的数据类型有哪些？ Redis 支持的数据类型：string（字符串）、list（列表）、hash（字典）、set（集合）、zset（有序集合）。\n185. Redis 支持的 Java 客户端都有哪些？ 支持的 Java 客户端有 Redisson、jedis、lettuce 等。\n186. jedis 和 Redisson 有哪些区别？ jedis：提供了比较全面的 Redis 命令的支持。 Redisson：实现了分布式和可扩展的 Java 数据结构，与 jedis 相比 Redisson 的功能相对简单，不支持排序、 事务、管道、分区等 Redis 特性。 187. 怎么保证缓存和数据库数据的一致性？ 合理设置缓存的过期时间。 新增、更改、删除数据库操作时同步更新 Redis，可以使用事物机制来保证数据的一致性。 188. Redis 持久化有几种方式？ Redis 的持久化有两种方式，或者说有两种策略：\nRDB（Redis Database）：指定的时间间隔能对你的数据进行快照存储。 AOF（Append Only File）：每一个收到的写命令都通过write函数追加到文件中。 189. Redis 怎么实现分布式锁？ Redis 分布式锁其实就是在系统里面占一个“坑”，其他程序也要占“坑”的时候，占用成功了就可以继续执行，失败了 就只能放弃或稍后重试。\n占坑一般使用 setnx(set if not exists)指令，只允许被一个程序占有，使用完调用 del 释放锁。\n190. Redis 分布式锁有什么缺陷？ Redis 分布式锁不能解决超时的问题，分布式锁有一个超时时间，程序的执行如果超出了锁的超时时间就会出现问 题。\n191. Redis 如何做内存优化？ 尽量使用 Redis 的散列表，把相关的信息放到散列表里面存储，而不是把每个字段单独存储，这样可以有效的减少内 存使用。比如将 Web 系统的用户对象，应该放到散列表里面再整体存储到 Redis，而不是把用户的姓名、年龄、密 码、邮箱等字段分别设置 key 进行存储。\n192. Redis 淘汰策略有哪些？ volatile-lru：从已设置过期时间的数据集（server. db[i]. expires）中挑选最近最少使用的数据淘汰。 volatile-ttl：从已设置过期时间的数据集（server. db[i]. expires）中挑选将要过期的数据淘汰。 volatile-random：从已设置过期时间的数据集（server. db[i]. expires）中任意选择数据淘汰。 allkeys-lru：从数据集（server. db[i]. dict）中挑选最近最少使用的数据淘汰。 allkeys-random：从数据集（server. db[i]. dict）中任意选择数据淘汰。 no-enviction（驱逐）：禁止驱逐数据。 193. Redis 常见的性能问题有哪些？该如何解决？ 主服务器写内存快照，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所 以主服务器最好不要写内存快照。 Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，主从库最好在同一个局域网内。 JVM 194. 说一下 JVM 的主要组成部分？及其作用？ 类加载器（ClassLoader） 运行时数据区（Runtime Data Area） 执行引擎（Execution Engine） 本地库接口（Native Interface） 组件的作用： 首先通过类加载器（ClassLoader）会把 Java 代码转换成字节码，运行时数据区（Runtime Data Area）再把字节码加载到内存中，而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执 行，因此需要特定的命令解析器执行引擎（Execution Engine），将字节码翻译成底层系统指令，再交由 CPU 去执 行，而这个过程中需要调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。\n195. 说一下 JVM 运行时数据区？ 不同虚拟机的运行时数据区可能略微有所不同，但都会遵从 Java 虚拟机规范， Java 虚拟机规范规定的区域分为以下 5 个部分：\n程序计数器（Program Counter Register）：当前线程所执行的字节码的行号指示器，字节码解析器的工作是 通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等 基础功能，都需要依赖这个计数器来完成； Java 虚拟机栈（Java Virtual Machine Stacks）：用于存储局部变量表、操作数栈、动态链接、方法出口等信 息； 本地方法栈（Native Method Stack）：与虚拟机栈的作用是一样的，只不过虚拟机栈是服务 Java 方法的，而 本地方法栈是为虚拟机调用 Native 方法服务的； Java 堆（Java Heap）：Java 虚拟机中内存最大的一块，是被所有线程共享的，几乎所有的对象实例都在这里 分配内存； 方法区（Methed Area）：用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据。 196. 说一下堆栈的区别？ 功能方面：堆是用来存放对象的，栈是用来执行程序的。 共享性：堆是线程共享的，栈是线程私有的。 空间大小：堆大小远远大于栈。 197. 队列和栈是什么？有什么区别？ 队列和栈都是被用来预存储数据的。 队列允许先进先出检索元素，但也有例外的情况，Deque 接口允许从两端检索元素。\n栈和队列很相似，但它运行对元素进行后进先出进行检索。\n198. 什么是双亲委派模型？ 在介绍双亲委派模型之前先说下类加载器。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立在 JVM 中的唯一性，每一个类加载器，都有一个独立的类名称空间。类加载器就是根据指定全限定名称将 class 文件加 载到 JVM 内存，然后再转化为 class 对象。\n类加载器分类：\n启动类加载器（Bootstrap ClassLoader），是虚拟机自身的一部分，用来加载Java_HOME/lib/目录中的，或者 被 -Xbootclasspath 参数所指定的路径中并且被虚拟机识别的类库； 其他类加载器： 扩展类加载器（Extension ClassLoader）：负责加载\\lib\\ext目录或Java. ext. dirs系统变量指定的路径中的所有 类库； 应用程序类加载器（Application ClassLoader）。负责加载用户类路径（classpath）上的指定类库，我们可以 直接使用这个类加载器。一般情况，如果我们没有自定义类加载器默认就是用这个加载器。 双亲委派模型：如果一个类加载器收到了类加载的请求，它首先不会自己去加载这个类，而是把这个请求委派给父类 加载器去完成，每一层的类加载器都是如此，这样所有的加载请求都会被传送到顶层的启动类加载器中，只有当父加 载无法完成加载请求（它的搜索范围中没找到所需的类）时，子加载器才会尝试去加载类。\n199. 说一下类装载的执行过程？ 类装载分为以下 5 个步骤： 加载：根据查找路径找到相应的 class 文件然后导入； 检查：检查加载的 class 文件的正确性； 准备：给类中的静态变量分配内存空间； 解析：虚拟机将常量池中的符号引用替换成直接引用的过程。符号引用就理解为一个标示，而在直接引用直接 指向内存中的地址； 初始化：对静态变量和静态代码块执行初始化工作。 200. 怎么判断对象是否可以被回收？ 一般有两种方法来判断： 引用计数器：为每个对象创建一个引用计数，有对象引用时计数器 +1，引用被释放时计数 -1，当计数器为 0 时 就可以被回收。它有一个缺点不能解决循环引用的问题； 可达性分析：从 GC Roots 开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引 用链相连时，则证明此对象是可以被回收的。 201. Java 中都有哪些引用类型？ 强引用：发生 gc 的时候不会被回收。 软引用：有用但不是必须的对象，在发生内存溢出之前会被回收。 弱引用：有用但不是必须的对象，在下一次GC时会被回收。 虚引用（幽灵引用/幻影引用）：无法通过虚引用获得对象，用 PhantomReference 实现虚引用，虚引用的用途 是在 gc 时返回一个通知。 202. 说一下 JVM 有哪些垃圾回收算法？ 标记-清除算法：标记无用对象，然后进行清除回收。缺点：效率不高，无法清除垃圾碎片。 标记-整理算法：标记无用对象，让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存。 复制算法：按照容量划分二个大小相等的内存区域，当一块用完的时候将活着的对象复制到另一块上，然后再 把已使用的内存空间一次清理掉。缺点：内存使用率不高，只有原来的一半。 分代算法：根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代，新生代基本采用复制算法， 老年代采用标记整理算法。 203. 说一下 JVM 有哪些垃圾回收器？ Serial：最早的单线程串行垃圾回收器。 Serial Old：Serial 垃圾回收器的老年版本，同样也是单线程的，可以作为 CMS 垃圾回收器的备选预案。 ParNew：是 Serial 的多线程版本。 Parallel 和 ParNew 收集器类似是多线程的，但 Parallel 是吞吐量优先的收集器，可以牺牲等待时间换取系统的 吞吐量。 Parallel Old 是 Parallel 老生代版本，Parallel 使用的是复制的内存回收算法，Parallel Old 使用的是标记-整理 的内存回收算法。 CMS：一种以获得最短停顿时间为目标的收集器，非常适用 B/S 系统。 G1：一种兼顾吞吐量和停顿时间的 GC 实现，是 JDK 9 以后的默认 GC 选项。 204. 详细介绍一下 CMS 垃圾回收器？ CMS 是英文 Concurrent Mark-Sweep 的简称，是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对 于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动 JVM 的参数加上“- XX:+UseConcMarkSweepGC”来指定使用 CMS 垃圾回收器。\nCMS 使用的是标记-清除的算法实现的，所以在 gc 的时候回产生大量的内存碎片，当剩余内存不能满足程序运行要 求时，系统将会出现 Concurrent Mode Failure，临时 CMS 会采用 Serial Old 回收器进行垃圾清除，此时的性能将 会被降低。\n205. 新生代垃圾回收器和老生代垃圾回收器都有哪些？有什么区别？ 新生代回收器：Serial、ParNew、Parallel Scavenge 老年代回收器：Serial Old、Parallel Old、CMS 整堆回收器：G1 新生代垃圾回收器一般采用的是复制算法，复制算法的优点是效率高，缺点是内存利用率低；老年代回收器一般采用 的是标记-整理的算法进行垃圾回收。\n206. 简述分代垃圾回收器是怎么工作的？ 分代回收器有两个分区：老生代和新生代，新生代默认的空间占比总空间的 1/3，老生代的默认占比是 2/3。 新生代使用的是复制算法，新生代里有 3 个分区：Eden、To Survivor、From Survivor，它们的默认占比是 8:1:1， 它的执行流程如下：\n把 Eden + From Survivor 存活的对象放入 To Survivor 区； 清空 Eden 和 From Survivor 分区； From Survivor 和 To Survivor 分区交换，From Survivor 变 To Survivor，To Survivor 变 From Survivor。 每次在 From Survivor 到 To Survivor 移动时都存活的对象，年龄就 +1，当年龄到达 15 （默认配置是 15 ）时，升级 为老生代。大对象也会直接进入老生代。\n老生代当空间占用到达某个值之后就会触发全局垃圾收回，一般使用标记整理的执行算法。以上这些循环往复就构成 了整个分代垃圾回收的整体执行流程。\n207. 说一下 JVM 调优的工具？ JDK 自带了很多监控工具，都位于 JDK 的 bin 目录下，其中最常用的是 jconsole 和 jvisualvm 这两款视图监控工 具。\njconsole：用于对 JVM 中的内存、线程和类等进行监控； jvisualvm：JDK 自带的全能分析工具，可以分析：内存快照、线程快照、程序死锁、监控内存的变化、gc 变化 等。 208. 常用的 JVM 调优的参数都有哪些？ -Xms2g：初始化推大小为 2g； -Xmx2g：堆最大内存为 2g； -XX:NewRatio=4：设置年轻的和老年代的内存比例为 1:4； -XX:SurvivorRatio=8：设置新生代 Eden 和 Survivor 比例为 8:2； –XX:+UseParNewGC：指定使用 ParNew + Serial Old 垃圾回收器组合； -XX:+UseParallelOldGC：指定使用 ParNew + ParNew Old 垃圾回收器组合； -XX:+UseConcMarkSweepGC：指定使用 CMS + Serial Old 垃圾回收器组合； -XX:+PrintGC：开启打印 gc 信息； -XX:+PrintGCDetails：打印 gc 详细信息。 ","permalink":"https://XianCH.github.io/posts/tech/java/java%E9%9D%A2%E8%AF%95%E9%A2%98/","summary":"包含的模块 十九个模块，分别是： Java 基础、容器、多线程、反射、对象拷贝、Java Web 、异常、网络、设计模式、 Spring/Spring MVC、Spring Boot/Spring Cloud、Hibernate、MyBatis、RabbitMQ、Kafka、Zookeeper、 MySQL、Redis、JVM ，如下图所示： Java 基础 1. JDK 和","title":"java面试题"},{"content":"//查询未成年作家的评分在70以上的书籍 由于洋流影响所以作家和书籍可能出现重复，需要进行去重 List\u0026lt;Book\u0026gt; bookList = new ArrayList\u0026lt;\u0026gt;(); Set\u0026lt;Book\u0026gt; uniqueBookValues = new HashSet\u0026lt;\u0026gt;(); Set\u0026lt;Author\u0026gt; uniqueAuthorValues = new HashSet\u0026lt;\u0026gt;(); for (Author author : authors) { if (uniqueAuthorValues.add(author)) { if (author.getAge() \u0026lt; 18) { List\u0026lt;Book\u0026gt; books = author.getBooks(); for (Book book : books) { if (book.getScore() \u0026gt; 70) { if (uniqueBookValues.add(book)) { bookList.add(book); } } } } } } System.out.println(bookList); List\u0026lt;Book\u0026gt; collect = authors.stream() .distinct() .filter(author -\u0026gt; author.getAge() \u0026lt; 18) .map(author -\u0026gt; author.getBooks()) .flatMap(Collection::stream) .filter(book -\u0026gt; book.getScore() \u0026gt; 70) .distinct() .collect(Collectors.toList()); System.out.println(collect); 1.2 函数式编程思想 1.2.1 概念 ​\t面向对象思想需要关注用什么对象完成什么事情。而函数式编程思想就类似于我们数学中的函数。它主要关注的是对数据进行了什么操作。\n1.2.2 优点 代码简洁，开发快速 接近自然语言，易于理解 易于\u0026quot;并发编程\u0026quot; 2. Lambda表达式 2.1 概述 ​\tLambda是JDK8中一个语法糖。他可以对某些匿名内部类的写法进行简化。它是函数式编程思想的一个重要体现。让我们不用关注是什么对象。而是更关注我们对数据进行了什么操作。\n2.2 核心原则 可推导可省略\n2. 3 基本格式 (参数列表)-\u0026gt;{代码} 例一 我们在创建线程并启动时可以使用匿名内部类的写法：\nnew Thread(new Runnable() { @Override public void run() { System.out.println(\u0026#34;你知道吗 我比你想象的 更想在你身边\u0026#34;); } }).start(); 可以使用Lambda的格式对其进行修改。修改后如下：\nnew Thread(()-\u0026gt;{ System.out.println(\u0026#34;你知道吗 我比你想象的 更想在你身边\u0026#34;); }).start(); 例二: 现有方法定义如下，其中IntBinaryOperator是一个接口。先使用匿名内部类的写法调用该方法。\npublic static int calculateNum(IntBinaryOperator operator){ int a = 10; int b = 20; return operator.applyAsInt(a, b); } public static void main(String[] args) { int i = calculateNum(new IntBinaryOperator() { @Override public int applyAsInt(int left, int right) { return left + right; } }); System.out.println(i); } Lambda写法：\npublic static void main(String[] args) { int i = calculateNum((int left, int right)-\u0026gt;{ return left + right; }); System.out.println(i); } 例三： 现有方法定义如下，其中IntPredicate是一个接口。先使用匿名内部类的写法调用该方法。\npublic static void printNum(IntPredicate predicate){ int[] arr = {1,2,3,4,5,6,7,8,9,10}; for (int i : arr) { if(predicate.test(i)){ System.out.println(i); } } } public static void main(String[] args) { printNum(new IntPredicate() { @Override public boolean test(int value) { return value%2==0; } }); } Lambda写法：\npublic static void main(String[] args) { printNum((int value)-\u0026gt; { return value%2==0; }); } public static void printNum(IntPredicate predicate){ int[] arr = {1,2,3,4,5,6,7,8,9,10}; for (int i : arr) { if(predicate.test(i)){ System.out.println(i); } } } 例四： 现有方法定义如下，其中Function是一个接口。先使用匿名内部类的写法调用该方法。\npublic static \u0026lt;R\u0026gt; R typeConver(Function\u0026lt;String,R\u0026gt; function){ String str = \u0026#34;1235\u0026#34;; R result = function.apply(str); return result; } public static void main(String[] args) { Integer result = typeConver(new Function\u0026lt;String, Integer\u0026gt;() { @Override public Integer apply(String s) { return Integer.valueOf(s); } }); System.out.println(result); } Lambda写法：\nInteger result = typeConver((String s)-\u0026gt;{ return Integer.valueOf(s); }); System.out.println(result); 例五： 现有方法定义如下，其中IntConsumer是一个接口。先使用匿名内部类的写法调用该方法。\npublic static void foreachArr(IntConsumer consumer){ int[] arr = {1,2,3,4,5,6,7,8,9,10}; for (int i : arr) { consumer.accept(i); } } public static void main(String[] args) { foreachArr(new IntConsumer() { @Override public void accept(int value) { System.out.println(value); } }); } Lambda写法：\npublic static void main(String[] args) { foreachArr((int value)-\u0026gt;{ System.out.println(value); }); } 2.4 省略规则 参数类型可以省略 方法体只有一句代码时大括号return和唯一一句代码的分号可以省略 方法只有一个参数时小括号可以省略 以上这些规则都记不住也可以省略不记 3. Stream流 3.1 概述 ​\tJava8的Stream使用的是函数式编程模式，如同它的名字一样，它可以被用来对集合或数组进行链状流式的操作。可以更方便的让我们对集合或数组操作。\n3.2 案例数据准备 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.16\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; @Data @NoArgsConstructor @AllArgsConstructor @EqualsAndHashCode//用于后期的去重使用 public class Author { //id private Long id; //姓名 private String name; //年龄 private Integer age; //简介 private String intro; //作品 private List\u0026lt;Book\u0026gt; books; } @Data @AllArgsConstructor @NoArgsConstructor @EqualsAndHashCode//用于后期的去重使用 public class Book { //id private Long id; //书名 private String name; //分类 private String category; //评分 private Integer score; //简介 private String intro; } private static List\u0026lt;Author\u0026gt; getAuthors() { //数据初始化 Author author = new Author(1L,\u0026#34;蒙多\u0026#34;,33,\u0026#34;一个从菜刀中明悟哲理的祖安人\u0026#34;,null); Author author2 = new Author(2L,\u0026#34;亚拉索\u0026#34;,15,\u0026#34;狂风也追逐不上他的思考速度\u0026#34;,null); Author author3 = new Author(3L,\u0026#34;易\u0026#34;,14,\u0026#34;是这个世界在限制他的思维\u0026#34;,null); Author author4 = new Author(3L,\u0026#34;易\u0026#34;,14,\u0026#34;是这个世界在限制他的思维\u0026#34;,null); //书籍列表 List\u0026lt;Book\u0026gt; books1 = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Book\u0026gt; books2 = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Book\u0026gt; books3 = new ArrayList\u0026lt;\u0026gt;(); books1.add(new Book(1L,\u0026#34;刀的两侧是光明与黑暗\u0026#34;,\u0026#34;哲学,爱情\u0026#34;,88,\u0026#34;用一把刀划分了爱恨\u0026#34;)); books1.add(new Book(2L,\u0026#34;一个人不能死在同一把刀下\u0026#34;,\u0026#34;个人成长,爱情\u0026#34;,99,\u0026#34;讲述如何从失败中明悟真理\u0026#34;)); books2.add(new Book(3L,\u0026#34;那风吹不到的地方\u0026#34;,\u0026#34;哲学\u0026#34;,85,\u0026#34;带你用思维去领略世界的尽头\u0026#34;)); books2.add(new Book(3L,\u0026#34;那风吹不到的地方\u0026#34;,\u0026#34;哲学\u0026#34;,85,\u0026#34;带你用思维去领略世界的尽头\u0026#34;)); books2.add(new Book(4L,\u0026#34;吹或不吹\u0026#34;,\u0026#34;爱情,个人传记\u0026#34;,56,\u0026#34;一个哲学家的恋爱观注定很难把他所在的时代理解\u0026#34;)); books3.add(new Book(5L,\u0026#34;你的剑就是我的剑\u0026#34;,\u0026#34;爱情\u0026#34;,56,\u0026#34;无法想象一个武者能对他的伴侣这么的宽容\u0026#34;)); books3.add(new Book(6L,\u0026#34;风与剑\u0026#34;,\u0026#34;个人传记\u0026#34;,100,\u0026#34;两个哲学家灵魂和肉体的碰撞会激起怎么样的火花呢？\u0026#34;)); books3.add(new Book(6L,\u0026#34;风与剑\u0026#34;,\u0026#34;个人传记\u0026#34;,100,\u0026#34;两个哲学家灵魂和肉体的碰撞会激起怎么样的火花呢？\u0026#34;)); author.setBooks(books1); author2.setBooks(books2); author3.setBooks(books3); author4.setBooks(books3); List\u0026lt;Author\u0026gt; authorList = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(author,author2,author3,author4)); return authorList; } 3.3 快速入门 3.3.1 需求 ​\t我们可以调用getAuthors方法获取到作家的集合。现在需要打印所有年龄小于18的作家的名字，并且要注意去重。\n3.3.2 实现 //打印所有年龄小于18的作家的名字，并且要注意去重 List\u0026lt;Author\u0026gt; authors = getAuthors(); authors. stream()//把集合转换成流 .distinct()//先去除重复的作家 .filter(author -\u0026gt; author.getAge()\u0026lt;18)//筛选年龄小于18的 .forEach(author -\u0026gt; System.out.println(author.getName()));//遍历打印名字 3.4 常用操作 3.4.1 创建流 单列集合： 集合对象.stream()\nList\u0026lt;Author\u0026gt; authors = getAuthors(); Stream\u0026lt;Author\u0026gt; stream = authors.stream(); 数组：Arrays.stream(数组) 或者使用Stream.of来创建\nInteger[] arr = {1,2,3,4,5}; Stream\u0026lt;Integer\u0026gt; stream = Arrays.stream(arr); Stream\u0026lt;Integer\u0026gt; stream2 = Stream.of(arr); 双列集合：转换成单列集合后再创建\nMap\u0026lt;String,Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;蜡笔小新\u0026#34;,19); map.put(\u0026#34;黑子\u0026#34;,17); map.put(\u0026#34;日向翔阳\u0026#34;,16); Stream\u0026lt;Map.Entry\u0026lt;String, Integer\u0026gt;\u0026gt; stream = map.entrySet().stream(); 3.4.2 中间操作 filter ​\t可以对流中的元素进行条件过滤，符合过滤条件的才能继续留在流中。\n例如：\n​\t打印所有姓名长度大于1的作家的姓名\nList\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .filter(author -\u0026gt; author.getName().length()\u0026gt;1) .forEach(author -\u0026gt; System.out.println(author.getName())); map ​\t可以把对流中的元素进行计算或转换。\n例如：\n​\t打印所有作家的姓名\nList\u0026lt;Author\u0026gt; authors = getAuthors(); authors .stream() .map(author -\u0026gt; author.getName()) .forEach(name-\u0026gt;System.out.println(name)); // 打印所有作家的姓名 List\u0026lt;Author\u0026gt; authors = getAuthors(); // authors.stream() // .map(author -\u0026gt; author.getName()) // .forEach(s -\u0026gt; System.out.println(s)); authors.stream() .map(author -\u0026gt; author.getAge()) .map(age-\u0026gt;age+10) .forEach(age-\u0026gt; System.out.println(age)); distinct ​\t可以去除流中的重复元素。\n例如：\n​\t打印所有作家的姓名，并且要求其中不能有重复元素。\nList\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .distinct() .forEach(author -\u0026gt; System.out.println(author.getName())); 注意：distinct方法是依赖Object的equals方法来判断是否是相同对象的。所以需要注意重写equals方法。\nsorted ​\t可以对流中的元素进行排序。\n例如：\n​\t对流中的元素按照年龄进行降序排序，并且要求不能有重复的元素。\nList\u0026lt;Author\u0026gt; authors = getAuthors(); // 对流中的元素按照年龄进行降序排序，并且要求不能有重复的元素。 authors.stream() .distinct() .sorted() .forEach(author -\u0026gt; System.out.println(author.getAge())); List\u0026lt;Author\u0026gt; authors = getAuthors(); // 对流中的元素按照年龄进行降序排序，并且要求不能有重复的元素。 authors.stream() .distinct() .sorted((o1, o2) -\u0026gt; o2.getAge()-o1.getAge()) .forEach(author -\u0026gt; System.out.println(author.getAge())); 注意：如果调用空参的sorted()方法，需要流中的元素是实现了Comparable。\n​\nlimit ​\t可以设置流的最大长度，超出的部分将被抛弃。\n例如：\n​\t对流中的元素按照年龄进行降序排序，并且要求不能有重复的元素,然后打印其中年龄最大的两个作家的姓名。\nList\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .distinct() .sorted() .limit(2) .forEach(author -\u0026gt; System.out.println(author.getName())); skip ​\t跳过流中的前n个元素，返回剩下的元素\n例如：\n​\t打印除了年龄最大的作家外的其他作家，要求不能有重复元素，并且按照年龄降序排序。\n// 打印除了年龄最大的作家外的其他作家，要求不能有重复元素，并且按照年龄降序排序。 List\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .distinct() .sorted() .skip(1) .forEach(author -\u0026gt; System.out.println(author.getName())); flatMap ​\tmap只能把一个对象转换成另一个对象来作为流中的元素。而flatMap可以把一个对象转换成多个对象作为流中的元素。\n例一：\n​\t打印所有书籍的名字。要求对重复的元素进行去重。\n// 打印所有书籍的名字。要求对重复的元素进行去重。 List\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .flatMap(author -\u0026gt; author.getBooks().stream()) .distinct() .forEach(book -\u0026gt; System.out.println(book.getName())); 例二：\n​\t打印现有数据的所有分类。要求对分类进行去重。不能出现这种格式：哲学,爱情\n// 打印现有数据的所有分类。要求对分类进行去重。不能出现这种格式：哲学,爱情 爱情 List\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .flatMap(author -\u0026gt; author.getBooks().stream()) .distinct() .flatMap(book -\u0026gt; Arrays.stream(book.getCategory().split(\u0026#34;,\u0026#34;))) .distinct() .forEach(category-\u0026gt; System.out.println(category)); 3.4.3 终结操作 forEach ​\t对流中的元素进行遍历操作，我们通过传入的参数去指定对遍历到的元素进行什么具体操作。\n例子：\n​\t输出所有作家的名字\n// 输出所有作家的名字 List\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .map(author -\u0026gt; author.getName()) .distinct() .forEach(name-\u0026gt; System.out.println(name)); count ​\t可以用来获取当前流中元素的个数。\n例子：\n​\t打印这些作家的所出书籍的数目，注意删除重复元素。\n// 打印这些作家的所出书籍的数目，注意删除重复元素。 List\u0026lt;Author\u0026gt; authors = getAuthors(); long count = authors.stream() .flatMap(author -\u0026gt; author.getBooks().stream()) .distinct() .count(); System.out.println(count); max\u0026amp;min ​\t可以用来或者流中的最值。\n例子：\n​\t分别获取这些作家的所出书籍的最高分和最低分并打印。\n// 分别获取这些作家的所出书籍的最高分和最低分并打印。 //Stream\u0026lt;Author\u0026gt; -\u0026gt; Stream\u0026lt;Book\u0026gt; -\u0026gt;Stream\u0026lt;Integer\u0026gt; -\u0026gt;求值 List\u0026lt;Author\u0026gt; authors = getAuthors(); Optional\u0026lt;Integer\u0026gt; max = authors.stream() .flatMap(author -\u0026gt; author.getBooks().stream()) .map(book -\u0026gt; book.getScore()) .max((score1, score2) -\u0026gt; score1 - score2); Optional\u0026lt;Integer\u0026gt; min = authors.stream() .flatMap(author -\u0026gt; author.getBooks().stream()) .map(book -\u0026gt; book.getScore()) .min((score1, score2) -\u0026gt; score1 - score2); System.out.println(max.get()); System.out.println(min.get()); collect ​\t把当前流转换成一个集合。\n例子：\n​\t获取一个存放所有作者名字的List集合。\n// 获取一个存放所有作者名字的List集合。 List\u0026lt;Author\u0026gt; authors = getAuthors(); List\u0026lt;String\u0026gt; nameList = authors.stream() .map(author -\u0026gt; author.getName()) .collect(Collectors.toList()); System.out.println(nameList); ​\t获取一个所有书名的Set集合。\n// 获取一个所有书名的Set集合。 List\u0026lt;Author\u0026gt; authors = getAuthors(); Set\u0026lt;Book\u0026gt; books = authors.stream() .flatMap(author -\u0026gt; author.getBooks().stream()) .collect(Collectors.toSet()); System.out.println(books); ​\t获取一个Map集合，map的key为作者名，value为List\n// 获取一个Map集合，map的key为作者名，value为List\u0026lt;Book\u0026gt; List\u0026lt;Author\u0026gt; authors = getAuthors(); Map\u0026lt;String, List\u0026lt;Book\u0026gt;\u0026gt; map = authors.stream() .distinct() .collect(Collectors.toMap(author -\u0026gt; author.getName(), author -\u0026gt; author.getBooks())); System.out.println(map); 查找与匹配 anyMatch ​\t可以用来判断是否有任意符合匹配条件的元素，结果为boolean类型。\n例子：\n​\t判断是否有年龄在29以上的作家\n// 判断是否有年龄在29以上的作家 List\u0026lt;Author\u0026gt; authors = getAuthors(); boolean flag = authors.stream() .anyMatch(author -\u0026gt; author.getAge() \u0026gt; 29); System.out.println(flag); allMatch ​\t可以用来判断是否都符合匹配条件，结果为boolean类型。如果都符合结果为true，否则结果为false。\n例子：\n​\t判断是否所有的作家都是成年人\n// 判断是否所有的作家都是成年人 List\u0026lt;Author\u0026gt; authors = getAuthors(); boolean flag = authors.stream() .allMatch(author -\u0026gt; author.getAge() \u0026gt;= 18); System.out.println(flag); noneMatch ​\t可以判断流中的元素是否都不符合匹配条件。如果都不符合结果为true，否则结果为false\n例子：\n​\t判断作家是否都没有超过100岁的。\n// 判断作家是否都没有超过100岁的。 List\u0026lt;Author\u0026gt; authors = getAuthors(); boolean b = authors.stream() .noneMatch(author -\u0026gt; author.getAge() \u0026gt; 100); System.out.println(b); findAny ​\t获取流中的任意一个元素。该方法没有办法保证获取的一定是流中的第一个元素。\n例子：\n​\t获取任意一个年龄大于18的作家，如果存在就输出他的名字\n// 获取任意一个年龄大于18的作家，如果存在就输出他的名字 List\u0026lt;Author\u0026gt; authors = getAuthors(); Optional\u0026lt;Author\u0026gt; optionalAuthor = authors.stream() .filter(author -\u0026gt; author.getAge()\u0026gt;18) .findAny(); optionalAuthor.ifPresent(author -\u0026gt; System.out.println(author.getName())); findFirst ​\t获取流中的第一个元素。\n例子：\n​\t获取一个年龄最小的作家，并输出他的姓名。\n// 获取一个年龄最小的作家，并输出他的姓名。 List\u0026lt;Author\u0026gt; authors = getAuthors(); Optional\u0026lt;Author\u0026gt; first = authors.stream() .sorted((o1, o2) -\u0026gt; o1.getAge() - o2.getAge()) .findFirst(); first.ifPresent(author -\u0026gt; System.out.println(author.getName())); reduce归并 ​\t对流中的数据按照你指定的计算方式计算出一个结果。（缩减操作）\n​\treduce的作用是把stream中的元素给组合起来，我们可以传入一个初始值，它会按照我们的计算方式依次拿流中的元素和初始化值进行计算，计算结果再和后面的元素计算。\n​\treduce两个参数的重载形式内部的计算方式如下：\nT result = identity; for (T element : this stream) result = accumulator.apply(result, element) return result; ​\t其中identity就是我们可以通过方法参数传入的初始值，accumulator的apply具体进行什么计算也是我们通过方法参数来确定的。\n例子：\n​\t使用reduce求所有作者年龄的和\n// 使用reduce求所有作者年龄的和 List\u0026lt;Author\u0026gt; authors = getAuthors(); Integer sum = authors.stream() .distinct() .map(author -\u0026gt; author.getAge()) .reduce(0, (result, element) -\u0026gt; result + element); System.out.println(sum); ​\t使用reduce求所有作者中年龄的最大值\n// 使用reduce求所有作者中年龄的最大值 List\u0026lt;Author\u0026gt; authors = getAuthors(); Integer max = authors.stream() .map(author -\u0026gt; author.getAge()) .reduce(Integer.MIN_VALUE, (result, element) -\u0026gt; result \u0026lt; element ? element : result); System.out.println(max); ​\t使用reduce求所有作者中年龄的最小值\n// 使用reduce求所有作者中年龄的最小值 List\u0026lt;Author\u0026gt; authors = getAuthors(); Integer min = authors.stream() .map(author -\u0026gt; author.getAge()) .reduce(Integer.MAX_VALUE, (result, element) -\u0026gt; result \u0026gt; element ? element : result); System.out.println(min); ​\treduce一个参数的重载形式内部的计算\nboolean foundAny = false; T result = null; for (T element : this stream) { if (!foundAny) { foundAny = true; result = element; } else result = accumulator.apply(result, element); } return foundAny ? Optional.of(result) : Optional.empty(); ​\t如果用一个参数的重载方法去求最小值代码如下：\n// 使用reduce求所有作者中年龄的最小值 List\u0026lt;Author\u0026gt; authors = getAuthors(); Optional\u0026lt;Integer\u0026gt; minOptional = authors.stream() .map(author -\u0026gt; author.getAge()) .reduce((result, element) -\u0026gt; result \u0026gt; element ? element : result); minOptional.ifPresent(age-\u0026gt; System.out.println(age)); 3.5 注意事项 惰性求值（如果没有终结操作，没有中间操作是不会得到执行的） 流是一次性的（一旦一个流对象经过一个终结操作后。这个流就不能再被使用） 不会影响原数据（我们在流中可以多数据做很多处理。但是正常情况下是不会影响原来集合中的元素的。这往往也是我们期望的） 4. Optional 4.1 概述 ​\t我们在编写代码的时候出现最多的就是空指针异常。所以在很多情况下我们需要做各种非空的判断。\n​\t例如：\nAuthor author = getAuthor(); if(author!=null){ System.out.println(author.getName()); } ​\t尤其是对象中的属性还是一个对象的情况下。这种判断会更多。\n​\t而过多的判断语句会让我们的代码显得臃肿不堪。\n​\t所以在JDK8中引入了Optional,养成使用Optional的习惯后你可以写出更优雅的代码来避免空指针异常。\n​\t并且在很多函数式编程相关的API中也都用到了Optional，如果不会使用Optional也会对函数式编程的学习造成影响。\n4.2 使用 4.2.1 创建对象 ​\tOptional就好像是包装类，可以把我们的具体数据封装Optional对象内部。然后我们去使用Optional中封装好的方法操作封装进去的数据就可以非常优雅的避免空指针异常。\n​\t我们一般使用Optional的静态方法ofNullable来把数据封装成一个Optional对象。无论传入的参数是否为null都不会出现问题。\nAuthor author = getAuthor(); Optional\u0026lt;Author\u0026gt; authorOptional = Optional.ofNullable(author); ​\t你可能会觉得还要加一行代码来封装数据比较麻烦。但是如果改造下getAuthor方法，让其的返回值就是封装好的Optional的话，我们在使用时就会方便很多。\n​\t而且在实际开发中我们的数据很多是从数据库获取的。Mybatis从3.5版本可以也已经支持Optional了。我们可以直接把dao方法的返回值类型定义成Optional类型，MyBastis会自己把数据封装成Optional对象返回。封装的过程也不需要我们自己操作。\n​\t如果你确定一个对象不是空的则可以使用Optional的静态方法of来把数据封装成Optional对象。\nAuthor author = new Author(); Optional\u0026lt;Author\u0026gt; authorOptional = Optional.of(author); ​\t但是一定要注意，如果使用of的时候传入的参数必须不为null。（尝试下传入null会出现什么结果）\n​\t如果一个方法的返回值类型是Optional类型。而如果我们经判断发现某次计算得到的返回值为null，这个时候就需要把null封装成Optional对象返回。这时则可以使用Optional的静态方法empty来进行封装。\nOptional.empty() ​\n​\t所以最后你觉得哪种方式会更方便呢？ofNullable\n4.2.2 安全消费值 ​\t我们获取到一个Optional对象后肯定需要对其中的数据进行使用。这时候我们可以使用其ifPresent方法对来消费其中的值。\n​\t这个方法会判断其内封装的数据是否为空，不为空时才会执行具体的消费代码。这样使用起来就更加安全了。\n​\t例如,以下写法就优雅的避免了空指针异常。\nOptional\u0026lt;Author\u0026gt; authorOptional = Optional.ofNullable(getAuthor()); authorOptional.ifPresent(author -\u0026gt; System.out.println(author.getName())); 4.2.3 获取值 ​\t如果我们想获取值自己进行处理可以使用get方法获取，但是不推荐。因为当Optional内部的数据为空的时候会出现异常。\n4.2.4 安全获取值 ​\t如果我们期望安全的获取值。我们不推荐使用get方法，而是使用Optional提供的以下方法。\norElseGet\n获取数据并且设置数据为空时的默认值。如果数据不为空就能获取到该数据。如果为空则根据你传入的参数来创建对象作为默认值返回。\nOptional\u0026lt;Author\u0026gt; authorOptional = Optional.ofNullable(getAuthor()); Author author1 = authorOptional.orElseGet(() -\u0026gt; new Author()); orElseThrow\n获取数据，如果数据不为空就能获取到该数据。如果为空则根据你传入的参数来创建异常抛出。\nOptional\u0026lt;Author\u0026gt; authorOptional = Optional.ofNullable(getAuthor()); try { Author author = authorOptional.orElseThrow((Supplier\u0026lt;Throwable\u0026gt;) () -\u0026gt; new RuntimeException(\u0026#34;author为空\u0026#34;)); System.out.println(author.getName()); } catch (Throwable throwable) { throwable.printStackTrace(); } 4.2.5 过滤 ​\t我们可以使用filter方法对数据进行过滤。如果原本是有数据的，但是不符合判断，也会变成一个无数据的Optional对象。\nOptional\u0026lt;Author\u0026gt; authorOptional = Optional.ofNullable(getAuthor()); authorOptional.filter(author -\u0026gt; author.getAge()\u0026gt;100).ifPresent(author -\u0026gt; System.out.println(author.getName())); 4.2.6 判断 ​\t我们可以使用isPresent方法进行是否存在数据的判断。如果为空返回值为false,如果不为空，返回值为true。但是这种方式并不能体现Optional的好处，更推荐使用ifPresent方法。\nOptional\u0026lt;Author\u0026gt; authorOptional = Optional.ofNullable(getAuthor()); if (authorOptional.isPresent()) { System.out.println(authorOptional.get().getName()); } 4.2.7 数据转换 ​\tOptional还提供了map可以让我们的对数据进行转换，并且转换得到的数据也还是被Optional包装好的，保证了我们的使用安全。\n例如我们想获取作家的书籍集合。\nprivate static void testMap() { Optional\u0026lt;Author\u0026gt; authorOptional = getAuthorOptional(); Optional\u0026lt;List\u0026lt;Book\u0026gt;\u0026gt; optionalBooks = authorOptional.map(author -\u0026gt; author.getBooks()); optionalBooks.ifPresent(books -\u0026gt; System.out.println(books)); } 5. 函数式接口 5.1 概述 ​\t只有一个抽象方法的接口我们称之为函数接口。\n​\tJDK的函数式接口都加上了**@FunctionalInterface** 注解进行标识。但是无论是否加上该注解只要接口中只有一个抽象方法，都是函数式接口。\n5.2 常见函数式接口 ​\tConsumer 消费接口\n根据其中抽象方法的参数列表和返回值类型知道，我们可以在方法中对传入的参数进行消费。\n​\tFunction 计算转换接口\n根据其中抽象方法的参数列表和返回值类型知道，我们可以在方法中对传入的参数计算或转换，把结果返回\n​\tPredicate 判断接口\n根据其中抽象方法的参数列表和返回值类型知道，我们可以在方法中对传入的参数条件判断，返回判断结果\n​\tSupplier 生产型接口\n根据其中抽象方法的参数列表和返回值类型知道，我们可以在方法中创建对象，把创建好的对象返回\n5.3 常用的默认方法 and\n我们在使用Predicate接口时候可能需要进行判断条件的拼接。而and方法相当于是使用\u0026amp;\u0026amp;来拼接两个判断条件\n例如：\n打印作家中年龄大于17并且姓名的长度大于1的作家。\nList\u0026lt;Author\u0026gt; authors = getAuthors(); Stream\u0026lt;Author\u0026gt; authorStream = authors.stream(); authorStream.filter(new Predicate\u0026lt;Author\u0026gt;() { @Override public boolean test(Author author) { return author.getAge()\u0026gt;17; } }.and(new Predicate\u0026lt;Author\u0026gt;() { @Override public boolean test(Author author) { return author.getName().length()\u0026gt;1; } })).forEach(author -\u0026gt; System.out.println(author)); or\n我们在使用Predicate接口时候可能需要进行判断条件的拼接。而or方法相当于是使用||来拼接两个判断条件。\n例如：\n打印作家中年龄大于17或者姓名的长度小于2的作家。\n// 打印作家中年龄大于17或者姓名的长度小于2的作家。 List\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .filter(new Predicate\u0026lt;Author\u0026gt;() { @Override public boolean test(Author author) { return author.getAge()\u0026gt;17; } }.or(new Predicate\u0026lt;Author\u0026gt;() { @Override public boolean test(Author author) { return author.getName().length()\u0026lt;2; } })).forEach(author -\u0026gt; System.out.println(author.getName())); negate\nPredicate接口中的方法。negate方法相当于是在判断添加前面加了个! 表示取反\n例如：\n打印作家中年龄不大于17的作家。\n// 打印作家中年龄不大于17的作家。 List\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .filter(new Predicate\u0026lt;Author\u0026gt;() { @Override public boolean test(Author author) { return author.getAge()\u0026gt;17; } }.negate()).forEach(author -\u0026gt; System.out.println(author.getAge())); 6. 方法引用 ​\t我们在使用lambda时，如果方法体中只有一个方法的调用的话（包括构造方法）,我们可以用方法引用进一步简化代码。\n6.1 推荐用法 ​\t我们在使用lambda时不需要考虑什么时候用方法引用，用哪种方法引用，方法引用的格式是什么。我们只需要在写完lambda方法发现方法体只有一行代码，并且是方法的调用时使用快捷键尝试是否能够转换成方法引用即可。\n​\t当我们方法引用使用的多了慢慢的也可以直接写出方法引用。\n6.2 基本格式 ​\t类名或者对象名::方法名\n6.3 语法详解(了解) 6.3.1 引用类的静态方法 ​\t其实就是引用类的静态方法\n格式 类名::方法名 使用前提 ​\t如果我们在重写方法的时候，方法体中只有一行代码，并且这行代码是调用了某个类的静态方法，并且我们把要重写的抽象方法中所有的参数都按照顺序传入了这个静态方法中，这个时候我们就可以引用类的静态方法。\n​\n例如：\n如下代码就可以用方法引用进行简化\nList\u0026lt;Author\u0026gt; authors = getAuthors(); Stream\u0026lt;Author\u0026gt; authorStream = authors.stream(); authorStream.map(author -\u0026gt; author.getAge()) .map(age-\u0026gt;String.valueOf(age)); 注意，如果我们所重写的方法是没有参数的，调用的方法也是没有参数的也相当于符合以上规则。\n优化后如下：\nList\u0026lt;Author\u0026gt; authors = getAuthors(); Stream\u0026lt;Author\u0026gt; authorStream = authors.stream(); authorStream.map(author -\u0026gt; author.getAge()) .map(String::valueOf); 6.3.2 引用对象的实例方法 格式 对象名::方法名 使用前提 ​\t如果我们在重写方法的时候，方法体中只有一行代码，并且这行代码是调用了某个对象的成员方法，并且我们把要重写的抽象方法中所有的参数都按照顺序传入了这个成员方法中，这个时候我们就可以引用对象的实例方法\n例如：\nList\u0026lt;Author\u0026gt; authors = getAuthors(); Stream\u0026lt;Author\u0026gt; authorStream = authors.stream(); StringBuilder sb = new StringBuilder(); authorStream.map(author -\u0026gt; author.getName()) .forEach(name-\u0026gt;sb.append(name)); 优化后：\nList\u0026lt;Author\u0026gt; authors = getAuthors(); Stream\u0026lt;Author\u0026gt; authorStream = authors.stream(); StringBuilder sb = new StringBuilder(); authorStream.map(author -\u0026gt; author.getName()) .forEach(sb::append); 6.3.4 引用类的实例方法 格式 类名::方法名 使用前提 ​\t如果我们在重写方法的时候，方法体中只有一行代码，并且这行代码是调用了第一个参数的成员方法，并且我们把要重写的抽象方法中剩余的所有的参数都按照顺序传入了这个成员方法中，这个时候我们就可以引用类的实例方法。\n例如：\ninterface UseString{ String use(String str,int start,int length); } public static String subAuthorName(String str, UseString useString){ int start = 0; int length = 1; return useString.use(str,start,length); } public static void main(String[] args) { subAuthorName(\u0026#34;三更草堂\u0026#34;, new UseString() { @Override public String use(String str, int start, int length) { return str.substring(start,length); } }); } 优化后如下：\npublic static void main(String[] args) { subAuthorName(\u0026#34;三更草堂\u0026#34;, String::substring); } 6.3.5 构造器引用 ​\t如果方法体中的一行代码是构造器的话就可以使用构造器引用。\n格式 类名::new 使用前提 ​\t如果我们在重写方法的时候，方法体中只有一行代码，并且这行代码是调用了某个类的构造方法，并且我们把要重写的抽象方法中的所有的参数都按照顺序传入了这个构造方法中，这个时候我们就可以引用构造器。\n例如：\nList\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .map(author -\u0026gt; author.getName()) .map(name-\u0026gt;new StringBuilder(name)) .map(sb-\u0026gt;sb.append(\u0026#34;-三更\u0026#34;).toString()) .forEach(str-\u0026gt; System.out.println(str)); 优化后：\nList\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .map(author -\u0026gt; author.getName()) .map(StringBuilder::new) .map(sb-\u0026gt;sb.append(\u0026#34;-三更\u0026#34;).toString()) .forEach(str-\u0026gt; System.out.println(str)); 7. 高级用法 基本数据类型优化 ​\t我们之前用到的很多Stream的方法由于都使用了泛型。所以涉及到的参数和返回值都是引用数据类型。\n​\t即使我们操作的是整数小数，但是实际用的都是他们的包装类。JDK5中引入的自动装箱和自动拆箱让我们在使用对应的包装类时就好像使用基本数据类型一样方便。但是你一定要知道装箱和拆箱肯定是要消耗时间的。虽然这个时间消耗很下。但是在大量的数据不断的重复装箱拆箱的时候，你就不能无视这个时间损耗了。\n​\t所以为了让我们能够对这部分的时间消耗进行优化。Stream还提供了很多专门针对基本数据类型的方法。\n​\t例如：mapToInt,mapToLong,mapToDouble,flatMapToInt,flatMapToDouble等。\nprivate static void test27() { List\u0026lt;Author\u0026gt; authors = getAuthors(); authors.stream() .map(author -\u0026gt; author.getAge()) .map(age -\u0026gt; age + 10) .filter(age-\u0026gt;age\u0026gt;18) .map(age-\u0026gt;age+2) .forEach(System.out::println); authors.stream() .mapToInt(author -\u0026gt; author.getAge()) .map(age -\u0026gt; age + 10) .filter(age-\u0026gt;age\u0026gt;18) .map(age-\u0026gt;age+2) .forEach(System.out::println); } 并行流 ​\t当流中有大量元素时，我们可以使用并行流去提高操作的效率。其实并行流就是把任务分配给多个线程去完全。如果我们自己去用代码实现的话其实会非常的复杂，并且要求你对并发编程有足够的理解和认识。而如果我们使用Stream的话，我们只需要修改一个方法的调用就可以使用并行流来帮我们实现，从而提高效率。\n​\tparallel方法可以把串行流转换成并行流。\nprivate static void test28() { Stream\u0026lt;Integer\u0026gt; stream = Stream.of(1, 2, 3, 4, 5, 6, 7, 8, 9, 10); Integer sum = stream.parallel() .peek(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer num) { System.out.println(num+Thread.currentThread().getName()); } }) .filter(num -\u0026gt; num \u0026gt; 5) .reduce((result, ele) -\u0026gt; result + ele) .get(); System.out.println(sum); } ​\t也可以通过parallelStream直接获取并行流对象。\nList\u0026lt;Author\u0026gt; authors = getAuthors(); authors.parallelStream() .map(author -\u0026gt; author.getAge()) .map(age -\u0026gt; age + 10) .filter(age-\u0026gt;age\u0026gt;18) .map(age-\u0026gt;age+2) .forEach(System.out::println); ","permalink":"https://XianCH.github.io/posts/tech/java/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/","summary":"//查询未成年作家的评分在70以上的书籍 由于洋流影响所以作家和书籍可能出现重复，需要进行去重 List\u0026lt;Book\u0026gt; bookList = new ArrayList\u0026lt;\u0026gt;(); Set\u0026lt;Book\u0026gt; uniqueBookValues = new HashSet\u0026lt;\u0026gt;(); Set\u0026lt;Author\u0026gt; uniqueAuthorValues = new HashSet\u0026lt;\u0026gt;(); for (Author author : authors) { if (uniqueAuthorValues.add(author)) { if (author.getAge() \u0026lt; 18) { List\u0026lt;Book\u0026gt; books = author.getBooks(); for (Book book : books) { if (book.getScore() \u0026gt; 70) { if (uniqueBookValues.add(book)) { bookList.add(book); } } } } } } System.out.println(bookList); List\u0026lt;Book\u0026gt; collect = authors.stream() .distinct() .filter(author -\u0026gt; author.getAge() \u0026lt; 18) .map(author -\u0026gt; author.getBooks()) .flatMap(Collection::stream) .filter(book -\u0026gt; book.getScore() \u0026gt; 70) .distinct() .collect(Collectors.toList()); System.out.println(collect); 1.2 函数式编程思想 1.2.1 概念 ​ 面向对象思","title":"java函数式编程思想"},{"content":"微服务保护 1.初识Sentinel 1.1.雪崩问题及解决方案 1.1.1.雪崩问题 微服务中，服务间调用关系错综复杂，一个微服务往往依赖于多个其它微服务。\n如图，如果服务提供者I发生了故障，当前的应用的部分业务因为依赖于服务I，因此也会被阻塞。此时，其它不依赖于服务I的业务似乎不受影响。\n但是，依赖服务I的业务请求被阻塞，用户不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞：\n服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，那么当前服务也就不可用了。\n那么，依赖于当前服务的其它服务随着时间的推移，最终也都会变的不可用，形成级联失败，雪崩就发生了：\n1.1.2.超时处理 解决雪崩问题的常见方式有四种：\n•超时处理：设定超时时间，请求超过一定时间没有响应就返回错误信息，不会无休止等待\n1.1.3.仓壁模式 方案2：仓壁模式\n仓壁模式来源于船舱的设计：\n船舱都会被隔板分离为多个独立空间，当船体破损时，只会导致部分空间进入，将故障控制在一定范围内，避免整个船体都被淹没。\n于此类似，我们可以限定每个业务能使用的线程数，避免耗尽整个tomcat的资源，因此也叫线程隔离。\n1.1.4.断路器 断路器模式：由断路器统计业务执行的异常比例，如果超出阈值则会熔断该业务，拦截访问该业务的一切请求。\n断路器会统计访问某个服务的请求数量，异常比例：\n当发现访问服务D的请求异常比例过高时，认为服务D有导致雪崩的风险，会拦截访问服务D的一切请求，形成熔断：\n1.1.5.限流 流量控制：限制业务访问的QPS，避免服务因流量的突增而故障。\n1.1.6.总结 什么是雪崩问题？\n微服务之间相互调用，因为调用链中的一个服务故障，引起整个链路都无法访问的情况。 可以认为：\n限流是对服务的保护，避免因瞬间高并发流量而导致服务故障，进而避免雪崩。是一种预防措施。\n超时处理、线程隔离、降级熔断是在部分服务故障时，将故障控制在一定范围，避免雪崩。是一种补救措施。\n1.2.服务保护技术对比 在SpringCloud当中支持多种服务保护技术：\nNetfix Hystrix Sentinel Resilience4J 早期比较流行的是Hystrix框架，但目前国内实用最广泛的还是阿里巴巴的Sentinel框架，这里我们做下对比：\nSentinel Hystrix 隔离策略 信号量隔离 线程池隔离/信号量隔离 熔断降级策略 基于慢调用比例或异常比例 基于失败比率 实时指标实现 滑动窗口 滑动窗口（基于 RxJava） 规则配置 支持多种数据源 支持多种数据源 扩展性 多个扩展点 插件的形式 基于注解的支持 支持 支持 限流 基于 QPS，支持基于调用关系的限流 有限的支持 流量整形 支持慢启动、匀速排队模式 不支持 系统自适应保护 支持 不支持 控制台 开箱即用，可配置规则、查看秒级监控、机器发现等 不完善 常见框架的适配 Servlet、Spring Cloud、Dubbo、gRPC 等 Servlet、Spring Cloud Netflix 1.3.Sentinel介绍和安装 1.3.1.初识Sentinel Sentinel是阿里巴巴开源的一款微服务流量控制组件。官网地址：https://sentinelguard.io/zh-cn/index.html\nSentinel 具有以下特征:\n•丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。\n•完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。\n•广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。\n•完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。\n1.3.2.安装Sentinel 1）下载\nsentinel官方提供了UI控制台，方便我们对系统做限流设置。大家可以在GitHub下载。\n课前资料也提供了下载好的jar包：\n2）运行\n将jar包放到任意非中文目录，执行命令：\njava -jar sentinel-dashboard-1.8.1.jar 如果要修改Sentinel的默认端口、账户、密码，可以通过下列配置：\n配置项 默认值 说明 server.port 8080 服务端口 sentinel.dashboard.auth.username sentinel 默认用户名 sentinel.dashboard.auth.password sentinel 默认密码 例如，修改端口：\njava -Dserver.port=8090 -jar sentinel-dashboard-1.8.1.jar 3）访问\n访问http://localhost:8080页面，就可以看到sentinel的控制台了：\n需要输入账号和密码，默认都是：sentinel\n登录后，发现一片空白，什么都没有：\n这是因为我们还没有与微服务整合。\n1.4.微服务整合Sentinel 我们在order-service中整合sentinel，并连接sentinel的控制台，步骤如下：\n1）引入sentinel依赖\n\u0026lt;!--sentinel--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-sentinel\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2）配置控制台\n修改application.yaml文件，添加下面内容：\nserver: port: 8088 spring: cloud: sentinel: transport: dashboard: localhost:8080 3）访问order-service的任意端点\n打开浏览器，访问http://localhost:8088/order/101，这样才能触发sentinel的监控。\n然后再访问sentinel的控制台，查看效果：\n2.流量控制 雪崩问题虽然有四种方案，但是限流是避免服务因突发的流量而发生故障，是对微服务雪崩问题的预防。我们先学习这种模式。\n2.1.簇点链路 当请求进入微服务时，首先会访问DispatcherServlet，然后进入Controller、Service、Mapper，这样的一个调用链就叫做簇点链路。簇点链路中被监控的每一个接口就是一个资源。\n默认情况下sentinel会监控SpringMVC的每一个端点（Endpoint，也就是controller中的方法），因此SpringMVC的每一个端点（Endpoint）就是调用链路中的一个资源。\n例如，我们刚才访问的order-service中的OrderController中的端点：/order/{orderId}\n流控、熔断等都是针对簇点链路中的资源来设置的，因此我们可以点击对应资源后面的按钮来设置规则：\n流控：流量控制 降级：降级熔断 热点：热点参数限流，是限流的一种 授权：请求的权限控制 2.1.快速入门 2.1.1.示例 点击资源/order/{orderId}后面的流控按钮，就可以弹出表单。\n表单中可以填写限流规则，如下：\n其含义是限制 /order/{orderId}这个资源的单机QPS为1，即每秒只允许1次请求，超出的请求会被拦截并报错。\n2.1.2.练习： 需求：给 /order/{orderId}这个资源设置流控规则，QPS不能超过 5，然后测试。\n1）首先在sentinel控制台添加限流规则\n2）利用jmeter测试\n如果没有用过jmeter，可以参考课前资料提供的文档《Jmeter快速入门.md》\n课前资料提供了编写好的Jmeter测试样例：\n打开jmeter，导入课前资料提供的测试样例：\n选择：\n20个用户，2秒内运行完，QPS是10，超过了5.\n选中流控入门，QPS\u0026lt;5右键运行：\n注意，不要点击菜单中的执行按钮来运行。\n结果：\n可以看到，成功的请求每次只有5个\n2.2.流控模式 在添加限流规则时，点击高级选项，可以选择三种流控模式：\n直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式 关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流 链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流 快速入门测试的就是直接模式。\n2.2.1.关联模式 关联模式：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流\n配置规则：\n语法说明：当/write资源访问量触发阈值时，就会对/read资源限流，避免影响/write资源。\n使用场景：比如用户支付时需要修改订单状态，同时用户要查询订单。查询和修改操作会争抢数据库锁，产生竞争。业务需求是优先支付和更新订单的业务，因此当修改订单业务触发阈值时，需要对查询订单业务限流。\n需求说明：\n在OrderController新建两个端点：/order/query和/order/update，无需实现业务\n配置流控规则，当/order/ update资源被访问的QPS超过5时，对/order/query请求限流\n1）定义/order/query端点，模拟订单查询\n@GetMapping(\u0026#34;/query\u0026#34;) public String queryOrder() { return \u0026#34;查询订单成功\u0026#34;; } 2）定义/order/update端点，模拟订单更新\n@GetMapping(\u0026#34;/update\u0026#34;) public String updateOrder() { return \u0026#34;更新订单成功\u0026#34;; } 重启服务，查看sentinel控制台的簇点链路：\n3）配置流控规则\n对哪个端点限流，就点击哪个端点后面的按钮。我们是对订单查询/order/query限流，因此点击它后面的按钮：\n在表单中填写流控规则：\n4）在Jmeter测试\n选择《流控模式-关联》：\n可以看到1000个用户，100秒，因此QPS为10，超过了我们设定的阈值：5\n查看http请求：\n请求的目标是/order/update，这样这个断点就会触发阈值。\n但限流的目标是/order/query，我们在浏览器访问，可以发现：\n确实被限流了。\n5）总结\n2.2.2.链路模式 链路模式：只针对从指定链路访问到本资源的请求做统计，判断是否超过阈值。\n配置示例：\n例如有两条请求链路：\n/test1 \u0026ndash;\u0026gt; /common\n/test2 \u0026ndash;\u0026gt; /common\n如果只希望统计从/test2进入到/common的请求，则可以这样配置：\n实战案例\n需求：有查询订单和创建订单业务，两者都需要查询商品。针对从查询订单进入到查询商品的请求统计，并设置限流。\n步骤：\n在OrderService中添加一个queryGoods方法，不用实现业务\n在OrderController中，改造/order/query端点，调用OrderService中的queryGoods方法\n在OrderController中添加一个/order/save的端点，调用OrderService的queryGoods方法\n给queryGoods设置限流规则，从/order/query进入queryGoods的方法限制QPS必须小于2\n实现：\n1）添加查询商品方法 在order-service服务中，给OrderService类添加一个queryGoods方法：\npublic void queryGoods(){ System.err.println(\u0026#34;查询商品\u0026#34;); } 2）查询订单时，查询商品 在order-service的OrderController中，修改/order/query端点的业务逻辑：\n@GetMapping(\u0026#34;/query\u0026#34;) public String queryOrder() { // 查询商品 orderService.queryGoods(); // 查询订单 System.out.println(\u0026#34;查询订单\u0026#34;); return \u0026#34;查询订单成功\u0026#34;; } 3）新增订单，查询商品 在order-service的OrderController中，修改/order/save端点，模拟新增订单：\n@GetMapping(\u0026#34;/save\u0026#34;) public String saveOrder() { // 查询商品 orderService.queryGoods(); // 查询订单 System.err.println(\u0026#34;新增订单\u0026#34;); return \u0026#34;新增订单成功\u0026#34;; } 4）给查询商品添加资源标记 默认情况下，OrderService中的方法是不被Sentinel监控的，需要我们自己通过注解来标记要监控的方法。\n给OrderService的queryGoods方法添加@SentinelResource注解：\n@SentinelResource(\u0026#34;goods\u0026#34;) public void queryGoods(){ System.err.println(\u0026#34;查询商品\u0026#34;); } 链路模式中，是对不同来源的两个链路做监控。但是sentinel默认会给进入SpringMVC的所有请求设置同一个root资源，会导致链路模式失效。\n我们需要关闭这种对SpringMVC的资源聚合，修改order-service服务的application.yml文件：\nspring: cloud: sentinel: web-context-unify: false # 关闭context整合 重启服务，访问/order/query和/order/save，可以查看到sentinel的簇点链路规则中，出现了新的资源：\n5）添加流控规则 点击goods资源后面的流控按钮，在弹出的表单中填写下面信息：\n只统计从/order/query进入/goods的资源，QPS阈值为2，超出则被限流。\n6）Jmeter测试 选择《流控模式-链路》：\n可以看到这里200个用户，50秒内发完，QPS为4，超过了我们设定的阈值2\n一个http请求是访问/order/save：\n运行的结果：\n完全不受影响。\n另一个是访问/order/query：\n运行结果：\n每次只有2个通过。\n2.2.3.总结 流控模式有哪些？\n•直接：对当前资源限流\n•关联：高优先级资源触发阈值，对低优先级资源限流。\n•链路：阈值统计时，只统计从指定资源进入当前资源的请求，是对请求来源的限流\n2.3.流控效果 在流控的高级选项中，还有一个流控效果选项：\n流控效果是指请求达到流控阈值时应该采取的措施，包括三种：\n快速失败：达到阈值后，新的请求会被立即拒绝并抛出FlowException异常。是默认的处理方式。\nwarm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值。\n排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长\n2.3.1.warm up 阈值一般是一个微服务能承担的最大QPS，但是一个服务刚刚启动时，一切资源尚未初始化（冷启动），如果直接将QPS跑到最大值，可能导致服务瞬间宕机。\nwarm up也叫预热模式，是应对服务冷启动的一种方案。请求阈值初始值是 maxThreshold / coldFactor，持续指定时长后，逐渐提高到maxThreshold值。而coldFactor的默认值是3.\n例如，我设置QPS的maxThreshold为10，预热时间为5秒，那么初始阈值就是 10 / 3 ，也就是3，然后在5秒后逐渐增长到10.\n案例\n需求：给/order/{orderId}这个资源设置限流，最大QPS为10，利用warm up效果，预热时长为5秒\n1）配置流控规则： 2）Jmeter测试 选择《流控效果，warm up》：\nQPS为10.\n刚刚启动时，大部分请求失败，成功的只有3个，说明QPS被限定在3：\n随着时间推移，成功比例越来越高：\n到Sentinel控制台查看实时监控：\n一段时间后：\n2.3.2.排队等待 当请求超过QPS阈值时，快速失败和warm up 会拒绝新的请求并抛出异常。\n而排队等待则是让所有请求进入一个队列中，然后按照阈值允许的时间间隔依次执行。后来的请求必须等待前面执行完成，如果请求预期的等待时间超出最大时长，则会被拒绝。\n工作原理\n例如：QPS = 5，意味着每200ms处理一个队列中的请求；timeout = 2000，意味着预期等待时长超过2000ms的请求会被拒绝并抛出异常。\n那什么叫做预期等待时长呢？\n比如现在一下子来了12 个请求，因为每200ms执行一个请求，那么：\n第6个请求的预期等待时长 = 200 * （6 - 1） = 1000ms 第12个请求的预期等待时长 = 200 * （12-1） = 2200ms 现在，第1秒同时接收到10个请求，但第2秒只有1个请求，此时QPS的曲线这样的：\n如果使用队列模式做流控，所有进入的请求都要排队，以固定的200ms的间隔执行，QPS会变的很平滑：\n平滑的QPS曲线，对于服务器来说是更友好的。\n案例\n需求：给/order/{orderId}这个资源设置限流，最大QPS为10，利用排队的流控效果，超时时长设置为5s\n1）添加流控规则 2）Jmeter测试 选择《流控效果，队列》：\nQPS为15，已经超过了我们设定的10。\n如果是之前的 快速失败、warmup模式，超出的请求应该会直接报错。\n但是我们看看队列模式的运行结果：\n全部都通过了。\n再去sentinel查看实时监控的QPS曲线：\nQPS非常平滑，一致保持在10，但是超出的请求没有被拒绝，而是放入队列。因此响应时间（等待时间）会越来越长。\n当队列满了以后，才会有部分请求失败：\n2.3.3.总结 流控效果有哪些？\n快速失败：QPS超过阈值时，拒绝新的请求\nwarm up： QPS超过阈值时，拒绝新的请求；QPS阈值是逐渐提升的，可以避免冷启动时高并发导致服务宕机。\n排队等待：请求会进入队列，按照阈值允许的时间间隔依次执行请求；如果请求预期等待时长大于超时时间，直接拒绝\n2.4.热点参数限流 之前的限流是统计访问某个资源的所有请求，判断是否超过QPS阈值。而热点参数限流是分别统计参数值相同的请求，判断是否超过QPS阈值。\n2.4.1.全局参数限流 例如，一个根据id查询商品的接口：\n访问/goods/{id}的请求中，id参数值会有变化，热点参数限流会根据参数值分别统计QPS，统计结果：\n当id=1的请求触发阈值被限流时，id值不为1的请求不受影响。\n配置示例：\n代表的含义是：对hot这个资源的0号参数（第一个参数）做统计，每1秒相同参数值的请求数不能超过5\n2.4.2.热点参数限流 刚才的配置中，对查询商品这个接口的所有商品一视同仁，QPS都限定为5.\n而在实际开发中，可能部分商品是热点商品，例如秒杀商品，我们希望这部分商品的QPS限制与其它商品不一样，高一些。那就需要配置热点参数限流的高级选项了：\n结合上一个配置，这里的含义是对0号的long类型参数限流，每1秒相同参数的QPS不能超过5，有两个例外：\n•如果参数值是100，则每1秒允许的QPS为10\n•如果参数值是101，则每1秒允许的QPS为15\n2.4.4.案例 案例需求：给/order/{orderId}这个资源添加热点参数限流，规则如下：\n•默认的热点参数规则是每1秒请求量不超过2\n•给102这个参数设置例外：每1秒请求量不超过4\n•给103这个参数设置例外：每1秒请求量不超过10\n注意事项：热点参数限流对默认的SpringMVC资源无效，需要利用@SentinelResource注解标记资源\n1）标记资源 给order-service中的OrderController中的/order/{orderId}资源添加注解：\n2）热点参数限流规则 访问该接口，可以看到我们标记的hot资源出现了：\n这里不要点击hot后面的按钮，页面有BUG\n点击左侧菜单中热点规则菜单：\n点击新增，填写表单：\n3）Jmeter测试 选择《热点参数限流 QPS1》：\n这里发起请求的QPS为5.\n包含3个http请求：\n普通参数，QPS阈值为2\n运行结果：\n例外项，QPS阈值为4\n运行结果：\n例外项，QPS阈值为10\n运行结果：\n3.隔离和降级 限流是一种预防措施，虽然限流可以尽量避免因高并发而引起的服务故障，但服务还会因为其它原因而故障。\n而要将这些故障控制在一定范围，避免雪崩，就要靠线程隔离（舱壁模式）和熔断降级手段了。\n线程隔离之前讲到过：调用者在调用服务提供者时，给每个调用的请求分配独立线程池，出现故障时，最多消耗这个线程池内资源，避免把调用者的所有资源耗尽。\n熔断降级：是在调用方这边加入断路器，统计对服务提供者的调用，如果调用的失败比例过高，则熔断该业务，不允许访问该服务的提供者了。\n可以看到，不管是线程隔离还是熔断降级，都是对客户端（调用方）的保护。需要在调用方 发起远程调用时做线程隔离、或者服务熔断。\n而我们的微服务远程调用都是基于Feign来完成的，因此我们需要将Feign与Sentinel整合，在Feign里面实现线程隔离和服务熔断。\n3.1.FeignClient整合Sentinel SpringCloud中，微服务调用都是通过Feign来实现的，因此做客户端保护必须整合Feign和Sentinel。\n3.1.1.修改配置，开启sentinel功能 修改OrderService的application.yml文件，开启Feign的Sentinel功能：\nfeign: sentinel: enabled: true # 开启feign对sentinel的支持 3.1.2.编写失败降级逻辑 业务失败后，不能直接报错，而应该返回用户一个友好提示或者默认结果，这个就是失败降级逻辑。\n给FeignClient编写失败后的降级逻辑\n①方式一：FallbackClass，无法对远程调用的异常做处理\n②方式二：FallbackFactory，可以对远程调用的异常做处理，我们选择这种\n这里我们演示方式二的失败降级处理。\n步骤一：在feing-api项目中定义类，实现FallbackFactory：\n代码：\npackage cn.itcast.feign.clients.fallback; import cn.itcast.feign.clients.UserClient; import cn.itcast.feign.pojo.User; import feign.hystrix.FallbackFactory; import lombok.extern.slf4j.Slf4j; @Slf4j public class UserClientFallbackFactory implements FallbackFactory\u0026lt;UserClient\u0026gt; { @Override public UserClient create(Throwable throwable) { return new UserClient() { @Override public User findById(Long id) { log.error(\u0026#34;查询用户异常\u0026#34;, throwable); return new User(); } }; } } 步骤二：在feing-api项目中的DefaultFeignConfiguration类中将UserClientFallbackFactory注册为一个Bean：\n@Bean public UserClientFallbackFactory userClientFallbackFactory(){ return new UserClientFallbackFactory(); } 步骤三：在feing-api项目中的UserClient接口中使用UserClientFallbackFactory：\nimport cn.itcast.feign.clients.fallback.UserClientFallbackFactory; import cn.itcast.feign.pojo.User; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @FeignClient(value = \u0026#34;userservice\u0026#34;, fallbackFactory = UserClientFallbackFactory.class) public interface UserClient { @GetMapping(\u0026#34;/user/{id}\u0026#34;) User findById(@PathVariable(\u0026#34;id\u0026#34;) Long id); } 重启后，访问一次订单查询业务，然后查看sentinel控制台，可以看到新的簇点链路：\n3.1.3.总结 Sentinel支持的雪崩解决方案：\n线程隔离（仓壁模式） 降级熔断 Feign整合Sentinel的步骤：\n在application.yml中配置：feign.sentienl.enable=true 给FeignClient编写FallbackFactory并注册为Bean 将FallbackFactory配置到FeignClient 3.2.线程隔离（舱壁模式） 3.2.1.线程隔离的实现方式 线程隔离有两种方式实现：\n线程池隔离\n信号量隔离（Sentinel默认采用）\n如图：\n线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果\n信号量隔离：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求。\n两者的优缺点：\n3.2.2.sentinel的线程隔离 用法说明：\n在添加限流规则时，可以选择两种阈值类型：\nQPS：就是每秒的请求数，在快速入门中已经演示过\n线程数：是该资源能使用用的tomcat线程数的最大值。也就是通过限制线程数量，实现线程隔离（舱壁模式）。\n案例需求：给 order-service服务中的UserClient的查询用户接口设置流控规则，线程数不能超过 2。然后利用jemeter测试。\n1）配置隔离规则 选择feign接口后面的流控按钮：\n填写表单：\n2）Jmeter测试 选择《阈值类型-线程数\u0026lt;2》：\n一次发生10个请求，有较大概率并发线程数超过2，而超出的请求会走之前定义的失败降级逻辑。\n查看运行结果：\n发现虽然结果都是通过了，不过部分请求得到的响应是降级返回的null信息。\n3.2.3.总结 线程隔离的两种手段是？\n信号量隔离\n线程池隔离\n信号量隔离的特点是？\n基于计数器模式，简单，开销小 线程池隔离的特点是？\n基于线程池模式，有额外开销，但隔离控制更强 3.3.熔断降级 熔断降级是解决雪崩问题的重要手段。其思路是由断路器统计服务调用的异常比例、慢请求比例，如果超出阈值则会熔断该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。\n断路器控制熔断和放行是通过状态机来完成的：\n状态机包括三个状态：\nclosed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态 open：打开状态，服务调用被熔断，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态 half-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作。 请求成功：则切换到closed状态 请求失败：则切换到open状态 断路器熔断策略有三种：慢调用、异常比例、异常数\n3.3.1.慢调用 慢调用：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求。在指定时间内，如果请求数量超过设定的最小数量，慢调用比例大于设定的阈值，则触发熔断。\n例如：\n解读：RT超过500ms的调用是慢调用，统计最近10000ms内的请求，如果请求量超过10次，并且慢调用比例不低于0.5，则触发熔断，熔断时长为5秒。然后进入half-open状态，放行一次请求做测试。\n案例\n需求：给 UserClient的查询用户接口设置降级规则，慢调用的RT阈值为50ms，统计时间为1秒，最小请求数量为5，失败阈值比例为0.4，熔断时长为5\n1）设置慢调用 修改user-service中的/user/{id}这个接口的业务。通过休眠模拟一个延迟时间：\n此时，orderId=101的订单，关联的是id为1的用户，调用时长为60ms：\norderId=102的订单，关联的是id为2的用户，调用时长为非常短；\n2）设置熔断规则 下面，给feign接口设置降级规则：\n规则：\n超过50ms的请求都会被认为是慢请求\n3）测试 在浏览器访问：http://localhost:8088/order/101，快速刷新5次，可以发现：\n触发了熔断，请求时长缩短至5ms，快速失败了，并且走降级逻辑，返回的null\n在浏览器访问：http://localhost:8088/order/102，竟然也被熔断了：\n3.3.2.异常比例、异常数 异常比例或异常数：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常的比例达到设定的比例阈值（或超过指定异常数），则触发熔断。\n例如，一个异常比例设置：\n解读：统计最近1000ms内的请求，如果请求量超过10次，并且异常比例不低于0.4，则触发熔断。\n一个异常数设置：\n解读：统计最近1000ms内的请求，如果请求量超过10次，并且异常比例不低于2次，则触发熔断。\n案例\n需求：给 UserClient的查询用户接口设置降级规则，统计时间为1秒，最小请求数量为5，失败阈值比例为0.4，熔断时长为5s\n1）设置异常请求 首先，修改user-service中的/user/{id}这个接口的业务。手动抛出异常，以触发异常比例的熔断：\n也就是说，id 为 2时，就会触发异常\n2）设置熔断规则 下面，给feign接口设置降级规则：\n规则：\n在5次请求中，只要异常比例超过0.4，也就是有2次以上的异常，就会触发熔断。\n3）测试 在浏览器快速访问：http://localhost:8088/order/102，快速刷新5次，触发熔断：\n此时，我们去访问本来应该正常的103：\n4.授权规则 授权规则可以对请求方来源做判断和控制。\n4.1.授权规则 4.1.1.基本规则 授权规则可以对调用方的来源做控制，有白名单和黑名单两种方式。\n白名单：来源（origin）在白名单内的调用者允许访问\n黑名单：来源（origin）在黑名单内的调用者不允许访问\n点击左侧菜单的授权，可以看到授权规则：\n资源名：就是受保护的资源，例如/order/{orderId}\n流控应用：是来源者的名单，\n如果是勾选白名单，则名单中的来源被许可访问。 如果是勾选黑名单，则名单中的来源被禁止访问。 比如：\n我们允许请求从gateway到order-service，不允许浏览器访问order-service，那么白名单中就要填写网关的来源名称（origin）。\n4.1.2.如何获取origin Sentinel是通过RequestOriginParser这个接口的parseOrigin来获取请求的来源的。\npublic interface RequestOriginParser { /** * 从请求request对象中获取origin，获取方式自定义 */ String parseOrigin(HttpServletRequest request); } 这个方法的作用就是从request对象中，获取请求者的origin值并返回。\n默认情况下，sentinel不管请求者从哪里来，返回值永远是default，也就是说一切请求的来源都被认为是一样的值default。\n因此，我们需要自定义这个接口的实现，让不同的请求，返回不同的origin。\n例如order-service服务中，我们定义一个RequestOriginParser的实现类：\npackage cn.itcast.order.sentinel; import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.RequestOriginParser; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; import javax.servlet.http.HttpServletRequest; @Component public class HeaderOriginParser implements RequestOriginParser { @Override public String parseOrigin(HttpServletRequest request) { // 1.获取请求头 String origin = request.getHeader(\u0026#34;origin\u0026#34;); // 2.非空判断 if (StringUtils.isEmpty(origin)) { origin = \u0026#34;blank\u0026#34;; } return origin; } } 我们会尝试从request-header中获取origin值。\n4.1.3.给网关添加请求头 既然获取请求origin的方式是从reques-header中获取origin值，我们必须让所有从gateway路由到微服务的请求都带上origin头。\n这个需要利用之前学习的一个GatewayFilter来实现，AddRequestHeaderGatewayFilter。\n修改gateway服务中的application.yml，添加一个defaultFilter：\nspring: cloud: gateway: default-filters: - AddRequestHeader=origin,gateway routes: # ...略 这样，从gateway路由的所有请求都会带上origin头，值为gateway。而从其它地方到达微服务的请求则没有这个头。\n4.1.4.配置授权规则 接下来，我们添加一个授权规则，放行origin值为gateway的请求。\n配置如下：\n现在，我们直接跳过网关，访问order-service服务：\n通过网关访问：\n4.2.自定义异常结果 默认情况下，发生限流、降级、授权拦截时，都会抛出异常到调用方。异常结果都是flow limmiting（限流）。这样不够友好，无法得知是限流还是降级还是授权拦截。\n4.2.1.异常类型 而如果要自定义异常时的返回结果，需要实现BlockExceptionHandler接口：\npublic interface BlockExceptionHandler { /** * 处理请求被限流、降级、授权拦截时抛出的异常：BlockException */ void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception; } 这个方法有三个参数：\nHttpServletRequest request：request对象 HttpServletResponse response：response对象 BlockException e：被sentinel拦截时抛出的异常 这里的BlockException包含多个不同的子类：\n异常 说明 FlowException 限流异常 ParamFlowException 热点参数限流的异常 DegradeException 降级异常 AuthorityException 授权规则异常 SystemBlockException 系统规则异常 4.2.2.自定义异常处理 下面，我们就在order-service定义一个自定义异常处理类：\npackage cn.itcast.order.sentinel; import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.BlockExceptionHandler; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.alibaba.csp.sentinel.slots.block.authority.AuthorityException; import com.alibaba.csp.sentinel.slots.block.degrade.DegradeException; import com.alibaba.csp.sentinel.slots.block.flow.FlowException; import com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowException; import org.springframework.stereotype.Component; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; @Component public class SentinelExceptionHandler implements BlockExceptionHandler { @Override public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception { String msg = \u0026#34;未知异常\u0026#34;; int status = 429; if (e instanceof FlowException) { msg = \u0026#34;请求被限流了\u0026#34;; } else if (e instanceof ParamFlowException) { msg = \u0026#34;请求被热点参数限流\u0026#34;; } else if (e instanceof DegradeException) { msg = \u0026#34;请求被降级了\u0026#34;; } else if (e instanceof AuthorityException) { msg = \u0026#34;没有权限访问\u0026#34;; status = 401; } response.setContentType(\u0026#34;application/json;charset=utf-8\u0026#34;); response.setStatus(status); response.getWriter().println(\u0026#34;{\\\u0026#34;msg\\\u0026#34;: \u0026#34; + msg + \u0026#34;, \\\u0026#34;status\\\u0026#34;: \u0026#34; + status + \u0026#34;}\u0026#34;); } } 重启测试，在不同场景下，会返回不同的异常消息.\n限流：\n授权拦截时：\n5.规则持久化 现在，sentinel的所有规则都是内存存储，重启后所有规则都会丢失。在生产环境下，我们必须确保这些规则的持久化，避免丢失。\n5.1.规则管理模式 规则是否能持久化，取决于规则管理模式，sentinel支持三种规则管理模式：\n原始模式：Sentinel的默认模式，将规则保存在内存，重启服务会丢失。 pull模式 push模式 5.1.1.pull模式 pull模式：控制台将配置的规则推送到Sentinel客户端，而客户端会将配置规则保存在本地文件或数据库中。以后会定时去本地文件或数据库中查询，更新本地规则。\n5.1.2.push模式 push模式：控制台将配置规则推送到远程配置中心，例如Nacos。Sentinel客户端监听Nacos，获取配置变更的推送消息，完成本地配置更新。\n5.2.实现push模式 详细步骤可以参考课前资料的《sentinel规则持久化》：\n","permalink":"https://XianCH.github.io/posts/tech/distributed/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BF%9D%E6%8A%A4/","summary":"微服务保护 1.初识Sentinel 1.1.雪崩问题及解决方案 1.1.1.雪崩问题 微服务中，服务间调用关系错综复杂，一个微服务往往依赖于多个其它微服务。 如图，如果服务提供者I发生了故障，当前的应用的部分业务因为依赖于服务I，因此也会被阻塞。此时，其它不依赖于服务I的业务似乎不受影响","title":"微服务保护"},{"content":"1.什么是多级缓存 传统的缓存策略一般是请求到达Tomcat后，先查询Redis，如果未命中则查询数据库，如图：\n存在下面的问题：\n•请求要经过Tomcat处理，Tomcat的性能成为整个系统的瓶颈\n•Redis缓存失效时，会对数据库产生冲击\n多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务性能：\n浏览器访问静态资源时，优先读取浏览器本地缓存 访问非静态资源（ajax查询数据）时，访问服务端 请求到达Nginx后，优先读取Nginx本地缓存 如果Nginx本地缓存未命中，则去直接查询Redis（不经过Tomcat） 如果Redis查询未命中，则查询Tomcat 请求进入Tomcat后，优先查询JVM进程缓存 如果JVM进程缓存未命中，则查询数据库 在多级缓存架构中，Nginx内部需要编写本地缓存查询、Redis查询、Tomcat查询的业务逻辑，因此这样的nginx服务不再是一个反向代理服务器，而是一个编写业务的Web服务器了。\n因此这样的业务Nginx服务也需要搭建集群来提高并发，再有专门的nginx服务来做反向代理，如图：\n另外，我们的Tomcat服务将来也会部署为集群模式：\n可见，多级缓存的关键有两个：\n一个是在nginx中编写业务，实现nginx本地缓存、Redis、Tomcat的查询\n另一个就是在Tomcat中实现JVM进程缓存\n其中Nginx编程则会用到OpenResty框架结合Lua这样的语言。\n这也是今天课程的难点和重点。\n2.JVM进程缓存 为了演示多级缓存的案例，我们先准备一个商品查询的业务。\n2.1.导入案例 参考课前资料的：《案例导入说明.md》\n2.2.初识Caffeine 缓存在日常开发中启动至关重要的作用，由于是存储在内存中，数据的读取速度是非常快的，能大量减少对数据库的访问，减少数据库的压力。我们把缓存分为两类：\n分布式缓存，例如Redis： 优点：存储容量更大、可靠性更好、可以在集群间共享 缺点：访问缓存有网络开销 场景：缓存数据量较大、可靠性要求较高、需要在集群间共享 进程本地缓存，例如HashMap、GuavaCache： 优点：读取本地内存，没有网络开销，速度更快 缺点：存储容量有限、可靠性较低、无法共享 场景：性能要求较高，缓存数据量较小 我们今天会利用Caffeine框架来实现JVM进程缓存。\nCaffeine是一个基于Java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。GitHub地址：https://github.com/ben-manes/caffeine\nCaffeine的性能非常好，下图是官方给出的性能对比：\n可以看到Caffeine的性能遥遥领先！\n缓存使用的基本API：\n@Test void testBasicOps() { // 构建cache对象 Cache\u0026lt;String, String\u0026gt; cache = Caffeine.newBuilder().build(); // 存数据 cache.put(\u0026#34;gf\u0026#34;, \u0026#34;迪丽热巴\u0026#34;); // 取数据 String gf = cache.getIfPresent(\u0026#34;gf\u0026#34;); System.out.println(\u0026#34;gf = \u0026#34; + gf); // 取数据，包含两个参数： // 参数一：缓存的key // 参数二：Lambda表达式，表达式参数就是缓存的key，方法体是查询数据库的逻辑 // 优先根据key查询JVM缓存，如果未命中，则执行参数二的Lambda表达式 String defaultGF = cache.get(\u0026#34;defaultGF\u0026#34;, key -\u0026gt; { // 根据key去数据库查询数据 return \u0026#34;柳岩\u0026#34;; }); System.out.println(\u0026#34;defaultGF = \u0026#34; + defaultGF); } Caffeine既然是缓存的一种，肯定需要有缓存的清除策略，不然的话内存总会有耗尽的时候。\nCaffeine提供了三种缓存驱逐策略：\n基于容量：设置缓存的数量上限\n// 创建缓存对象 Cache\u0026lt;String, String\u0026gt; cache = Caffeine.newBuilder() .maximumSize(1) // 设置缓存大小上限为 1 .build(); 基于时间：设置缓存的有效时间\n// 创建缓存对象 Cache\u0026lt;String, String\u0026gt; cache = Caffeine.newBuilder() // 设置缓存有效期为 10 秒，从最后一次写入开始计时 .expireAfterWrite(Duration.ofSeconds(10)) .build(); 基于引用：设置缓存为软引用或弱引用，利用GC来回收缓存数据。性能较差，不建议使用。\n注意：在默认情况下，当一个缓存元素过期的时候，Caffeine不会自动立即将其清理和驱逐。而是在一次读或写操作后，或者在空闲时间完成对失效数据的驱逐。\n2.3.实现JVM进程缓存 2.3.1.需求 利用Caffeine实现下列需求：\n给根据id查询商品的业务添加缓存，缓存未命中时查询数据库 给根据id查询商品库存的业务添加缓存，缓存未命中时查询数据库 缓存初始大小为100 缓存上限为10000 2.3.2.实现 首先，我们需要定义两个Caffeine的缓存对象，分别保存商品、库存的缓存数据。\n在item-service的com.heima.item.config包下定义CaffeineConfig类：\npackage com.heima.item.config; import com.github.benmanes.caffeine.cache.Cache; import com.github.benmanes.caffeine.cache.Caffeine; import com.heima.item.pojo.Item; import com.heima.item.pojo.ItemStock; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class CaffeineConfig { @Bean public Cache\u0026lt;Long, Item\u0026gt; itemCache(){ return Caffeine.newBuilder() .initialCapacity(100) .maximumSize(10_000) .build(); } @Bean public Cache\u0026lt;Long, ItemStock\u0026gt; stockCache(){ return Caffeine.newBuilder() .initialCapacity(100) .maximumSize(10_000) .build(); } } 然后，修改item-service中的com.heima.item.web包下的ItemController类，添加缓存逻辑：\n@RestController @RequestMapping(\u0026#34;item\u0026#34;) public class ItemController { @Autowired private IItemService itemService; @Autowired private IItemStockService stockService; @Autowired private Cache\u0026lt;Long, Item\u0026gt; itemCache; @Autowired private Cache\u0026lt;Long, ItemStock\u0026gt; stockCache; // ...其它略 @GetMapping(\u0026#34;/{id}\u0026#34;) public Item findById(@PathVariable(\u0026#34;id\u0026#34;) Long id) { return itemCache.get(id, key -\u0026gt; itemService.query() .ne(\u0026#34;status\u0026#34;, 3).eq(\u0026#34;id\u0026#34;, key) .one() ); } @GetMapping(\u0026#34;/stock/{id}\u0026#34;) public ItemStock findStockById(@PathVariable(\u0026#34;id\u0026#34;) Long id) { return stockCache.get(id, key -\u0026gt; stockService.getById(key)); } } 3.Lua语法入门 Nginx编程需要用到Lua语言，因此我们必须先入门Lua的基本语法。\n3.1.初识Lua Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。官网：https://www.lua.org/\nLua经常嵌入到C语言开发的程序中，例如游戏开发、游戏插件等。\nNginx本身也是C语言开发，因此也允许基于Lua做拓展。\n3.1.HelloWorld CentOS7默认已经安装了Lua语言环境，所以可以直接运行Lua代码。\n1）在Linux虚拟机的任意目录下，新建一个hello.lua文件\n2）添加下面的内容\nprint(\u0026#34;Hello World!\u0026#34;) 3）运行\n3.2.变量和循环 学习任何语言必然离不开变量，而变量的声明必须先知道数据的类型。\n3.2.1.Lua的数据类型 Lua中支持的常见数据类型包括：\n另外，Lua提供了type()函数来判断一个变量的数据类型：\n3.2.2.声明变量 Lua声明变量的时候无需指定数据类型，而是用local来声明变量为局部变量：\n-- 声明字符串，可以用单引号或双引号， local str = \u0026#39;hello\u0026#39; -- 字符串拼接可以使用 .. local str2 = \u0026#39;hello\u0026#39; .. \u0026#39;world\u0026#39; -- 声明数字 local num = 21 -- 声明布尔类型 local flag = true Lua中的table类型既可以作为数组，又可以作为Java中的map来使用。数组就是特殊的table，key是数组角标而已：\n-- 声明数组 ，key为角标的 table local arr = {\u0026#39;java\u0026#39;, \u0026#39;python\u0026#39;, \u0026#39;lua\u0026#39;} -- 声明table，类似java的map local map = {name=\u0026#39;Jack\u0026#39;, age=21} Lua中的数组角标是从1开始，访问的时候与Java中类似：\n-- 访问数组，lua数组的角标从1开始 print(arr[1]) Lua中的table可以用key来访问：\n-- 访问table print(map[\u0026#39;name\u0026#39;]) print(map.name) 3.2.3.循环 对于table，我们可以利用for循环来遍历。不过数组和普通table遍历略有差异。\n遍历数组：\n-- 声明数组 key为索引的 table local arr = {\u0026#39;java\u0026#39;, \u0026#39;python\u0026#39;, \u0026#39;lua\u0026#39;} -- 遍历数组 for index,value in ipairs(arr) do print(index, value) end 遍历普通table\n-- 声明map，也就是table local map = {name=\u0026#39;Jack\u0026#39;, age=21} -- 遍历table for key,value in pairs(map) do print(key, value) end 3.3.条件控制、函数 Lua中的条件控制和函数声明与Java类似。\n3.3.1.函数 定义函数的语法：\nfunction 函数名( argument1, argument2..., argumentn) -- 函数体 return 返回值 end 例如，定义一个函数，用来打印数组：\nfunction printArr(arr) for index, value in ipairs(arr) do print(value) end end 3.3.2.条件控制 类似Java的条件控制，例如if、else语法：\nif(布尔表达式) then --[ 布尔表达式为 true 时执行该语句块 --] else --[ 布尔表达式为 false 时执行该语句块 --] end 与java不同，布尔表达式中的逻辑运算是基于英文单词：\n3.3.3.案例 需求：自定义一个函数，可以打印table，当参数为nil时，打印错误信息\nfunction printArr(arr) if not arr then print(\u0026#39;数组不能为空！\u0026#39;) end for index, value in ipairs(arr) do print(value) end end 4.实现多级缓存 多级缓存的实现离不开Nginx编程，而Nginx编程又离不开OpenResty。\n4.1.安装OpenResty OpenResty® 是一个基于 Nginx的高性能 Web 平台，用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。具备下列特点：\n具备Nginx的完整功能 基于Lua语言进行扩展，集成了大量精良的 Lua 库、第三方模块 允许使用Lua自定义业务逻辑、自定义库 官方网站： https://openresty.org/cn/\n安装Lua可以参考课前资料提供的《安装OpenResty.md》：\n4.2.OpenResty快速入门 我们希望达到的多级缓存架构如图：\n其中：\nwindows上的nginx用来做反向代理服务，将前端的查询商品的ajax请求代理到OpenResty集群\nOpenResty集群用来编写多级缓存业务\n4.2.1.反向代理流程 现在，商品详情页使用的是假的商品数据。不过在浏览器中，可以看到页面有发起ajax请求查询真实商品数据。\n这个请求如下：\n请求地址是localhost，端口是80，就被windows上安装的Nginx服务给接收到了。然后代理给了OpenResty集群：\n我们需要在OpenResty中编写业务，查询商品数据并返回到浏览器。\n但是这次，我们先在OpenResty接收请求，返回假的商品数据。\n4.2.2.OpenResty监听请求 OpenResty的很多功能都依赖于其目录下的Lua库，需要在nginx.conf中指定依赖库的目录，并导入依赖：\n1）添加对OpenResty的Lua模块的加载\n修改/usr/local/openresty/nginx/conf/nginx.conf文件，在其中的http下面，添加下面代码：\n#lua 模块 lua_package_path \u0026#34;/usr/local/openresty/lualib/?.lua;;\u0026#34;; #c模块 lua_package_cpath \u0026#34;/usr/local/openresty/lualib/?.so;;\u0026#34;; 2）监听/api/item路径\n修改/usr/local/openresty/nginx/conf/nginx.conf文件，在nginx.conf的server下面，添加对/api/item这个路径的监听：\nlocation /api/item { # 默认的响应类型 default_type application/json; # 响应结果由lua/item.lua文件来决定 content_by_lua_file lua/item.lua; } 这个监听，就类似于SpringMVC中的@GetMapping(\u0026quot;/api/item\u0026quot;)做路径映射。\n而content_by_lua_file lua/item.lua则相当于调用item.lua这个文件，执行其中的业务，把结果返回给用户。相当于java中调用service。\n4.2.3.编写item.lua 1）在/usr/loca/openresty/nginx目录创建文件夹：lua\n2）在/usr/loca/openresty/nginx/lua文件夹下，新建文件：item.lua\n3）编写item.lua，返回假数据\nitem.lua中，利用ngx.say()函数返回数据到Response中\nngx.say(\u0026#39;{\u0026#34;id\u0026#34;:10001,\u0026#34;name\u0026#34;:\u0026#34;SALSA AIR\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4\u0026#34;,\u0026#34;price\u0026#34;:17900,\u0026#34;image\u0026#34;:\u0026#34;https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp\u0026#34;,\u0026#34;category\u0026#34;:\u0026#34;拉杆箱\u0026#34;,\u0026#34;brand\u0026#34;:\u0026#34;RIMOWA\u0026#34;,\u0026#34;spec\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;status\u0026#34;:1,\u0026#34;createTime\u0026#34;:\u0026#34;2019-04-30T16:00:00.000+00:00\u0026#34;,\u0026#34;updateTime\u0026#34;:\u0026#34;2019-04-30T16:00:00.000+00:00\u0026#34;,\u0026#34;stock\u0026#34;:2999,\u0026#34;sold\u0026#34;:31290}\u0026#39;) 4）重新加载配置\nnginx -s reload 刷新商品页面：http://localhost/item.html?id=1001，即可看到效果：\n4.3.请求参数处理 上一节中，我们在OpenResty接收前端请求，但是返回的是假数据。\n要返回真实数据，必须根据前端传递来的商品id，查询商品信息才可以。\n那么如何获取前端传递的商品参数呢？\n4.3.1.获取参数的API OpenResty中提供了一些API用来获取不同类型的前端请求参数：\n4.3.2.获取参数并返回 在前端发起的ajax请求如图：\n可以看到商品id是以路径占位符方式传递的，因此可以利用正则表达式匹配的方式来获取ID\n1）获取商品id\n修改/usr/loca/openresty/nginx/nginx.conf文件中监听/api/item的代码，利用正则表达式获取ID：\nlocation ~ /api/item/(\\d+) { # 默认的响应类型 default_type application/json; # 响应结果由lua/item.lua文件来决定 content_by_lua_file lua/item.lua; } 2）拼接ID并返回\n修改/usr/loca/openresty/nginx/lua/item.lua文件，获取id并拼接到结果中返回：\n-- 获取商品id local id = ngx.var[1] -- 拼接并返回 ngx.say(\u0026#39;{\u0026#34;id\u0026#34;:\u0026#39; .. id .. \u0026#39;,\u0026#34;name\u0026#34;:\u0026#34;SALSA AIR\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4\u0026#34;,\u0026#34;price\u0026#34;:17900,\u0026#34;image\u0026#34;:\u0026#34;https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp\u0026#34;,\u0026#34;category\u0026#34;:\u0026#34;拉杆箱\u0026#34;,\u0026#34;brand\u0026#34;:\u0026#34;RIMOWA\u0026#34;,\u0026#34;spec\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;status\u0026#34;:1,\u0026#34;createTime\u0026#34;:\u0026#34;2019-04-30T16:00:00.000+00:00\u0026#34;,\u0026#34;updateTime\u0026#34;:\u0026#34;2019-04-30T16:00:00.000+00:00\u0026#34;,\u0026#34;stock\u0026#34;:2999,\u0026#34;sold\u0026#34;:31290}\u0026#39;) 3）重新加载并测试\n运行命令以重新加载OpenResty配置：\nnginx -s reload 刷新页面可以看到结果中已经带上了ID：\n4.4.查询Tomcat 拿到商品ID后，本应去缓存中查询商品信息，不过目前我们还未建立nginx、redis缓存。因此，这里我们先根据商品id去tomcat查询商品信息。我们实现如图部分：\n需要注意的是，我们的OpenResty是在虚拟机，Tomcat是在Windows电脑上。两者IP一定不要搞错了。\n4.4.1.发送http请求的API nginx提供了内部API用以发送http请求：\nlocal resp = ngx.location.capture(\u0026#34;/path\u0026#34;,{ method = ngx.HTTP_GET, -- 请求方式 args = {a=1,b=2}, -- get方式传参数 }) 返回的响应内容包括：\nresp.status：响应状态码 resp.header：响应头，是一个table resp.body：响应体，就是响应数据 注意：这里的path是路径，并不包含IP和端口。这个请求会被nginx内部的server监听并处理。\n但是我们希望这个请求发送到Tomcat服务器，所以还需要编写一个server来对这个路径做反向代理：\nlocation /path { # 这里是windows电脑的ip和Java服务端口，需要确保windows防火墙处于关闭状态 proxy_pass http://192.168.150.1:8081; } 原理如图：\n4.4.2.封装http工具 下面，我们封装一个发送Http请求的工具，基于ngx.location.capture来实现查询tomcat。\n1）添加反向代理，到windows的Java服务\n因为item-service中的接口都是/item开头，所以我们监听/item路径，代理到windows上的tomcat服务。\n修改 /usr/local/openresty/nginx/conf/nginx.conf文件，添加一个location：\nlocation /item { proxy_pass http://192.168.150.1:8081; } 以后，只要我们调用ngx.location.capture(\u0026quot;/item\u0026quot;)，就一定能发送请求到windows的tomcat服务。\n2）封装工具类\n之前我们说过，OpenResty启动时会加载以下两个目录中的工具文件：\n所以，自定义的http工具也需要放到这个目录下。\n在/usr/local/openresty/lualib目录下，新建一个common.lua文件：\nvi /usr/local/openresty/lualib/common.lua 内容如下:\n-- 封装函数，发送http请求，并解析响应 local function read_http(path, params) local resp = ngx.location.capture(path,{ method = ngx.HTTP_GET, args = params, }) if not resp then -- 记录错误信息，返回404 ngx.log(ngx.ERR, \u0026#34;http请求查询失败, path: \u0026#34;, path , \u0026#34;, args: \u0026#34;, args) ngx.exit(404) end return resp.body end -- 将方法导出 local _M = { read_http = read_http } return _M 这个工具将read_http函数封装到_M这个table类型的变量中，并且返回，这类似于导出。\n使用的时候，可以利用require('common')来导入该函数库，这里的common是函数库的文件名。\n3）实现商品查询\n最后，我们修改/usr/local/openresty/lua/item.lua文件，利用刚刚封装的函数库实现对tomcat的查询：\n-- 引入自定义common工具模块，返回值是common中返回的 _M local common = require(\u0026#34;common\u0026#34;) -- 从 common中获取read_http这个函数 local read_http = common.read_http -- 获取路径参数 local id = ngx.var[1] -- 根据id查询商品 local itemJSON = read_http(\u0026#34;/item/\u0026#34;.. id, nil) -- 根据id查询商品库存 local itemStockJSON = read_http(\u0026#34;/item/stock/\u0026#34;.. id, nil) 这里查询到的结果是json字符串，并且包含商品、库存两个json字符串，页面最终需要的是把两个json拼接为一个json：\n这就需要我们先把JSON变为lua的table，完成数据整合后，再转为JSON。\n4.4.3.CJSON工具类 OpenResty提供了一个cjson的模块用来处理JSON的序列化和反序列化。\n官方地址： https://github.com/openresty/lua-cjson/\n1）引入cjson模块：\nlocal cjson = require \u0026#34;cjson\u0026#34; 2）序列化：\nlocal obj = { name = \u0026#39;jack\u0026#39;, age = 21 } -- 把 table 序列化为 json local json = cjson.encode(obj) 3）反序列化：\nlocal json = \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;jack\u0026#34;, \u0026#34;age\u0026#34;: 21}\u0026#39; -- 反序列化 json为 table local obj = cjson.decode(json); print(obj.name) 4.4.4.实现Tomcat查询 下面，我们修改之前的item.lua中的业务，添加json处理功能：\n-- 导入common函数库 local common = require(\u0026#39;common\u0026#39;) local read_http = common.read_http -- 导入cjson库 local cjson = require(\u0026#39;cjson\u0026#39;) -- 获取路径参数 local id = ngx.var[1] -- 根据id查询商品 local itemJSON = read_http(\u0026#34;/item/\u0026#34;.. id, nil) -- 根据id查询商品库存 local itemStockJSON = read_http(\u0026#34;/item/stock/\u0026#34;.. id, nil) -- JSON转化为lua的table local item = cjson.decode(itemJSON) local stock = cjson.decode(stockJSON) -- 组合数据 item.stock = stock.stock item.sold = stock.sold -- 把item序列化为json 返回结果 ngx.say(cjson.encode(item)) 4.4.5.基于ID负载均衡 刚才的代码中，我们的tomcat是单机部署。而实际开发中，tomcat一定是集群模式：\n因此，OpenResty需要对tomcat集群做负载均衡。\n而默认的负载均衡规则是轮询模式，当我们查询/item/10001时：\n第一次会访问8081端口的tomcat服务，在该服务内部就形成了JVM进程缓存 第二次会访问8082端口的tomcat服务，该服务内部没有JVM缓存（因为JVM缓存无法共享），会查询数据库 \u0026hellip; 你看，因为轮询的原因，第一次查询8081形成的JVM缓存并未生效，直到下一次再次访问到8081时才可以生效，缓存命中率太低了。\n怎么办？\n如果能让同一个商品，每次查询时都访问同一个tomcat服务，那么JVM缓存就一定能生效了。\n也就是说，我们需要根据商品id做负载均衡，而不是轮询。\n1）原理 nginx提供了基于请求路径做负载均衡的算法：\nnginx根据请求路径做hash运算，把得到的数值对tomcat服务的数量取余，余数是几，就访问第几个服务，实现负载均衡。\n例如：\n我们的请求路径是 /item/10001 tomcat总数为2台（8081、8082） 对请求路径/item/1001做hash运算求余的结果为1 则访问第一个tomcat服务，也就是8081 只要id不变，每次hash运算结果也不会变，那就可以保证同一个商品，一直访问同一个tomcat服务，确保JVM缓存生效。\n2）实现 修改/usr/local/openresty/nginx/conf/nginx.conf文件，实现基于ID做负载均衡。\n首先，定义tomcat集群，并设置基于路径做负载均衡：\nupstream tomcat-cluster { hash $request_uri; server 192.168.150.1:8081; server 192.168.150.1:8082; } 然后，修改对tomcat服务的反向代理，目标指向tomcat集群：\nlocation /item { proxy_pass http://tomcat-cluster; } 重新加载OpenResty\nnginx -s reload 3）测试 启动两台tomcat服务：\n同时启动：\n清空日志后，再次访问页面，可以看到不同id的商品，访问到了不同的tomcat服务：\n4.5.Redis缓存预热 Redis缓存会面临冷启动问题：\n冷启动：服务刚刚启动时，Redis中并没有缓存，如果所有商品数据都在第一次查询时添加缓存，可能会给数据库带来较大压力。\n缓存预热：在实际开发中，我们可以利用大数据统计用户访问的热点数据，在项目启动时将这些热点数据提前查询并保存到Redis中。\n我们数据量较少，并且没有数据统计相关功能，目前可以在启动时将所有数据都放入缓存中。\n1）利用Docker安装Redis\ndocker run --name redis -p 6379:6379 -d redis redis-server --appendonly yes 2）在item-service服务中引入Redis依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 3）配置Redis地址\nspring: redis: host: 192.168.150.101 4）编写初始化类\n缓存预热需要在项目启动时完成，并且必须是拿到RedisTemplate之后。\n这里我们利用InitializingBean接口来实现，因为InitializingBean可以在对象被Spring创建并且成员变量全部注入后执行。\npackage com.heima.item.config; import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.ObjectMapper; import com.heima.item.pojo.Item; import com.heima.item.pojo.ItemStock; import com.heima.item.service.IItemService; import com.heima.item.service.IItemStockService; import org.springframework.beans.factory.InitializingBean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.StringRedisTemplate; import org.springframework.stereotype.Component; import java.util.List; @Component public class RedisHandler implements InitializingBean { @Autowired private StringRedisTemplate redisTemplate; @Autowired private IItemService itemService; @Autowired private IItemStockService stockService; private static final ObjectMapper MAPPER = new ObjectMapper(); @Override public void afterPropertiesSet() throws Exception { // 初始化缓存 // 1.查询商品信息 List\u0026lt;Item\u0026gt; itemList = itemService.list(); // 2.放入缓存 for (Item item : itemList) { // 2.1.item序列化为JSON String json = MAPPER.writeValueAsString(item); // 2.2.存入redis redisTemplate.opsForValue().set(\u0026#34;item🆔\u0026#34; + item.getId(), json); } // 3.查询商品库存信息 List\u0026lt;ItemStock\u0026gt; stockList = stockService.list(); // 4.放入缓存 for (ItemStock stock : stockList) { // 2.1.item序列化为JSON String json = MAPPER.writeValueAsString(stock); // 2.2.存入redis redisTemplate.opsForValue().set(\u0026#34;item:stock:id:\u0026#34; + stock.getId(), json); } } } 4.6.查询Redis缓存 现在，Redis缓存已经准备就绪，我们可以再OpenResty中实现查询Redis的逻辑了。如下图红框所示：\n当请求进入OpenResty之后：\n优先查询Redis缓存 如果Redis缓存未命中，再查询Tomcat 4.6.1.封装Redis工具 OpenResty提供了操作Redis的模块，我们只要引入该模块就能直接使用。但是为了方便，我们将Redis操作封装到之前的common.lua工具库中。\n修改/usr/local/openresty/lualib/common.lua文件：\n1）引入Redis模块，并初始化Redis对象\n-- 导入redis local redis = require(\u0026#39;resty.redis\u0026#39;) -- 初始化redis local red = redis:new() red:set_timeouts(1000, 1000, 1000) 2）封装函数，用来释放Redis连接，其实是放入连接池\nlocal function close_redis(red) local pool_max_idle_time = 10000 local pool_size = 100 local ok, err = red:set_keepalive(pool_max_idle_time, pool_size) if not ok then ngx.log(ngx.ERR, \u0026#34;放入redis连接池失败: \u0026#34;, err) end end 3）封装函数，根据key查询Redis数据\nlocal function read_redis(ip, port, key) local ok, err = red:connect(ip, port) if not ok then ngx.log(ngx.ERR, \u0026#34;连接redis失败 : \u0026#34;, err) return nil end local resp, err = red:get(key) if not resp then ngx.log(ngx.ERR, \u0026#34;查询Redis失败: \u0026#34;, err, \u0026#34;, key = \u0026#34; , key) end if resp == ngx.null then resp = nil ngx.log(ngx.ERR, \u0026#34;查询Redis数据为空, key = \u0026#34;, key) end close_redis(red) return resp end 4）导出\n-- 将方法导出 local _M = { read_http = read_http, read_redis = read_redis } return _M 完整的common.lua：\n-- 导入redis local redis = require(\u0026#39;resty.redis\u0026#39;) -- 初始化redis local red = redis:new() red:set_timeouts(1000, 1000, 1000) -- 关闭redis连接的工具方法，其实是放入连接池 local function close_redis(red) local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒 local pool_size = 100 --连接池大小 local ok, err = red:set_keepalive(pool_max_idle_time, pool_size) if not ok then ngx.log(ngx.ERR, \u0026#34;放入redis连接池失败: \u0026#34;, err) end end -- 查询redis的方法 ip和port是redis地址，key是查询的key local function read_redis(ip, port, key) -- 获取一个连接 local ok, err = red:connect(ip, port) if not ok then ngx.log(ngx.ERR, \u0026#34;连接redis失败 : \u0026#34;, err) return nil end -- 查询redis local resp, err = red:get(key) -- 查询失败处理 if not resp then ngx.log(ngx.ERR, \u0026#34;查询Redis失败: \u0026#34;, err, \u0026#34;, key = \u0026#34; , key) end --得到的数据为空处理 if resp == ngx.null then resp = nil ngx.log(ngx.ERR, \u0026#34;查询Redis数据为空, key = \u0026#34;, key) end close_redis(red) return resp end -- 封装函数，发送http请求，并解析响应 local function read_http(path, params) local resp = ngx.location.capture(path,{ method = ngx.HTTP_GET, args = params, }) if not resp then -- 记录错误信息，返回404 ngx.log(ngx.ERR, \u0026#34;http查询失败, path: \u0026#34;, path , \u0026#34;, args: \u0026#34;, args) ngx.exit(404) end return resp.body end -- 将方法导出 local _M = { read_http = read_http, read_redis = read_redis } return _M 4.6.2.实现Redis查询 接下来，我们就可以去修改item.lua文件，实现对Redis的查询了。\n查询逻辑是：\n根据id查询Redis 如果查询失败则继续查询Tomcat 将查询结果返回 1）修改/usr/local/openresty/lua/item.lua文件，添加一个查询函数：\n-- 导入common函数库 local common = require(\u0026#39;common\u0026#39;) local read_http = common.read_http local read_redis = common.read_redis -- 封装查询函数 function read_data(key, path, params) local val = read_redis(\u0026#34;127.0.0.1\u0026#34;, 6379, key) if not val then ngx.log(ngx.ERR, \u0026#34;redis查询失败，尝试查询http， key: \u0026#34;, key) val = read_http(path, params) end return val end 2）而后修改商品查询、库存查询的业务：\n3）完整的item.lua代码：\n-- 导入common函数库 local common = require(\u0026#39;common\u0026#39;) local read_http = common.read_http local read_redis = common.read_redis -- 导入cjson库 local cjson = require(\u0026#39;cjson\u0026#39;) -- 封装查询函数 function read_data(key, path, params) -- 查询本地缓存 local val = read_redis(\u0026#34;127.0.0.1\u0026#34;, 6379, key) -- 判断查询结果 if not val then ngx.log(ngx.ERR, \u0026#34;redis查询失败，尝试查询http， key: \u0026#34;, key) -- redis查询失败，去查询http val = read_http(path, params) end -- 返回数据 return val end -- 获取路径参数 local id = ngx.var[1] local itemJSON = read_data(\u0026#34;item🆔\u0026#34; .. id, \u0026#34;/item/\u0026#34; .. id, nil) local stockJSON = read_data(\u0026#34;item:stock:id:\u0026#34; .. id, \u0026#34;/item/stock/\u0026#34; .. id, nil) -- JSON转化为lua的table local item = cjson.decode(itemJSON) local stock = cjson.decode(stockJSON) -- 组合数据 item.stock = stock.stock item.sold = stock.sold -- 把item序列化为json 返回结果 ngx.say(cjson.encode(item)) 4.7.Nginx本地缓存 现在，整个多级缓存中只差最后一环，也就是nginx的本地缓存了。如图：\n4.7.1.本地缓存API OpenResty为Nginx提供了shard dict的功能，可以在nginx的多个worker之间共享数据，实现缓存功能。\n1）开启共享字典，在nginx.conf的http下添加配置：\n# 共享字典，也就是本地缓存，名称叫做：item_cache，大小150m lua_shared_dict item_cache 150m; 2）操作共享字典：\n-- 获取本地缓存对象 local item_cache = ngx.shared.item_cache -- 存储, 指定key、value、过期时间，单位s，默认为0代表永不过期 item_cache:set(\u0026#39;key\u0026#39;, \u0026#39;value\u0026#39;, 1000) -- 读取 local val = item_cache:get(\u0026#39;key\u0026#39;) 4.7.2.实现本地缓存查询 1）修改/usr/local/openresty/lua/item.lua文件，修改read_data查询函数，添加本地缓存逻辑：\n-- 导入共享词典，本地缓存 local item_cache = ngx.shared.item_cache -- 封装查询函数 function read_data(key, expire, path, params) -- 查询本地缓存 local val = item_cache:get(key) if not val then ngx.log(ngx.ERR, \u0026#34;本地缓存查询失败，尝试查询Redis， key: \u0026#34;, key) -- 查询redis val = read_redis(\u0026#34;127.0.0.1\u0026#34;, 6379, key) -- 判断查询结果 if not val then ngx.log(ngx.ERR, \u0026#34;redis查询失败，尝试查询http， key: \u0026#34;, key) -- redis查询失败，去查询http val = read_http(path, params) end end -- 查询成功，把数据写入本地缓存 item_cache:set(key, val, expire) -- 返回数据 return val end 2）修改item.lua中查询商品和库存的业务，实现最新的read_data函数：\n其实就是多了缓存时间参数，过期后nginx缓存会自动删除，下次访问即可更新缓存。\n这里给商品基本信息设置超时时间为30分钟，库存为1分钟。\n因为库存更新频率较高，如果缓存时间过长，可能与数据库差异较大。\n3）完整的item.lua文件：\n-- 导入common函数库 local common = require(\u0026#39;common\u0026#39;) local read_http = common.read_http local read_redis = common.read_redis -- 导入cjson库 local cjson = require(\u0026#39;cjson\u0026#39;) -- 导入共享词典，本地缓存 local item_cache = ngx.shared.item_cache -- 封装查询函数 function read_data(key, expire, path, params) -- 查询本地缓存 local val = item_cache:get(key) if not val then ngx.log(ngx.ERR, \u0026#34;本地缓存查询失败，尝试查询Redis， key: \u0026#34;, key) -- 查询redis val = read_redis(\u0026#34;127.0.0.1\u0026#34;, 6379, key) -- 判断查询结果 if not val then ngx.log(ngx.ERR, \u0026#34;redis查询失败，尝试查询http， key: \u0026#34;, key) -- redis查询失败，去查询http val = read_http(path, params) end end -- 查询成功，把数据写入本地缓存 item_cache:set(key, val, expire) -- 返回数据 return val end -- 获取路径参数 local id = ngx.var[1] -- 查询商品信息 local itemJSON = read_data(\u0026#34;item🆔\u0026#34; .. id, 1800, \u0026#34;/item/\u0026#34; .. id, nil) -- 查询库存信息 local stockJSON = read_data(\u0026#34;item:stock:id:\u0026#34; .. id, 60, \u0026#34;/item/stock/\u0026#34; .. id, nil) -- JSON转化为lua的table local item = cjson.decode(itemJSON) local stock = cjson.decode(stockJSON) -- 组合数据 item.stock = stock.stock item.sold = stock.sold -- 把item序列化为json 返回结果 ngx.say(cjson.encode(item)) 5.缓存同步 大多数情况下，浏览器查询到的都是缓存数据，如果缓存数据与数据库数据存在较大差异，可能会产生比较严重的后果。\n所以我们必须保证数据库数据、缓存数据的一致性，这就是缓存与数据库的同步。\n5.1.数据同步策略 缓存数据同步的常见方式有三种：\n设置有效期：给缓存设置有效期，到期后自动删除。再次查询时更新\n优势：简单、方便 缺点：时效性差，缓存过期之前可能不一致 场景：更新频率较低，时效性要求低的业务 同步双写：在修改数据库的同时，直接修改缓存\n优势：时效性强，缓存与数据库强一致 缺点：有代码侵入，耦合度高； 场景：对一致性、时效性要求较高的缓存数据 **异步通知：**修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据\n优势：低耦合，可以同时通知多个缓存服务 缺点：时效性一般，可能存在中间不一致状态 场景：时效性要求一般，有多个服务需要同步 而异步实现又可以基于MQ或者Canal来实现：\n1）基于MQ的异步通知：\n解读：\n商品服务完成对数据的修改后，只需要发送一条消息到MQ中。 缓存服务监听MQ消息，然后完成对缓存的更新 依然有少量的代码侵入。\n2）基于Canal的通知\n解读：\n商品服务完成商品修改后，业务直接结束，没有任何代码侵入 Canal监听MySQL变化，当发现变化后，立即通知缓存服务 缓存服务接收到canal通知，更新缓存 代码零侵入\n5.2.安装Canal 5.2.1.认识Canal Canal [kə\u0026rsquo;næl]，译意为水道/管道/沟渠，canal是阿里巴巴旗下的一款开源项目，基于Java开发。基于数据库增量日志解析，提供增量数据订阅\u0026amp;消费。GitHub的地址：https://github.com/alibaba/canal\nCanal是基于mysql的主从同步来实现的，MySQL主从同步的原理如下：\n1）MySQL master 将数据变更写入二进制日志( binary log），其中记录的数据叫做binary log events 2）MySQL slave 将 master 的 binary log events拷贝到它的中继日志(relay log) 3）MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据 而Canal就是把自己伪装成MySQL的一个slave节点，从而监听master的binary log变化。再把得到的变化信息通知给Canal的客户端，进而完成对其它数据库的同步。\n5.2.2.安装Canal 安装和配置Canal参考课前资料文档：\n5.3.监听Canal Canal提供了各种语言的客户端，当Canal监听到binlog变化时，会通知Canal的客户端。\n我们可以利用Canal提供的Java客户端，监听Canal通知消息。当收到变化的消息时，完成对缓存的更新。\n不过这里我们会使用GitHub上的第三方开源的canal-starter客户端。地址：https://github.com/NormanGyllenhaal/canal-client\n与SpringBoot完美整合，自动装配，比官方客户端要简单好用很多。\n5.3.1.引入依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;top.javatool\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;canal-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.1-RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 5.3.2.编写配置： canal: destination: heima # canal的集群名字，要与安装canal时设置的名称一致 server: 192.168.150.101:11111 # canal服务地址 5.3.3.修改Item实体类 通过@Id、@Column、等注解完成Item与数据库表字段的映射：\npackage com.heima.item.pojo; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableField; import com.baomidou.mybatisplus.annotation.TableId; import com.baomidou.mybatisplus.annotation.TableName; import lombok.Data; import org.springframework.data.annotation.Id; import org.springframework.data.annotation.Transient; import javax.persistence.Column; import java.util.Date; @Data @TableName(\u0026#34;tb_item\u0026#34;) public class Item { @TableId(type = IdType.AUTO) @Id private Long id;//商品id @Column(name = \u0026#34;name\u0026#34;) private String name;//商品名称 private String title;//商品标题 private Long price;//价格（分） private String image;//商品图片 private String category;//分类名称 private String brand;//品牌名称 private String spec;//规格 private Integer status;//商品状态 1-正常，2-下架 private Date createTime;//创建时间 private Date updateTime;//更新时间 @TableField(exist = false) @Transient private Integer stock; @TableField(exist = false) @Transient private Integer sold; } 5.3.4.编写监听器 通过实现EntryHandler\u0026lt;T\u0026gt;接口编写监听器，监听Canal消息。注意两点：\n实现类通过@CanalTable(\u0026quot;tb_item\u0026quot;)指定监听的表信息 EntryHandler的泛型是与表对应的实体类 package com.heima.item.canal; import com.github.benmanes.caffeine.cache.Cache; import com.heima.item.config.RedisHandler; import com.heima.item.pojo.Item; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import top.javatool.canal.client.annotation.CanalTable; import top.javatool.canal.client.handler.EntryHandler; @CanalTable(\u0026#34;tb_item\u0026#34;) @Component public class ItemHandler implements EntryHandler\u0026lt;Item\u0026gt; { @Autowired private RedisHandler redisHandler; @Autowired private Cache\u0026lt;Long, Item\u0026gt; itemCache; @Override public void insert(Item item) { // 写数据到JVM进程缓存 itemCache.put(item.getId(), item); // 写数据到redis redisHandler.saveItem(item); } @Override public void update(Item before, Item after) { // 写数据到JVM进程缓存 itemCache.put(after.getId(), after); // 写数据到redis redisHandler.saveItem(after); } @Override public void delete(Item item) { // 删除数据到JVM进程缓存 itemCache.invalidate(item.getId()); // 删除数据到redis redisHandler.deleteItemById(item.getId()); } } 在这里对Redis的操作都封装到了RedisHandler这个对象中，是我们之前做缓存预热时编写的一个类，内容如下：\npackage com.heima.item.config; import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.ObjectMapper; import com.heima.item.pojo.Item; import com.heima.item.pojo.ItemStock; import com.heima.item.service.IItemService; import com.heima.item.service.IItemStockService; import org.springframework.beans.factory.InitializingBean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.StringRedisTemplate; import org.springframework.stereotype.Component; import java.util.List; @Component public class RedisHandler implements InitializingBean { @Autowired private StringRedisTemplate redisTemplate; @Autowired private IItemService itemService; @Autowired private IItemStockService stockService; private static final ObjectMapper MAPPER = new ObjectMapper(); @Override public void afterPropertiesSet() throws Exception { // 初始化缓存 // 1.查询商品信息 List\u0026lt;Item\u0026gt; itemList = itemService.list(); // 2.放入缓存 for (Item item : itemList) { // 2.1.item序列化为JSON String json = MAPPER.writeValueAsString(item); // 2.2.存入redis redisTemplate.opsForValue().set(\u0026#34;item🆔\u0026#34; + item.getId(), json); } // 3.查询商品库存信息 List\u0026lt;ItemStock\u0026gt; stockList = stockService.list(); // 4.放入缓存 for (ItemStock stock : stockList) { // 2.1.item序列化为JSON String json = MAPPER.writeValueAsString(stock); // 2.2.存入redis redisTemplate.opsForValue().set(\u0026#34;item:stock:id:\u0026#34; + stock.getId(), json); } } public void saveItem(Item item) { try { String json = MAPPER.writeValueAsString(item); redisTemplate.opsForValue().set(\u0026#34;item🆔\u0026#34; + item.getId(), json); } catch (JsonProcessingException e) { throw new RuntimeException(e); } } public void deleteItemById(Long id) { redisTemplate.delete(\u0026#34;item🆔\u0026#34; + id); } } ","permalink":"https://XianCH.github.io/posts/tech/distributed/%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98/","summary":"1.什么是多级缓存 传统的缓存策略一般是请求到达Tomcat后，先查询Redis，如果未命中则查询数据库，如图： 存在下面的问题： •请求要经过Tomcat处理，Tomcat的性能成为整个系统的瓶颈 •Redis缓存失效时，会对数据库产生冲击 多级缓存就是充分利用请求处理的每个环节，分别添","title":"多级缓存"},{"content":"1.Nacos配置管理 Nacos除了可以做注册中心，同样可以做配置管理来使用。\n1.1.统一配置管理 当微服务部署的实例越来越多，达到数十、数百时，逐个修改微服务配置就会让人抓狂，而且很容易出错。我们需要一种统一配置管理方案，可以集中管理所有实例的配置。\nNacos一方面可以将配置集中管理，另一方可以在配置变更时，及时通知微服务，实现配置的热更新。\n1.1.1.在nacos中添加配置文件 如何在nacos中管理配置呢？\n然后在弹出的表单中，填写配置信息：\n注意：项目的核心配置，需要热更新的配置才有放到nacos管理的必要。基本不会变更的一些配置还是保存在微服务本地比较好。\n1.1.2.从微服务拉取配置 微服务要拉取nacos中管理的配置，并且与本地的application.yml配置合并，才能完成项目启动。\n但如果尚未读取application.yml，又如何得知nacos地址呢？\n因此spring引入了一种新的配置文件：bootstrap.yaml文件，会在application.yml之前被读取，流程如下：\n1）引入nacos-config依赖\n首先，在user-service服务中，引入nacos-config的客户端依赖：\n\u0026lt;!--nacos配置管理依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2）添加bootstrap.yaml\n然后，在user-service中添加一个bootstrap.yaml文件，内容如下：\nspring: application: name: userservice # 服务名称 profiles: active: dev #开发环境，这里是dev cloud: nacos: server-addr: localhost:8848 # Nacos地址 config: file-extension: yaml # 文件后缀名 这里会根据spring.cloud.nacos.server-addr获取nacos地址，再根据\n${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}作为文件id，来读取配置。\n本例中，就是去读取userservice-dev.yaml：\n3）读取nacos配置\n在user-service中的UserController中添加业务逻辑，读取pattern.dateformat配置：\n完整代码：\npackage cn.itcast.user.web; import cn.itcast.user.pojo.User; import cn.itcast.user.service.UserService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.*; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; @Slf4j @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired private UserService userService; @Value(\u0026#34;${pattern.dateformat}\u0026#34;) private String dateformat; @GetMapping(\u0026#34;now\u0026#34;) public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat)); } // ...略 } 在页面访问，可以看到效果：\n1.2.配置热更新 我们最终的目的，是修改nacos中的配置后，微服务中无需重启即可让配置生效，也就是配置热更新。\n要实现配置热更新，可以使用两种方式：\n1.2.1.方式一 在@Value注入的变量所在类上添加注解@RefreshScope：\n1.2.2.方式二 使用@ConfigurationProperties注解代替@Value注解。\n在user-service服务中，添加一个类，读取patterrn.dateformat属性：\npackage cn.itcast.user.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; @Component @Data @ConfigurationProperties(prefix = \u0026#34;pattern\u0026#34;) public class PatternProperties { private String dateformat; } 在UserController中使用这个类代替@Value：\n完整代码：\npackage cn.itcast.user.web; import cn.itcast.user.config.PatternProperties; import cn.itcast.user.pojo.User; import cn.itcast.user.service.UserService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; @Slf4j @RestController @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired private UserService userService; @Autowired private PatternProperties patternProperties; @GetMapping(\u0026#34;now\u0026#34;) public String now(){ return LocalDateTime.now().format(DateTimeFormatter.ofPattern(patternProperties.getDateformat())); } // 略 } 1.3.配置共享 其实微服务启动时，会去nacos读取多个配置文件，例如：\n[spring.application.name]-[spring.profiles.active].yaml，例如：userservice-dev.yaml\n[spring.application.name].yaml，例如：userservice.yaml\n而[spring.application.name].yaml不包含环境，因此可以被多个环境共享。\n下面我们通过案例来测试配置共享\n1）添加一个环境共享配置 我们在nacos中添加一个userservice.yaml文件：\n2）在user-service中读取共享配置 在user-service服务中，修改PatternProperties类，读取新添加的属性：\n在user-service服务中，修改UserController，添加一个方法：\n3）运行两个UserApplication，使用不同的profile 修改UserApplication2这个启动项，改变其profile值：\n这样，UserApplication(8081)使用的profile是dev，UserApplication2(8082)使用的profile是test。\n启动UserApplication和UserApplication2\n访问http://localhost:8081/user/prop，结果：\n访问http://localhost:8082/user/prop，结果：\n可以看出来，不管是dev，还是test环境，都读取到了envSharedValue这个属性的值。\n4）配置共享的优先级 当nacos、服务本地同时出现相同属性时，优先级有高低之分：\n1.4.搭建Nacos集群 Nacos生产环境下一定要部署为集群状态，部署方式参考课前资料中的文档：\n2.Feign远程调用 先来看我们以前利用RestTemplate发起远程调用的代码：\n存在下面的问题：\n•代码可读性差，编程体验不统一\n•参数复杂URL难以维护\nFeign是一个声明式的http客户端，官方地址：https://github.com/OpenFeign/feign\n其作用就是帮助我们优雅的实现http请求的发送，解决上面提到的问题。\n2.1.Feign替代RestTemplate Fegin的使用步骤如下：\n1）引入依赖 我们在order-service服务的pom文件中引入feign的依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2）添加注解 在order-service的启动类添加注解开启Feign的功能：\n3）编写Feign的客户端 在order-service中新建一个接口，内容如下：\npackage cn.itcast.order.client; import cn.itcast.order.pojo.User; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @FeignClient(\u0026#34;userservice\u0026#34;) public interface UserClient { @GetMapping(\u0026#34;/user/{id}\u0026#34;) User findById(@PathVariable(\u0026#34;id\u0026#34;) Long id); } 这个客户端主要是基于SpringMVC的注解来声明远程调用的信息，比如：\n服务名称：userservice 请求方式：GET 请求路径：/user/{id} 请求参数：Long id 返回值类型：User 这样，Feign就可以帮助我们发送http请求，无需自己使用RestTemplate来发送了。\n4）测试 修改order-service中的OrderService类中的queryOrderById方法，使用Feign客户端代替RestTemplate：\n是不是看起来优雅多了。\n5）总结 使用Feign的步骤：\n① 引入依赖\n② 添加@EnableFeignClients注解\n③ 编写FeignClient接口\n④ 使用FeignClient中定义的方法代替RestTemplate\n2.2.自定义配置 Feign可以支持很多的自定义配置，如下表所示：\n类型 作用 说明 feign.Logger.Level 修改日志级别 包含四种不同的级别：NONE、BASIC、HEADERS、FULL feign.codec.Decoder 响应结果的解析器 http远程调用的结果做解析，例如解析json字符串为java对象 feign.codec.Encoder 请求参数编码 将请求参数编码，便于通过http请求发送 feign. Contract 支持的注解格式 默认是SpringMVC的注解 feign. Retryer 失败重试机制 请求失败的重试机制，默认是没有，不过会使用Ribbon的重试 一般情况下，默认值就能满足我们使用，如果要自定义时，只需要创建自定义的@Bean覆盖默认Bean即可。\n下面以日志为例来演示如何自定义配置。\n2.2.1.配置文件方式 基于配置文件修改feign的日志级别可以针对单个服务：\nfeign: client: config: userservice: # 针对某个微服务的配置 loggerLevel: FULL # 日志级别 也可以针对所有服务：\nfeign: client: config: default: # 这里用default就是全局配置，如果是写服务名称，则是针对某个微服务的配置 loggerLevel: FULL # 日志级别 而日志的级别分为四种：\nNONE：不记录任何日志信息，这是默认值。 BASIC：仅记录请求的方法，URL以及响应状态码和执行时间 HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息 FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。 2.2.2.Java代码方式 也可以基于Java代码来修改日志级别，先声明一个类，然后声明一个Logger.Level的对象：\npublic class DefaultFeignConfiguration { @Bean public Logger.Level feignLogLevel(){ return Logger.Level.BASIC; // 日志级别为BASIC } } 如果要全局生效，将其放到启动类的@EnableFeignClients这个注解中：\n@EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration .class) 如果是局部生效，则把它放到对应的@FeignClient这个注解中：\n@FeignClient(value = \u0026#34;userservice\u0026#34;, configuration = DefaultFeignConfiguration .class) 2.3.Feign使用优化 Feign底层发起http请求，依赖于其它的框架。其底层客户端实现包括：\n•URLConnection：默认实现，不支持连接池\n•Apache HttpClient ：支持连接池\n•OKHttp：支持连接池\n因此提高Feign的性能主要手段就是使用连接池代替默认的URLConnection。\n这里我们用Apache的HttpClient来演示。\n1）引入依赖\n在order-service的pom文件中引入Apache的HttpClient依赖：\n\u0026lt;!--httpClient的依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.openfeign\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;feign-httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2）配置连接池\n在order-service的application.yml中添加配置：\nfeign: client: config: default: # default全局的配置 loggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息 httpclient: enabled: true # 开启feign对HttpClient的支持 max-connections: 200 # 最大的连接数 max-connections-per-route: 50 # 每个路径的最大连接数 接下来，在FeignClientFactoryBean中的loadBalance方法中打断点：\nDebug方式启动order-service服务，可以看到这里的client，底层就是Apache HttpClient：\n总结，Feign的优化：\n1.日志级别尽量用basic\n2.使用HttpClient或OKHttp代替URLConnection\n① 引入feign-httpClient依赖\n② 配置文件开启httpClient功能，设置连接池参数\n2.4.最佳实践 所谓最近实践，就是使用过程中总结的经验，最好的一种使用方式。\n自习观察可以发现，Feign的客户端与服务提供者的controller代码非常相似：\nfeign客户端：\nUserController：\n有没有一种办法简化这种重复的代码编写呢？\n2.4.1.继承方式 一样的代码可以通过继承来共享：\n1）定义一个API接口，利用定义方法，并基于SpringMVC注解做声明。\n2）Feign客户端和Controller都集成改接口\n优点：\n简单 实现了代码共享 缺点：\n服务提供方、服务消费方紧耦合\n参数列表中的注解映射并不会继承，因此Controller中必须再次声明方法、参数列表、注解\n2.4.2.抽取方式 将Feign的Client抽取为独立模块，并且把接口有关的POJO、默认的Feign配置都放到这个模块中，提供给所有消费者使用。\n例如，将UserClient、User、Feign的默认配置都抽取到一个feign-api包中，所有微服务引用该依赖包，即可直接使用。\n2.4.3.实现基于抽取的最佳实践 1）抽取 首先创建一个module，命名为feign-api：\n项目结构：\n在feign-api中然后引入feign的starter依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 然后，order-service中编写的UserClient、User、DefaultFeignConfiguration都复制到feign-api项目中\n2）在order-service中使用feign-api 首先，删除order-service中的UserClient、User、DefaultFeignConfiguration等类或接口。\n在order-service的pom文件中中引入feign-api的依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;cn.itcast.demo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;feign-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 修改order-service中的所有与上述三个组件有关的导包部分，改成导入feign-api中的包\n3）重启测试 重启后，发现服务报错了：\n这是因为UserClient现在在cn.itcast.feign.clients包下，\n而order-service的@EnableFeignClients注解是在cn.itcast.order包下，不在同一个包，无法扫描到UserClient。\n4）解决扫描包问题 方式一：\n指定Feign应该扫描的包：\n@EnableFeignClients(basePackages = \u0026#34;cn.itcast.feign.clients\u0026#34;) 方式二：\n指定需要加载的Client接口：\n@EnableFeignClients(clients = {UserClient.class}) 3.Gateway服务网关 Spring Cloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等响应式编程和事件流技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。\n3.1.为什么需要网关 Gateway网关是我们服务的守门神，所有微服务的统一入口。\n网关的核心功能特性：\n请求路由 权限控制 限流 架构图：\n权限控制：网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。\n路由和负载均衡：一切请求都必须先经过gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。\n限流：当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。\n在SpringCloud中网关的实现包括两种：\ngateway zuul Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。\n3.2.gateway快速入门 下面，我们就演示下网关的基本路由功能。基本步骤如下：\n创建SpringBoot工程gateway，引入网关依赖 编写启动类 编写基础配置和路由规则 启动网关服务进行测试 1）创建gateway服务，引入依赖 创建服务：\n引入依赖：\n\u0026lt;!--网关--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-gateway\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--nacos服务发现依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2）编写启动类 package cn.itcast.gateway; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); } } 3）编写基础配置和路由规则 创建application.yml文件，内容如下：\nserver: port: 10010 # 网关端口 spring: application: name: gateway # 服务名称 cloud: nacos: server-addr: localhost:8848 # nacos地址 gateway: routes: # 网关路由配置 - id: user-service # 路由id，自定义，只要唯一即可 # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址 uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称 predicates: # 路由断言，也就是判断请求是否符合路由规则的条件 - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求 我们将符合Path 规则的一切请求，都代理到 uri参数指定的地址。\n本例中，我们将 /user/**开头的请求，代理到lb://userservice，lb是负载均衡，根据服务名拉取服务列表，实现负载均衡。\n4）重启测试 重启网关，访问http://localhost:10010/user/1时，符合/user/**规则，请求转发到uri：http://userservice/user/1，得到了结果：\n5）网关路由的流程图 整个访问的流程如下：\n总结：\n网关搭建步骤：\n创建项目，引入nacos服务发现和gateway依赖\n配置application.yml，包括服务基本信息、nacos地址、路由\n路由配置包括：\n路由id：路由的唯一标示\n路由目标（uri）：路由的目标地址，http代表固定地址，lb代表根据服务名负载均衡\n路由断言（predicates）：判断路由的规则，\n路由过滤器（filters）：对请求或响应做处理\n接下来，就重点来学习路由断言和路由过滤器的详细知识\n3.3.断言工厂 我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件\n例如Path=/user/**是按照路径匹配，这个规则是由\norg.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory类来\n处理的，像这样的断言工厂在SpringCloudGateway还有十几个:\n名称 说明 示例 After 是某个时间点后的请求 - After=2037-01-20T17:42:47.789-07:00[America/Denver] Before 是某个时间点之前的请求 - Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai] Between 是某两个时间点之前的请求 - Between=2037-01-20T17:42:47.789-07:00[America/Denver], 2037-01-21T17:42:47.789-07:00[America/Denver] Cookie 请求必须包含某些cookie - Cookie=chocolate, ch.p Header 请求必须包含某些header - Header=X-Request-Id, \\d+ Host 请求必须是访问某个host（域名） - Host=.somehost.org,.anotherhost.org Method 请求方式必须是指定方式 - Method=GET,POST Path 请求路径必须符合指定规则 - Path=/red/{segment},/blue/** Query 请求参数必须包含指定参数 - Query=name, Jack或者- Query=name RemoteAddr 请求者的ip必须是指定范围 - RemoteAddr=192.168.1.1/24 Weight 权重处理 我们只需要掌握Path这种路由工程就可以了。\n3.4.过滤器工厂 GatewayFilter是网关中提供的一种过滤器，可以对进入网关的请求和微服务返回的响应做处理：\n3.4.1.路由过滤器的种类 Spring提供了31种不同的路由过滤器工厂。例如：\n名称 说明 AddRequestHeader 给当前请求添加一个请求头 RemoveRequestHeader 移除请求中的一个请求头 AddResponseHeader 给响应结果中添加一个响应头 RemoveResponseHeader 从响应结果中移除有一个响应头 RequestRateLimiter 限制请求的流量 3.4.2.请求头过滤器 下面我们以AddRequestHeader 为例来讲解。\n需求：给所有进入userservice的请求添加一个请求头：Truth=itcast is freaking awesome!\n只需要修改gateway服务的application.yml文件，添加路由过滤即可：\nspring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** filters: # 过滤器 - AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头 当前过滤器写在userservice路由下，因此仅仅对访问userservice的请求有效。\n3.4.3.默认过滤器 如果要对所有的路由都生效，则可以将过滤器工厂写到default下。格式如下：\nspring: cloud: gateway: routes: - id: user-service uri: lb://userservice predicates: - Path=/user/** default-filters: # 默认过滤项 - AddRequestHeader=Truth, Itcast is freaking awesome! 3.4.4.总结 过滤器的作用是什么？\n① 对路由的请求或响应做加工处理，比如添加请求头\n② 配置在路由下的过滤器只对当前路由的请求生效\ndefaultFilters的作用是什么？\n① 对所有路由都生效的过滤器\n3.5.全局过滤器 上一节学习的过滤器，网关提供了31种，但每一种过滤器的作用都是固定的。如果我们希望拦截请求，做自己的业务逻辑则没办法实现。\n3.5.1.全局过滤器作用 全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现。\n定义方式是实现GlobalFilter接口。\npublic interface GlobalFilter { /** * 处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理 * * @param exchange 请求上下文，里面可以获取Request、Response等信息 * @param chain 用来把请求委托给下一个过滤器 * @return {@code Mono\u0026lt;Void\u0026gt;} 返回标示当前过滤器业务结束 */ Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain); } 在filter中编写自定义逻辑，可以实现下列功能：\n登录状态判断 权限校验 请求限流等 3.5.2.自定义全局过滤器 需求：定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件：\n参数中是否有authorization，\nauthorization参数值是否为admin\n如果同时满足则放行，否则拦截\n实现：\n在gateway中定义一个过滤器：\npackage cn.itcast.gateway.filters; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.annotation.Order; import org.springframework.http.HttpStatus; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; @Order(-1) @Component public class AuthorizeFilter implements GlobalFilter { @Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 1.获取请求参数 MultiValueMap\u0026lt;String, String\u0026gt; params = exchange.getRequest().getQueryParams(); // 2.获取authorization参数 String auth = params.getFirst(\u0026#34;authorization\u0026#34;); // 3.校验 if (\u0026#34;admin\u0026#34;.equals(auth)) { // 放行 return chain.filter(exchange); } // 4.拦截 // 4.1.禁止访问，设置状态码 exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN); // 4.2.结束处理 return exchange.getResponse().setComplete(); } } 3.5.3.过滤器执行顺序 请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter\n请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，排序后依次执行每个过滤器：\n排序的规则是什么呢？\n每一个过滤器都必须指定一个int类型的order值，order值越小，优先级越高，执行顺序越靠前。 GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定 路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。 当过滤器的order值一样时，会按照 defaultFilter \u0026gt; 路由过滤器 \u0026gt; GlobalFilter的顺序执行。 详细内容，可以查看源码：\norg.springframework.cloud.gateway.route.RouteDefinitionRouteLocator#getFilters()方法是先加载defaultFilters，然后再加载某个route的filters，然后合并。\norg.springframework.cloud.gateway.handler.FilteringWebHandler#handle()方法会加载全局过滤器，与前面的过滤器合并后根据order排序，组织过滤器链\n3.6.跨域问题 3.6.1.什么是跨域问题 跨域：域名不一致就是跨域，主要包括：\n域名不同： www.taobao.com 和 www.taobao.org 和 www.jd.com 和 miaosha.jd.com\n域名相同，端口不同：localhost:8080和localhost8081\n跨域问题：浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题\n解决方案：CORS，这个以前应该学习过，这里不再赘述了。不知道的小伙伴可以查看https://www.ruanyifeng.com/blog/2016/04/cors.html\n3.6.2.模拟跨域问题 找到课前资料的页面文件：\n放入tomcat或者nginx这样的web服务器中，启动并访问。\n可以在浏览器控制台看到下面的错误：\n从localhost:8090访问localhost:10010，端口不同，显然是跨域的请求。\n3.6.3.解决跨域问题 在gateway服务的application.yml文件中，添加下面的配置：\nspring: cloud: gateway: # 。。。 globalcors: # 全局的跨域处理 add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题 corsConfigurations: \u0026#39;[/**]\u0026#39;: allowedOrigins: # 允许哪些网站的跨域请求 - \u0026#34;http://localhost:8090\u0026#34; allowedMethods: # 允许的跨域ajax的请求方式 - \u0026#34;GET\u0026#34; - \u0026#34;POST\u0026#34; - \u0026#34;DELETE\u0026#34; - \u0026#34;PUT\u0026#34; - \u0026#34;OPTIONS\u0026#34; allowedHeaders: \u0026#34;*\u0026#34; # 允许在请求中携带的头信息 allowCredentials: true # 是否允许携带cookie maxAge: 360000 # 这次跨域检测的有效期 ","permalink":"https://XianCH.github.io/posts/tech/distributed/springcloud/","summary":"1.Nacos配置管理 Nacos除了可以做注册中心，同样可以做配置管理来使用。 1.1.统一配置管理 当微服务部署的实例越来越多，达到数十、数百时，逐个修改微服务配置就会让人抓狂，而且很容易出错。我们需要一种统一配置管理方案，可以集中管理所有实例的配置。 Nacos一方面可以将配置集中","title":"springcloud"},{"content":"1.单机部署 我们在Centos7虚拟机中使用Docker来安装。\n1.1.下载镜像 方式一：在线拉取\ndocker pull rabbitmq:3.8-management 方式二：从本地加载\n在课前资料已经提供了镜像包：\n上传到虚拟机中后，使用命令加载镜像即可：\ndocker load -i mq.tar 1.2.安装MQ 执行下面的命令来运行MQ容器：\ndocker run \\ -e RABBITMQ_DEFAULT_USER=itcast \\ -e RABBITMQ_DEFAULT_PASS=123321 \\ -v mq-plugins:/plugins \\ --name mq \\ --hostname mq1 \\ -p 15672:15672 \\ -p 5672:5672 \\ -d \\ rabbitmq:3.8-management 2.安装DelayExchange插件 官方的安装指南地址为：https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq\n上述文档是基于linux原生安装RabbitMQ，然后安装插件。\n因为我们之前是基于Docker安装RabbitMQ，所以下面我们会讲解基于Docker来安装RabbitMQ插件。\n2.1.下载插件 RabbitMQ有一个官方的插件社区，地址为：https://www.rabbitmq.com/community-plugins.html\n其中包含各种各样的插件，包括我们要使用的DelayExchange插件：\n大家可以去对应的GitHub页面下载3.8.9版本的插件，地址为https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/tag/3.8.9这个对应RabbitMQ的3.8.5以上版本。\n课前资料也提供了下载好的插件：\n2.2.上传插件 因为我们是基于Docker安装，所以需要先查看RabbitMQ的插件目录对应的数据卷。如果不是基于Docker的同学，请参考第一章部分，重新创建Docker容器。\n我们之前设定的RabbitMQ的数据卷名称为mq-plugins，所以我们使用下面命令查看数据卷：\ndocker volume inspect mq-plugins 可以得到下面结果：\n接下来，将插件上传到这个目录即可：\n2.3.安装插件 最后就是安装了，需要进入MQ容器内部来执行安装。我的容器名为mq，所以执行下面命令：\ndocker exec -it mq bash 执行时，请将其中的 -it 后面的mq替换为你自己的容器名.\n进入容器内部后，执行下面命令开启插件：\nrabbitmq-plugins enable rabbitmq_delayed_message_exchange 结果如下：\n3.集群部署 接下来，我们看看如何安装RabbitMQ的集群。\n2.1.集群分类 在RabbitMQ的官方文档中，讲述了两种集群的配置方式：\n普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。 镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。 我们先来看普通模式集群，我们的计划部署3节点的mq集群：\n主机名 控制台端口 amqp通信端口 mq1 8081 \u0026mdash;\u0026gt; 15672 8071 \u0026mdash;\u0026gt; 5672 mq2 8082 \u0026mdash;\u0026gt; 15672 8072 \u0026mdash;\u0026gt; 5672 mq3 8083 \u0026mdash;\u0026gt; 15672 8073 \u0026mdash;\u0026gt; 5672 集群中的节点标示默认都是：rabbit@[hostname]，因此以上三个节点的名称分别为：\nrabbit@mq1 rabbit@mq2 rabbit@mq3 2.2.获取cookie RabbitMQ底层依赖于Erlang，而Erlang虚拟机就是一个面向分布式的语言，默认就支持集群模式。集群模式中的每个RabbitMQ 节点使用 cookie 来确定它们是否被允许相互通信。\n要使两个节点能够通信，它们必须具有相同的共享秘密，称为Erlang cookie。cookie 只是一串最多 255 个字符的字母数字字符。\n每个集群节点必须具有相同的 cookie。实例之间也需要它来相互通信。\n我们先在之前启动的mq容器中获取一个cookie值，作为集群的cookie。执行下面的命令：\ndocker exec -it mq cat /var/lib/rabbitmq/.erlang.cookie 可以看到cookie值如下：\nFXZMCVGLBIXZCDEMMVZQ 接下来，停止并删除当前的mq容器，我们重新搭建集群。\ndocker rm -f mq 2.3.准备集群配置 在/tmp目录新建一个配置文件 rabbitmq.conf：\ncd /tmp # 创建文件 touch rabbitmq.conf 文件内容如下：\nloopback_users.guest = false listeners.tcp.default = 5672 cluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_config cluster_formation.classic_config.nodes.1 = rabbit@mq1 cluster_formation.classic_config.nodes.2 = rabbit@mq2 cluster_formation.classic_config.nodes.3 = rabbit@mq3 再创建一个文件，记录cookie\ncd /tmp # 创建cookie文件 touch .erlang.cookie # 写入cookie echo \u0026#34;FXZMCVGLBIXZCDEMMVZQ\u0026#34; \u0026gt; .erlang.cookie # 修改cookie文件的权限 chmod 600 .erlang.cookie 准备三个目录,mq1、mq2、mq3：\ncd /tmp # 创建目录 mkdir mq1 mq2 mq3 然后拷贝rabbitmq.conf、cookie文件到mq1、mq2、mq3：\n# 进入/tmp cd /tmp # 拷贝 cp rabbitmq.conf mq1 cp rabbitmq.conf mq2 cp rabbitmq.conf mq3 cp .erlang.cookie mq1 cp .erlang.cookie mq2 cp .erlang.cookie mq3 2.4.启动集群 创建一个网络：\ndocker network create mq-net docker volume create\n运行命令\ndocker run -d --net mq-net \\ -v ${PWD}/mq1/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\ -v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\ -e RABBITMQ_DEFAULT_USER=itcast \\ -e RABBITMQ_DEFAULT_PASS=123321 \\ --name mq1 \\ --hostname mq1 \\ -p 8071:5672 \\ -p 8081:15672 \\ rabbitmq:3.8-management docker run -d --net mq-net \\ -v ${PWD}/mq2/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\ -v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\ -e RABBITMQ_DEFAULT_USER=itcast \\ -e RABBITMQ_DEFAULT_PASS=123321 \\ --name mq2 \\ --hostname mq2 \\ -p 8072:5672 \\ -p 8082:15672 \\ rabbitmq:3.8-management docker run -d --net mq-net \\ -v ${PWD}/mq3/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\ -v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\ -e RABBITMQ_DEFAULT_USER=itcast \\ -e RABBITMQ_DEFAULT_PASS=123321 \\ --name mq3 \\ --hostname mq3 \\ -p 8073:5672 \\ -p 8083:15672 \\ rabbitmq:3.8-management 2.5.测试 在mq1这个节点上添加一个队列：\n如图，在mq2和mq3两个控制台也都能看到：\n2.5.1.数据共享测试 点击这个队列，进入管理页面：\n然后利用控制台发送一条消息到这个队列：\n结果在mq2、mq3上都能看到这条消息：\n2.5.2.可用性测试 我们让其中一台节点mq1宕机：\ndocker stop mq1 然后登录mq2或mq3的控制台，发现simple.queue也不可用了：\n说明数据并没有拷贝到mq2和mq3。\n4.镜像模式 在刚刚的案例中，一旦创建队列的主机宕机，队列就会不可用。不具备高可用能力。如果要解决这个问题，必须使用官方提供的镜像集群方案。\n官方文档地址：https://www.rabbitmq.com/ha.html\n4.1.镜像模式的特征 默认情况下，队列只保存在创建该队列的节点上。而镜像模式下，创建队列的节点被称为该队列的主节点，队列还会拷贝到集群中的其它节点，也叫做该队列的镜像节点。\n但是，不同队列可以在集群中的任意节点上创建，因此不同队列的主节点可以不同。甚至，一个队列的主节点可能是另一个队列的镜像节点。\n用户发送给队列的一切请求，例如发送消息、消息回执默认都会在主节点完成，如果是从节点接收到请求，也会路由到主节点去完成。镜像节点仅仅起到备份数据作用。\n当主节点接收到消费者的ACK时，所有镜像都会删除节点中的数据。\n总结如下：\n镜像队列结构是一主多从（从就是镜像） 所有操作都是主节点完成，然后同步给镜像节点 主宕机后，镜像节点会替代成新的主（如果在主从同步完成前，主就已经宕机，可能出现数据丢失） 不具备负载均衡功能，因为所有操作都会有主节点完成（但是不同队列，其主节点可以不同，可以利用这个提高吞吐量） 4.2.镜像模式的配置 镜像模式的配置有3种模式：\nha-mode ha-params 效果 准确模式exactly 队列的副本量count 集群中队列副本（主服务器和镜像服务器之和）的数量。count如果为1意味着单个副本：即队列主节点。count值为2表示2个副本：1个队列主和1个队列镜像。换句话说：count = 镜像数量 + 1。如果群集中的节点数少于count，则该队列将镜像到所有节点。如果有集群总数大于count+1，并且包含镜像的节点出现故障，则将在另一个节点上创建一个新的镜像。 all (none) 队列在群集中的所有节点之间进行镜像。队列将镜像到任何新加入的节点。镜像到所有节点将对所有群集节点施加额外的压力，包括网络I / O，磁盘I / O和磁盘空间使用情况。推荐使用exactly，设置副本数为（N / 2 +1）。 nodes node names 指定队列创建到哪些节点，如果指定的节点全部不存在，则会出现异常。如果指定的节点在集群中存在，但是暂时不可用，会创建节点到当前客户端连接到的节点。 这里我们以rabbitmqctl命令作为案例来讲解配置语法。\n语法示例：\n4.2.1.exactly模式 rabbitmqctl set_policy ha-two \u0026#34;^two\\.\u0026#34; \u0026#39;{\u0026#34;ha-mode\u0026#34;:\u0026#34;exactly\u0026#34;,\u0026#34;ha-params\u0026#34;:2,\u0026#34;ha-sync-mode\u0026#34;:\u0026#34;automatic\u0026#34;}\u0026#39; rabbitmqctl set_policy：固定写法 ha-two：策略名称，自定义 \u0026quot;^two\\.\u0026quot;：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以two.开头的队列名称 '{\u0026quot;ha-mode\u0026quot;:\u0026quot;exactly\u0026quot;,\u0026quot;ha-params\u0026quot;:2,\u0026quot;ha-sync-mode\u0026quot;:\u0026quot;automatic\u0026quot;}': 策略内容 \u0026quot;ha-mode\u0026quot;:\u0026quot;exactly\u0026quot;：策略模式，此处是exactly模式，指定副本数量 \u0026quot;ha-params\u0026quot;:2：策略参数，这里是2，就是副本数量为2，1主1镜像 \u0026quot;ha-sync-mode\u0026quot;:\u0026quot;automatic\u0026quot;：同步策略，默认是manual，即新加入的镜像节点不会同步旧的消息。如果设置为automatic，则新加入的镜像节点会把主节点中所有消息都同步，会带来额外的网络开销 4.2.2.all模式 rabbitmqctl set_policy ha-all \u0026#34;^all\\.\u0026#34; \u0026#39;{\u0026#34;ha-mode\u0026#34;:\u0026#34;all\u0026#34;}\u0026#39; ha-all：策略名称，自定义 \u0026quot;^all\\.\u0026quot;：匹配所有以all.开头的队列名 '{\u0026quot;ha-mode\u0026quot;:\u0026quot;all\u0026quot;}'：策略内容 \u0026quot;ha-mode\u0026quot;:\u0026quot;all\u0026quot;：策略模式，此处是all模式，即所有节点都会称为镜像节点 4.2.3.nodes模式 rabbitmqctl set_policy ha-nodes \u0026#34;^nodes\\.\u0026#34; \u0026#39;{\u0026#34;ha-mode\u0026#34;:\u0026#34;nodes\u0026#34;,\u0026#34;ha-params\u0026#34;:[\u0026#34;rabbit@nodeA\u0026#34;, \u0026#34;rabbit@nodeB\u0026#34;]}\u0026#39; rabbitmqctl set_policy：固定写法 ha-nodes：策略名称，自定义 \u0026quot;^nodes\\.\u0026quot;：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以nodes.开头的队列名称 '{\u0026quot;ha-mode\u0026quot;:\u0026quot;nodes\u0026quot;,\u0026quot;ha-params\u0026quot;:[\u0026quot;rabbit@nodeA\u0026quot;, \u0026quot;rabbit@nodeB\u0026quot;]}': 策略内容 \u0026quot;ha-mode\u0026quot;:\u0026quot;nodes\u0026quot;：策略模式，此处是nodes模式 \u0026quot;ha-params\u0026quot;:[\u0026quot;rabbit@mq1\u0026quot;, \u0026quot;rabbit@mq2\u0026quot;]：策略参数，这里指定副本所在节点名称 4.3.测试 我们使用exactly模式的镜像，因为集群节点数量为3，因此镜像数量就设置为2.\n运行下面的命令：\ndocker exec -it mq1 rabbitmqctl set_policy ha-two \u0026#34;^two\\.\u0026#34; \u0026#39;{\u0026#34;ha-mode\u0026#34;:\u0026#34;exactly\u0026#34;,\u0026#34;ha-params\u0026#34;:2,\u0026#34;ha-sync-mode\u0026#34;:\u0026#34;automatic\u0026#34;}\u0026#39; 下面，我们创建一个新的队列：\n在任意一个mq控制台查看队列：\n4.3.1.测试数据共享 给two.queue发送一条消息：\n然后在mq1、mq2、mq3的任意控制台查看消息：\n4.3.2.测试高可用 现在，我们让two.queue的主节点mq1宕机：\ndocker stop mq1 查看集群状态：\n查看队列状态：\n发现依然是健康的！并且其主节点切换到了rabbit@mq2上\n5.仲裁队列 从RabbitMQ 3.8版本开始，引入了新的仲裁队列，他具备与镜像队里类似的功能，但使用更加方便。\n5.1.添加仲裁队列 在任意控制台添加一个队列，一定要选择队列类型为Quorum类型。\n在任意控制台查看队列：\n可以看到，仲裁队列的 + 2字样。代表这个队列有2个镜像节点。\n因为仲裁队列默认的镜像数为5。如果你的集群有7个节点，那么镜像数肯定是5；而我们集群只有3个节点，因此镜像数量就是3.\n5.2.测试 可以参考对镜像集群的测试，效果是一样的。\n5.3.集群扩容 5.3.1.加入集群 1）启动一个新的MQ容器：\ndocker run -d --net mq-net \\ -v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\ -e RABBITMQ_DEFAULT_USER=itcast \\ -e RABBITMQ_DEFAULT_PASS=123321 \\ --name mq4 \\ --hostname mq5 \\ -p 8074:15672 \\ -p 8084:15672 \\ rabbitmq:3.8-management 2）进入容器控制台：\ndocker exec -it mq4 bash 3）停止mq进程\nrabbitmqctl stop_app 4）重置RabbitMQ中的数据：\nrabbitmqctl reset 5）加入mq1：\nrabbitmqctl join_cluster rabbit@mq1 6）再次启动mq进程\nrabbitmqctl start_app 5.3.2.增加仲裁队列副本 我们先查看下quorum.queue这个队列目前的副本情况，进入mq1容器：\ndocker exec -it mq1 bash 执行命令：\nrabbitmq-queues quorum_status \u0026#34;quorum.queue\u0026#34; 结果：\n现在，我们让mq4也加入进来：\nrabbitmq-queues add_member \u0026#34;quorum.queue\u0026#34; \u0026#34;rabbit@mq4\u0026#34; 结果：\n再次查看：\nrabbitmq-queues quorum_status \u0026#34;quorum.queue\u0026#34; 查看控制台，发现quorum.queue的镜像数量也从原来的 +2 变成了 +3：\n","permalink":"https://XianCH.github.io/posts/tech/distributed/rabbitmq%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97/","summary":"1.单机部署 我们在Centos7虚拟机中使用Docker来安装。 1.1.下载镜像 方式一：在线拉取 docker pull rabbitmq:3.8-management 方式二：从本地加载 在课前资料已经提供了镜像包： 上传到虚拟机中后，使用命令加载镜像即可： docker load -i mq.tar 1.2.安装MQ 执行下面的命令来运行MQ容器： docker run \\ -e RABBITMQ_DEFAULT_USER=itcast \\ -e RABBITMQ_DEFAULT_PASS=123321 \\ -v mq-plugins:/plugins \\ --name mq \\ --hostname mq1 \\ -p","title":"RabbitMq部署指南"},{"content":"服务异步通信-高级篇 消息队列在使用过程中，面临着很多实际问题需要思考：\n1.消息可靠性 消息从发送，到消费者接收，会经理多个过程：\n其中的每一步都可能导致消息丢失，常见的丢失原因包括：\n发送时丢失： 生产者发送的消息未送达exchange 消息到达exchange后未到达queue MQ宕机，queue将消息丢失 consumer接收到消息后未消费就宕机 针对这些问题，RabbitMQ分别给出了解决方案：\n生产者确认机制 mq持久化 消费者确认机制 失败重试机制 下面我们就通过案例来演示每一个步骤。\n首先，导入课前资料提供的demo工程：\n项目结构如下：\n1.1.生产者消息确认 RabbitMQ提供了publisher confirm机制来避免消息发送到MQ过程中丢失。这种机制必须给每个消息指定一个唯一ID。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功。\n返回结果有两种方式：\npublisher-confirm，发送者确认 消息成功投递到交换机，返回ack 消息未投递到交换机，返回nack publisher-return，发送者回执 消息投递到交换机了，但是没有路由到队列。返回ACK，及路由失败原因。 注意：\n1.1.1.修改配置 首先，修改publisher服务中的application.yml文件，添加下面的内容：\nspring: rabbitmq: publisher-confirm-type: correlated publisher-returns: true template: mandatory: true 说明：\npublish-confirm-type：开启publisher-confirm，这里支持两种类型： simple：同步等待confirm结果，直到超时 correlated：异步回调，定义ConfirmCallback，MQ返回结果时会回调这个ConfirmCallback publish-returns：开启publish-return功能，同样是基于callback机制，不过是定义ReturnCallback template.mandatory：定义消息路由失败时的策略。true，则调用ReturnCallback；false：则直接丢弃消息 1.1.2.定义Return回调 每个RabbitTemplate只能配置一个ReturnCallback，因此需要在项目加载时配置：\n修改publisher服务，添加一个：\npackage cn.itcast.mq.config; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.BeansException; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import org.springframework.context.annotation.Configuration; @Slf4j @Configuration public class CommonConfig implements ApplicationContextAware { @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { // 获取RabbitTemplate RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class); // 设置ReturnCallback rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -\u0026gt; { // 投递失败，记录日志 log.info(\u0026#34;消息发送失败，应答码{}，原因{}，交换机{}，路由键{},消息{}\u0026#34;, replyCode, replyText, exchange, routingKey, message.toString()); // 如果有业务需要，可以重发消息 }); } } 1.1.3.定义ConfirmCallback ConfirmCallback可以在发送消息时指定，因为每个业务处理confirm成功或失败的逻辑不一定相同。\n在publisher服务的cn.itcast.mq.spring.SpringAmqpTest类中，定义一个单元测试方法：\npublic void testSendMessage2SimpleQueue() throws InterruptedException { // 1.消息体 String message = \u0026#34;hello, spring amqp!\u0026#34;; // 2.全局唯一的消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 3.添加callback correlationData.getFuture().addCallback( result -\u0026gt; { if(result.isAck()){ // 3.1.ack，消息成功 log.debug(\u0026#34;消息发送成功, ID:{}\u0026#34;, correlationData.getId()); }else{ // 3.2.nack，消息失败 log.error(\u0026#34;消息发送失败, ID:{}, 原因{}\u0026#34;,correlationData.getId(), result.getReason()); } }, ex -\u0026gt; log.error(\u0026#34;消息发送异常, ID:{}, 原因{}\u0026#34;,correlationData.getId(),ex.getMessage()) ); // 4.发送消息 rabbitTemplate.convertAndSend(\u0026#34;task.direct\u0026#34;, \u0026#34;task\u0026#34;, message, correlationData); // 休眠一会儿，等待ack回执 Thread.sleep(2000); } 1.2.消息持久化 生产者确认可以确保消息投递到RabbitMQ的队列中，但是消息发送到RabbitMQ以后，如果突然宕机，也可能导致消息丢失。\n要想确保消息在RabbitMQ中安全保存，必须开启消息持久化机制。\n交换机持久化 队列持久化 消息持久化 1.2.1.交换机持久化 RabbitMQ中交换机默认是非持久化的，mq重启后就丢失。\nSpringAMQP中可以通过代码指定交换机持久化：\n@Bean public DirectExchange simpleExchange(){ // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除 return new DirectExchange(\u0026#34;simple.direct\u0026#34;, true, false); } 事实上，默认情况下，由SpringAMQP声明的交换机都是持久化的。\n可以在RabbitMQ控制台看到持久化的交换机都会带上D的标示：\n1.2.2.队列持久化 RabbitMQ中队列默认是非持久化的，mq重启后就丢失。\nSpringAMQP中可以通过代码指定交换机持久化：\n@Bean public Queue simpleQueue(){ // 使用QueueBuilder构建队列，durable就是持久化的 return QueueBuilder.durable(\u0026#34;simple.queue\u0026#34;).build(); } 事实上，默认情况下，由SpringAMQP声明的队列都是持久化的。\n可以在RabbitMQ控制台看到持久化的队列都会带上D的标示：\n1.2.3.消息持久化 利用SpringAMQP发送消息时，可以设置消息的属性（MessageProperties），指定delivery-mode：\n1：非持久化 2：持久化 用java代码指定：\n默认情况下，SpringAMQP发出的任何消息都是持久化的，不用特意指定。\n1.3.消费者消息确认 RabbitMQ是阅后即焚机制，RabbitMQ确认消息被消费者消费后会立刻删除。\n而RabbitMQ是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。\n设想这样的场景：\n1）RabbitMQ投递消息给消费者 2）消费者获取消息后，返回ACK给RabbitMQ 3）RabbitMQ删除消息 4）消费者宕机，消息尚未处理 这样，消息就丢失了。因此消费者返回ACK的时机非常重要。\n而SpringAMQP则允许配置三种确认模式：\n•manual：手动ack，需要在业务代码结束后，调用api发送ack。\n•auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack\n•none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除\n由此可知：\nnone模式下，消息投递是不可靠的，可能丢失 auto模式类似事务机制，出现异常时返回nack，消息回滚到mq；没有异常，返回ack manual：自己根据业务情况，判断什么时候该ack 一般，我们都是使用默认的auto即可。\n1.3.1.演示none模式 修改consumer服务的application.yml文件，添加下面内容：\nspring: rabbitmq: listener: simple: acknowledge-mode: none # 关闭ack 修改consumer服务的SpringRabbitListener类中的方法，模拟一个消息处理异常：\n@RabbitListener(queues = \u0026#34;simple.queue\u0026#34;) public void listenSimpleQueue(String msg) { log.info(\u0026#34;消费者接收到simple.queue的消息：【{}】\u0026#34;, msg); // 模拟异常 System.out.println(1 / 0); log.debug(\u0026#34;消息处理完成！\u0026#34;); } 测试可以发现，当消息处理抛异常时，消息依然被RabbitMQ删除了。\n1.3.2.演示auto模式 再次把确认机制修改为auto:\nspring: rabbitmq: listener: simple: acknowledge-mode: auto # 关闭ack 在异常位置打断点，再次发送消息，程序卡在断点时，可以发现此时消息状态为unack（未确定状态）：\n抛出异常后，因为Spring会自动返回nack，所以消息恢复至Ready状态，并且没有被RabbitMQ删除：\n1.4.消费失败重试机制 当消费者出现异常后，消息会不断requeue（重入队）到队列，再重新发送给消费者，然后再次异常，再次requeue，无限循环，导致mq的消息处理飙升，带来不必要的压力：\n怎么办呢？\n1.4.1.本地重试 我们可以利用Spring的retry机制，在消费者出现异常时利用本地重试，而不是无限制的requeue到mq队列。\n修改consumer服务的application.yml文件，添加内容：\nspring: rabbitmq: listener: simple: retry: enabled: true # 开启消费者失败重试 initial-interval: 1000 # 初识的失败等待时长为1秒 multiplier: 1 # 失败的等待时长倍数，下次等待时长 = multiplier * last-interval max-attempts: 3 # 最大重试次数 stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false 重启consumer服务，重复之前的测试。可以发现：\n在重试3次后，SpringAMQP会抛出异常AmqpRejectAndDontRequeueException，说明本地重试触发了 查看RabbitMQ控制台，发现消息被删除了，说明最后SpringAMQP返回的是ack，mq删除消息了 结论：\n开启本地重试时，消息处理过程中抛出异常，不会requeue到队列，而是在消费者本地重试 重试达到最大次数后，Spring会返回ack，消息会被丢弃 1.4.2.失败策略 在之前的测试中，达到最大重试次数后，消息会被丢弃，这是由Spring内部机制决定的。\n在开启重试模式后，重试次数耗尽，如果消息依然失败，则需要有MessageRecovery接口来处理，它包含三种不同的实现：\nRejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式\nImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队\nRepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机\n比较优雅的一种处理方案是RepublishMessageRecoverer，失败后将消息投递到一个指定的，专门存放异常消息的队列，后续由人工集中处理。\n1）在consumer服务中定义处理失败消息的交换机和队列\n@Bean public DirectExchange errorMessageExchange(){ return new DirectExchange(\u0026#34;error.direct\u0026#34;); } @Bean public Queue errorQueue(){ return new Queue(\u0026#34;error.queue\u0026#34;, true); } @Bean public Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange){ return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(\u0026#34;error\u0026#34;); } 2）定义一个RepublishMessageRecoverer，关联队列和交换机\n@Bean public MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate){ return new RepublishMessageRecoverer(rabbitTemplate, \u0026#34;error.direct\u0026#34;, \u0026#34;error\u0026#34;); } 完整代码：\npackage cn.itcast.mq.config; import org.springframework.amqp.core.Binding; import org.springframework.amqp.core.BindingBuilder; import org.springframework.amqp.core.DirectExchange; import org.springframework.amqp.core.Queue; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.amqp.rabbit.retry.MessageRecoverer; import org.springframework.amqp.rabbit.retry.RepublishMessageRecoverer; import org.springframework.context.annotation.Bean; @Configuration public class ErrorMessageConfig { @Bean public DirectExchange errorMessageExchange(){ return new DirectExchange(\u0026#34;error.direct\u0026#34;); } @Bean public Queue errorQueue(){ return new Queue(\u0026#34;error.queue\u0026#34;, true); } @Bean public Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange){ return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(\u0026#34;error\u0026#34;); } @Bean public MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate){ return new RepublishMessageRecoverer(rabbitTemplate, \u0026#34;error.direct\u0026#34;, \u0026#34;error\u0026#34;); } } 1.5.总结 如何确保RabbitMQ消息的可靠性？\n开启生产者确认机制，确保生产者的消息能到达队列 开启持久化功能，确保消息未消费前在队列中不会丢失 开启消费者确认机制为auto，由spring确认消息处理成功后完成ack 开启消费者失败重试机制，并设置MessageRecoverer，多次重试失败后将消息投递到异常交换机，交由人工处理 2.死信交换机 2.1.初识死信交换机 2.1.1.什么是死信交换机 什么是死信？\n当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）：\n消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false 消息是一个过期消息，超时无人消费 要投递的队列消息满了，无法投递 如果这个包含死信的队列配置了dead-letter-exchange属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为死信交换机（Dead Letter Exchange，检查DLX）。\n如图，一个消息被消费者拒绝了，变成了死信：\n因为simple.queue绑定了死信交换机 dl.direct，因此死信会投递给这个交换机：\n如果这个死信交换机也绑定了一个队列，则消息最终会进入这个存放死信的队列：\n另外，队列将死信投递给死信交换机时，必须知道两个信息：\n死信交换机名称 死信交换机与死信队列绑定的RoutingKey 这样才能确保投递的消息能到达死信交换机，并且正确的路由到死信队列。\n2.1.2.利用死信交换机接收死信（拓展） 在失败重试策略中，默认的RejectAndDontRequeueRecoverer会在本地重试次数耗尽后，发送reject给RabbitMQ，消息变成死信，被丢弃。\n我们可以给simple.queue添加一个死信交换机，给死信交换机绑定一个队列。这样消息变成死信后也不会丢弃，而是最终投递到死信交换机，路由到与死信交换机绑定的队列。\n我们在consumer服务中，定义一组死信交换机、死信队列：\n// 声明普通的 simple.queue队列，并且为其指定死信交换机：dl.direct @Bean public Queue simpleQueue2(){ return QueueBuilder.durable(\u0026#34;simple.queue\u0026#34;) // 指定队列名称，并持久化 .deadLetterExchange(\u0026#34;dl.direct\u0026#34;) // 指定死信交换机 .build(); } // 声明死信交换机 dl.direct @Bean public DirectExchange dlExchange(){ return new DirectExchange(\u0026#34;dl.direct\u0026#34;, true, false); } // 声明存储死信的队列 dl.queue @Bean public Queue dlQueue(){ return new Queue(\u0026#34;dl.queue\u0026#34;, true); } // 将死信队列 与 死信交换机绑定 @Bean public Binding dlBinding(){ return BindingBuilder.bind(dlQueue()).to(dlExchange()).with(\u0026#34;simple\u0026#34;); } 2.1.3.总结 什么样的消息会成为死信？\n消息被消费者reject或者返回nack 消息超时未消费 队列满了 死信交换机的使用场景是什么？\n如果队列绑定了死信交换机，死信会投递到死信交换机； 可以利用死信交换机收集所有消费者处理失败的消息（死信），交由人工处理，进一步提高消息队列的可靠性。 2.2.TTL 一个队列中的消息如果超时未消费，则会变为死信，超时分为两种情况：\n消息所在的队列设置了超时时间 消息本身设置了超时时间 2.2.1.接收超时死信的死信交换机 在consumer服务的SpringRabbitListener中，定义一个新的消费者，并且声明 死信交换机、死信队列：\n@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;dl.ttl.queue\u0026#34;, durable = \u0026#34;true\u0026#34;), exchange = @Exchange(name = \u0026#34;dl.ttl.direct\u0026#34;), key = \u0026#34;ttl\u0026#34; )) public void listenDlQueue(String msg){ log.info(\u0026#34;接收到 dl.ttl.queue的延迟消息：{}\u0026#34;, msg); } 2.2.2.声明一个队列，并且指定TTL 要给队列设置超时时间，需要在声明队列时配置x-message-ttl属性：\n@Bean public Queue ttlQueue(){ return QueueBuilder.durable(\u0026#34;ttl.queue\u0026#34;) // 指定队列名称，并持久化 .ttl(10000) // 设置队列的超时时间，10秒 .deadLetterExchange(\u0026#34;dl.ttl.direct\u0026#34;) // 指定死信交换机 .build(); } 注意，这个队列设定了死信交换机为dl.ttl.direct\n声明交换机，将ttl与交换机绑定：\n@Bean public DirectExchange ttlExchange(){ return new DirectExchange(\u0026#34;ttl.direct\u0026#34;); } @Bean public Binding ttlBinding(){ return BindingBuilder.bind(ttlQueue()).to(ttlExchange()).with(\u0026#34;ttl\u0026#34;); } 发送消息，但是不要指定TTL：\n@Test public void testTTLQueue() { // 创建消息 String message = \u0026#34;hello, ttl queue\u0026#34;; // 消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 发送消息 rabbitTemplate.convertAndSend(\u0026#34;ttl.direct\u0026#34;, \u0026#34;ttl\u0026#34;, message, correlationData); // 记录日志 log.debug(\u0026#34;发送消息成功\u0026#34;); } 发送消息的日志：\n查看下接收消息的日志：\n因为队列的TTL值是10000ms，也就是10秒。可以看到消息发送与接收之间的时差刚好是10秒。\n2.2.3.发送消息时，设定TTL 在发送消息时，也可以指定TTL：\n@Test public void testTTLMsg() { // 创建消息 Message message = MessageBuilder .withBody(\u0026#34;hello, ttl message\u0026#34;.getBytes(StandardCharsets.UTF_8)) .setExpiration(\u0026#34;5000\u0026#34;) .build(); // 消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 发送消息 rabbitTemplate.convertAndSend(\u0026#34;ttl.direct\u0026#34;, \u0026#34;ttl\u0026#34;, message, correlationData); log.debug(\u0026#34;发送消息成功\u0026#34;); } 查看发送消息日志：\n接收消息日志：\n这次，发送与接收的延迟只有5秒。说明当队列、消息都设置了TTL时，任意一个到期就会成为死信。\n2.2.4.总结 消息超时的两种方式是？\n给队列设置ttl属性，进入队列后超过ttl时间的消息变为死信 给消息设置ttl属性，队列接收到消息超过ttl时间后变为死信 如何实现发送一个消息20秒后消费者才收到消息？\n给消息的目标队列指定死信交换机 将消费者监听的队列绑定到死信交换机 发送消息时给消息设置超时时间为20秒 2.3.延迟队列 利用TTL结合死信交换机，我们实现了消息发出后，消费者延迟收到消息的效果。这种消息模式就称为延迟队列（Delay Queue）模式。\n延迟队列的使用场景包括：\n延迟发送短信 用户下单，如果用户在15 分钟内未支付，则自动取消 预约工作会议，20分钟后自动通知所有参会人员 因为延迟队列的需求非常多，所以RabbitMQ的官方也推出了一个插件，原生支持延迟队列效果。\n这个插件就是DelayExchange插件。参考RabbitMQ的插件列表页面：https://www.rabbitmq.com/community-plugins.html\n使用方式可以参考官网地址：https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq\n2.3.1.安装DelayExchange插件 参考课前资料：\n2.3.2.DelayExchange原理 DelayExchange需要将一个交换机声明为delayed类型。当我们发送消息到delayExchange时，流程如下：\n接收消息 判断消息是否具备x-delay属性 如果有x-delay属性，说明是延迟消息，持久化到硬盘，读取x-delay值，作为延迟时间 返回routing not found结果给消息发送者 x-delay时间到期后，重新投递消息到指定队列 2.3.3.使用DelayExchange 插件的使用也非常简单：声明一个交换机，交换机的类型可以是任意类型，只需要设定delayed属性为true即可，然后声明队列与其绑定即可。\n1）声明DelayExchange交换机 基于注解方式（推荐）：\n也可以基于@Bean的方式：\n2）发送消息 发送消息时，一定要携带x-delay属性，指定延迟的时间：\n2.3.4.总结 延迟队列插件的使用步骤包括哪些？\n•声明一个交换机，添加delayed属性为true\n•发送消息时，添加x-delay头，值为超时时间\n3.惰性队列 3.1.消息堆积问题 当生产者发送消息的速度超过了消费者处理消息的速度，就会导致队列中的消息堆积，直到队列存储消息达到上限。之后发送的消息就会成为死信，可能会被丢弃，这就是消息堆积问题。\n解决消息堆积有两种思路：\n增加更多消费者，提高消费速度。也就是我们之前说的work queue模式 扩大队列容积，提高堆积上限 要提升队列容积，把消息保存在内存中显然是不行的。\n3.2.惰性队列 从RabbitMQ的3.6.0版本开始，就增加了Lazy Queues的概念，也就是惰性队列。惰性队列的特征如下：\n接收到消息后直接存入磁盘而非内存 消费者要消费消息时才会从磁盘中读取并加载到内存 支持数百万条的消息存储 3.2.1.基于命令行设置lazy-queue 而要设置一个队列为惰性队列，只需要在声明队列时，指定x-queue-mode属性为lazy即可。可以通过命令行将一个运行中的队列修改为惰性队列：\nrabbitmqctl set_policy Lazy \u0026#34;^lazy-queue$\u0026#34; \u0026#39;{\u0026#34;queue-mode\u0026#34;:\u0026#34;lazy\u0026#34;}\u0026#39; --apply-to queues 命令解读：\nrabbitmqctl ：RabbitMQ的命令行工具 set_policy ：添加一个策略 Lazy ：策略名称，可以自定义 \u0026quot;^lazy-queue$\u0026quot; ：用正则表达式匹配队列的名字 '{\u0026quot;queue-mode\u0026quot;:\u0026quot;lazy\u0026quot;}' ：设置队列模式为lazy模式 --apply-to queues ：策略的作用对象，是所有的队列 3.2.2.基于@Bean声明lazy-queue 3.2.3.基于@RabbitListener声明LazyQueue 3.3.总结 消息堆积问题的解决方案？\n队列上绑定多个消费者，提高消费速度 使用惰性队列，可以再mq中保存更多消息 惰性队列的优点有哪些？\n基于磁盘存储，消息上限高 没有间歇性的page-out，性能比较稳定 惰性队列的缺点有哪些？\n基于磁盘存储，消息时效性会降低 性能受限于磁盘的IO 4.MQ集群 4.1.集群分类 RabbitMQ的是基于Erlang语言编写，而Erlang又是一个面向并发的语言，天然支持集群模式。RabbitMQ的集群有两种模式：\n•普通集群：是一种分布式集群，将队列分散到集群的各个节点，从而提高整个集群的并发能力。\n•镜像集群：是一种主从集群，普通集群的基础上，添加了主从备份功能，提高集群的数据可用性。\n镜像集群虽然支持主从，但主从同步并不是强一致的，某些情况下可能有数据丢失的风险。因此在RabbitMQ的3.8版本以后，推出了新的功能：仲裁队列来代替镜像集群，底层采用Raft协议确保主从的数据一致性。\n4.2.普通集群 4.2.1.集群结构和特征 普通集群，或者叫标准集群（classic cluster），具备下列特征：\n会在集群的各个节点间共享部分数据，包括：交换机、队列元信息。不包含队列中的消息。 当访问集群某节点时，如果队列不在该节点，会从数据所在节点传递到当前节点并返回 队列所在节点宕机，队列中的消息就会丢失 结构如图：\n4.2.2.部署 参考课前资料：《RabbitMQ部署指南.md》\n4.3.镜像集群 4.3.1.集群结构和特征 镜像集群：本质是主从模式，具备下面的特征：\n交换机、队列、队列中的消息会在各个mq的镜像节点之间同步备份。 创建队列的节点被称为该队列的主节点，备份到的其它节点叫做该队列的镜像节点。 一个队列的主节点可能是另一个队列的镜像节点 所有操作都是主节点完成，然后同步给镜像节点 主宕机后，镜像节点会替代成新的主 结构如图：\n4.3.2.部署 参考课前资料：《RabbitMQ部署指南.md》\n4.4.仲裁队列 4.4.1.集群特征 仲裁队列：仲裁队列是3.8版本以后才有的新功能，用来替代镜像队列，具备下列特征：\n与镜像队列一样，都是主从模式，支持主从数据同步 使用非常简单，没有复杂的配置 主从同步基于Raft协议，强一致 4.4.2.部署 参考课前资料：《RabbitMQ部署指南.md》\n4.4.3.Java代码创建仲裁队列 @Bean public Queue quorumQueue() { return QueueBuilder .durable(\u0026#34;quorum.queue\u0026#34;) // 持久化 .quorum() // 仲裁队列 .build(); } 4.4.4.SpringAMQP连接MQ集群 注意，这里用address来代替host、port方式\nspring: rabbitmq: addresses: 192.168.150.105:8071, 192.168.150.105:8072, 192.168.150.105:8073 username: itcast password: 123321 virtual-host: / ","permalink":"https://XianCH.github.io/posts/tech/distributed/rabbitmq-2/","summary":"服务异步通信-高级篇 消息队列在使用过程中，面临着很多实际问题需要思考： 1.消息可靠性 消息从发送，到消费者接收，会经理多个过程： 其中的每一步都可能导致消息丢失，常见的丢失原因包括： 发送时丢失： 生产者发送的消息未送达exchange 消息到达exchange后未到达queue MQ宕机，","title":"RabbitMq-2"},{"content":"RabbitMQ 1.初识MQ 1.1.同步和异步通讯 微服务间通讯有同步和异步两种方式：\n同步通讯：就像打电话，需要实时响应。\n异步通讯：就像发邮件，不需要马上回复。\n两种方式各有优劣，打电话可以立即得到响应，但是你却不能跟多个人同时通话。发送邮件可以同时与多个人收发邮件，但是往往响应会有延迟。\n1.1.1.同步通讯 我们之前学习的Feign调用就属于同步方式，虽然调用可以实时得到结果，但存在下面的问题：\n总结：\n同步调用的优点：\n时效性较强，可以立即得到结果 同步调用的问题：\n耦合度高 性能和吞吐能力下降 有额外的资源消耗 有级联失败问题 1.1.2.异步通讯 异步调用则可以避免上述问题：\n我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。\n在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单id。\n订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。\n为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。\nBroker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。\n好处：\n吞吐量提升：无需等待订阅者处理完成，响应更快速\n故障隔离：服务没有直接调用，不存在级联失败问题\n调用间没有阻塞，不会造成无效的资源占用\n耦合度极低，每个服务都可以灵活插拔，可替换\n流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件\n缺点：\n架构复杂了，业务没有明显的流程线，不好管理 需要依赖于Broker的可靠、安全、性能 好在现在开源软件或云平台上 Broker 的软件是非常成熟的，比较常见的一种就是我们今天要学习的MQ技术。\n1.2.技术对比： MQ，中文是消息队列（MessageQueue），字面来看就是存放消息的队列。也就是事件驱动架构中的Broker。\n比较常见的MQ实现：\nActiveMQ RabbitMQ RocketMQ Kafka 几种常见MQ的对比：\nRabbitMQ ActiveMQ RocketMQ Kafka 公司/社区 Rabbit Apache 阿里 Apache 开发语言 Erlang Java Java Scala\u0026amp;Java 协议支持 AMQP，XMPP，SMTP，STOMP OpenWire,STOMP，REST,XMPP,AMQP 自定义协议 自定义协议 可用性 高 一般 高 高 单机吞吐量 一般 差 高 非常高 消息延迟 微秒级 毫秒级 毫秒级 毫秒以内 消息可靠性 高 一般 高 一般 追求可用性：Kafka、 RocketMQ 、RabbitMQ\n追求可靠性：RabbitMQ、RocketMQ\n追求吞吐能力：RocketMQ、Kafka\n追求消息低延迟：RabbitMQ、Kafka\n2.快速入门 2.1.安装RabbitMQ 安装RabbitMQ，参考课前资料：\nMQ的基本结构：\nRabbitMQ中的一些角色：\npublisher：生产者 consumer：消费者 exchange个：交换机，负责消息路由 queue：队列，存储消息 virtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离 2.2.RabbitMQ消息模型 RabbitMQ官方提供了5个不同的Demo示例，对应了不同的消息模型：\n2.3.导入Demo工程 课前资料提供了一个Demo工程，mq-demo:\n导入后可以看到结构如下：\n包括三部分：\nmq-demo：父工程，管理项目依赖 publisher：消息的发送者 consumer：消息的消费者 2.4.入门案例 简单队列模式的模型图：\n官方的HelloWorld是基于最基础的消息队列模型来实现的，只包括三个角色：\npublisher：消息发布者，将消息发送到队列queue queue：消息队列，负责接受并缓存消息 consumer：订阅队列，处理队列中的消息 2.4.1.publisher实现 思路：\n建立连接 创建Channel 声明队列 发送消息 关闭连接和channel 代码实现：\npackage cn.itcast.mq.helloworld; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; import org.junit.Test; import java.io.IOException; import java.util.concurrent.TimeoutException; public class PublisherTest { @Test public void testSendMessage() throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(\u0026#34;192.168.150.101\u0026#34;); factory.setPort(5672); factory.setVirtualHost(\u0026#34;/\u0026#34;); factory.setUsername(\u0026#34;itcast\u0026#34;); factory.setPassword(\u0026#34;123321\u0026#34;); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = \u0026#34;simple.queue\u0026#34;; channel.queueDeclare(queueName, false, false, false, null); // 4.发送消息 String message = \u0026#34;hello, rabbitmq!\u0026#34;; channel.basicPublish(\u0026#34;\u0026#34;, queueName, null, message.getBytes()); System.out.println(\u0026#34;发送消息成功：【\u0026#34; + message + \u0026#34;】\u0026#34;); // 5.关闭通道和连接 channel.close(); connection.close(); } } 2.4.2.consumer实现 代码思路：\n建立连接 创建Channel 声明队列 订阅消息 代码实现：\npackage cn.itcast.mq.helloworld; import com.rabbitmq.client.*; import java.io.IOException; import java.util.concurrent.TimeoutException; public class ConsumerTest { public static void main(String[] args) throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(\u0026#34;192.168.150.101\u0026#34;); factory.setPort(5672); factory.setVirtualHost(\u0026#34;/\u0026#34;); factory.setUsername(\u0026#34;itcast\u0026#34;); factory.setPassword(\u0026#34;123321\u0026#34;); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = \u0026#34;simple.queue\u0026#34;; channel.queueDeclare(queueName, false, false, false, null); // 4.订阅消息 channel.basicConsume(queueName, true, new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { // 5.处理消息 String message = new String(body); System.out.println(\u0026#34;接收到消息：【\u0026#34; + message + \u0026#34;】\u0026#34;); } }); System.out.println(\u0026#34;等待接收消息。。。。\u0026#34;); } } 2.5.总结 基本消息队列的消息发送流程：\n建立connection\n创建channel\n利用channel声明队列\n利用channel向队列发送消息\n基本消息队列的消息接收流程：\n建立connection\n创建channel\n利用channel声明队列\n定义consumer的消费行为handleDelivery()\n利用channel将消费者与队列绑定\n3.SpringAMQP SpringAMQP是基于RabbitMQ封装的一套模板，并且还利用SpringBoot对其实现了自动装配，使用起来非常方便。\nSpringAmqp的官方地址：https://spring.io/projects/spring-amqp\nSpringAMQP提供了三个功能：\n自动声明队列、交换机及其绑定关系 基于注解的监听器模式，异步接收消息 封装了RabbitTemplate工具，用于发送消息 3.1.Basic Queue 简单队列模型 在父工程mq-demo中引入依赖\n\u0026lt;!--AMQP依赖，包含RabbitMQ--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 3.1.1.消息发送 首先配置MQ地址，在publisher服务的application.yml中添加配置：\nspring: rabbitmq: host: 192.168.150.101 # 主机名 port: 5672 # 端口 virtual-host: / # 虚拟主机 username: itcast # 用户名 password: 123321 # 密码 然后在publisher服务中编写测试类SpringAmqpTest，并利用RabbitTemplate实现消息发送：\npackage cn.itcast.mq.spring; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; @RunWith(SpringRunner.class) @SpringBootTest public class SpringAmqpTest { @Autowired private RabbitTemplate rabbitTemplate; @Test public void testSimpleQueue() { // 队列名称 String queueName = \u0026#34;simple.queue\u0026#34;; // 消息 String message = \u0026#34;hello, spring amqp!\u0026#34;; // 发送消息 rabbitTemplate.convertAndSend(queueName, message); } } 3.1.2.消息接收 首先配置MQ地址，在consumer服务的application.yml中添加配置：\nspring: rabbitmq: host: 192.168.150.101 # 主机名 port: 5672 # 端口 virtual-host: / # 虚拟主机 username: itcast # 用户名 password: 123321 # 密码 然后在consumer服务的cn.itcast.mq.listener包中新建一个类SpringRabbitListener，代码如下：\npackage cn.itcast.mq.listener; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; @Component public class SpringRabbitListener { @RabbitListener(queues = \u0026#34;simple.queue\u0026#34;) public void listenSimpleQueueMessage(String msg) throws InterruptedException { System.out.println(\u0026#34;spring 消费者接收到消息：【\u0026#34; + msg + \u0026#34;】\u0026#34;); } } 3.1.3.测试 启动consumer服务，然后在publisher服务中运行测试代码，发送MQ消息\n3.2.WorkQueue Work queues，也被称为（Task queues），任务模型。简单来说就是让多个消费者绑定到一个队列，共同消费队列中的消息。\n当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理。\n此时就可以使用work 模型，多个消费者共同处理消息处理，速度就能大大提高了。\n3.2.1.消息发送 这次我们循环发送，模拟大量消息堆积现象。\n在publisher服务中的SpringAmqpTest类中添加一个测试方法：\n/** * workQueue * 向队列中不停发送消息，模拟消息堆积。 */ @Test public void testWorkQueue() throws InterruptedException { // 队列名称 String queueName = \u0026#34;simple.queue\u0026#34;; // 消息 String message = \u0026#34;hello, message_\u0026#34;; for (int i = 0; i \u0026lt; 50; i++) { // 发送消息 rabbitTemplate.convertAndSend(queueName, message + i); Thread.sleep(20); } } 3.2.2.消息接收 要模拟多个消费者绑定同一个队列，我们在consumer服务的SpringRabbitListener中添加2个新的方法：\n@RabbitListener(queues = \u0026#34;simple.queue\u0026#34;) public void listenWorkQueue1(String msg) throws InterruptedException { System.out.println(\u0026#34;消费者1接收到消息：【\u0026#34; + msg + \u0026#34;】\u0026#34; + LocalTime.now()); Thread.sleep(20); } @RabbitListener(queues = \u0026#34;simple.queue\u0026#34;) public void listenWorkQueue2(String msg) throws InterruptedException { System.err.println(\u0026#34;消费者2........接收到消息：【\u0026#34; + msg + \u0026#34;】\u0026#34; + LocalTime.now()); Thread.sleep(200); } 注意到这个消费者sleep了1000秒，模拟任务耗时。\n3.2.3.测试 启动ConsumerApplication后，在执行publisher服务中刚刚编写的发送测试方法testWorkQueue。\n可以看到消费者1很快完成了自己的25条消息。消费者2却在缓慢的处理自己的25条消息。\n也就是说消息是平均分配给每个消费者，并没有考虑到消费者的处理能力。这样显然是有问题的。\n3.2.4.能者多劳 在spring中有一个简单的配置，可以解决这个问题。我们修改consumer服务的application.yml文件，添加配置：\nspring: rabbitmq: listener: simple: prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息 3.2.5.总结 Work模型的使用：\n多个消费者绑定到一个队列，同一条消息只会被一个消费者处理 通过设置prefetch来控制消费者预取的消息数量 3.3.发布/订阅 发布订阅的模型如图：\n可以看到，在订阅模型中，多了一个exchange角色，而且过程略有变化：\nPublisher：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） Exchange：交换机，图中的X。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有以下3种类型： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 Consumer：消费者，与以前一样，订阅队列，没有变化 Queue：消息队列也与以前一样，接收消息、缓存消息。 Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！\n3.4.Fanout Fanout，英文翻译是扇出，我觉得在MQ中叫广播更合适。\n在广播模式下，消息发送流程是这样的：\n1） 可以有多个队列 2） 每个队列都要绑定到Exchange（交换机） 3） 生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定 4） 交换机把消息发送给绑定过的所有队列 5） 订阅队列的消费者都能拿到消息 我们的计划是这样的：\n创建一个交换机 itcast.fanout，类型是Fanout 创建两个队列fanout.queue1和fanout.queue2，绑定到交换机itcast.fanout 3.4.1.声明队列和交换机 Spring提供了一个接口Exchange，来表示所有不同类型的交换机：\n在consumer中创建一个类，声明队列和交换机：\npackage cn.itcast.mq.config; import org.springframework.amqp.core.Binding; import org.springframework.amqp.core.BindingBuilder; import org.springframework.amqp.core.FanoutExchange; import org.springframework.amqp.core.Queue; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class FanoutConfig { /** * 声明交换机 * @return Fanout类型交换机 */ @Bean public FanoutExchange fanoutExchange(){ return new FanoutExchange(\u0026#34;itcast.fanout\u0026#34;); } /** * 第1个队列 */ @Bean public Queue fanoutQueue1(){ return new Queue(\u0026#34;fanout.queue1\u0026#34;); } /** * 绑定队列和交换机 */ @Bean public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange){ return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange); } /** * 第2个队列 */ @Bean public Queue fanoutQueue2(){ return new Queue(\u0026#34;fanout.queue2\u0026#34;); } /** * 绑定队列和交换机 */ @Bean public Binding bindingQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange){ return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange); } } 3.4.2.消息发送 在publisher服务的SpringAmqpTest类中添加测试方法：\n@Test public void testFanoutExchange() { // 队列名称 String exchangeName = \u0026#34;itcast.fanout\u0026#34;; // 消息 String message = \u0026#34;hello, everyone!\u0026#34;; rabbitTemplate.convertAndSend(exchangeName, \u0026#34;\u0026#34;, message); } 3.4.3.消息接收 在consumer服务的SpringRabbitListener中添加两个方法，作为消费者：\n@RabbitListener(queues = \u0026#34;fanout.queue1\u0026#34;) public void listenFanoutQueue1(String msg) { System.out.println(\u0026#34;消费者1接收到Fanout消息：【\u0026#34; + msg + \u0026#34;】\u0026#34;); } @RabbitListener(queues = \u0026#34;fanout.queue2\u0026#34;) public void listenFanoutQueue2(String msg) { System.out.println(\u0026#34;消费者2接收到Fanout消息：【\u0026#34; + msg + \u0026#34;】\u0026#34;); } 3.4.4.总结 交换机的作用是什么？\n接收publisher发送的消息 将消息按照规则路由到与之绑定的队列 不能缓存消息，路由失败，消息丢失 FanoutExchange的会将消息路由到每个绑定的队列 声明队列、交换机、绑定关系的Bean是什么？\nQueue FanoutExchange Binding 3.5.Direct 在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。\n在Direct模型下：\n队列与交换机的绑定，不能是任意绑定了，而是要指定一个RoutingKey（路由key） 消息的发送方在 向 Exchange发送消息时，也必须指定消息的 RoutingKey。 Exchange不再把消息交给每一个绑定的队列，而是根据消息的Routing Key进行判断，只有队列的Routingkey与消息的 Routing key完全一致，才会接收到消息 案例需求如下：\n利用@RabbitListener声明Exchange、Queue、RoutingKey\n在consumer服务中，编写两个消费者方法，分别监听direct.queue1和direct.queue2\n在publisher中编写测试方法，向itcast. direct发送消息\n3.5.1.基于注解声明队列和交换机 基于@Bean的方式声明队列和交换机比较麻烦，Spring还提供了基于注解方式来声明。\n在consumer的SpringRabbitListener中添加两个消费者，同时基于注解来声明队列和交换机：\n@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;direct.queue1\u0026#34;), exchange = @Exchange(name = \u0026#34;itcast.direct\u0026#34;, type = ExchangeTypes.DIRECT), key = {\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;} )) public void listenDirectQueue1(String msg){ System.out.println(\u0026#34;消费者接收到direct.queue1的消息：【\u0026#34; + msg + \u0026#34;】\u0026#34;); } @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;direct.queue2\u0026#34;), exchange = @Exchange(name = \u0026#34;itcast.direct\u0026#34;, type = ExchangeTypes.DIRECT), key = {\u0026#34;red\u0026#34;, \u0026#34;yellow\u0026#34;} )) public void listenDirectQueue2(String msg){ System.out.println(\u0026#34;消费者接收到direct.queue2的消息：【\u0026#34; + msg + \u0026#34;】\u0026#34;); } 3.5.2.消息发送 在publisher服务的SpringAmqpTest类中添加测试方法：\n@Test public void testSendDirectExchange() { // 交换机名称 String exchangeName = \u0026#34;itcast.direct\u0026#34;; // 消息 String message = \u0026#34;红色警报！日本乱排核废水，导致海洋生物变异，惊现哥斯拉！\u0026#34;; // 发送消息 rabbitTemplate.convertAndSend(exchangeName, \u0026#34;red\u0026#34;, message); } 3.5.3.总结 描述下Direct交换机与Fanout交换机的差异？\nFanout交换机将消息路由给每一个与之绑定的队列 Direct交换机根据RoutingKey判断路由给哪个队列 如果多个队列具有相同的RoutingKey，则与Fanout功能类似 基于@RabbitListener注解声明队列和交换机有哪些常见注解？\n@Queue @Exchange 3.6.Topic 3.6.1.说明 Topic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！\nRoutingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert\n通配符规则：\n#：匹配一个或多个词\n*：匹配不多不少恰好1个词\n举例：\nitem.#：能够匹配item.spu.insert 或者 item.spu\nitem.*：只能匹配item.spu\n​\n图示：\n解释：\nQueue1：绑定的是china.# ，因此凡是以 china.开头的routing key 都会被匹配到。包括china.news和china.weather Queue2：绑定的是#.news ，因此凡是以 .news结尾的 routing key 都会被匹配。包括china.news和japan.news 案例需求：\n实现思路如下：\n并利用@RabbitListener声明Exchange、Queue、RoutingKey\n在consumer服务中，编写两个消费者方法，分别监听topic.queue1和topic.queue2\n在publisher中编写测试方法，向itcast. topic发送消息\n3.6.2.消息发送 在publisher服务的SpringAmqpTest类中添加测试方法：\n/** * topicExchange */ @Test public void testSendTopicExchange() { // 交换机名称 String exchangeName = \u0026#34;itcast.topic\u0026#34;; // 消息 String message = \u0026#34;喜报！孙悟空大战哥斯拉，胜!\u0026#34;; // 发送消息 rabbitTemplate.convertAndSend(exchangeName, \u0026#34;china.news\u0026#34;, message); } 3.6.3.消息接收 在consumer服务的SpringRabbitListener中添加方法：\n@RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;topic.queue1\u0026#34;), exchange = @Exchange(name = \u0026#34;itcast.topic\u0026#34;, type = ExchangeTypes.TOPIC), key = \u0026#34;china.#\u0026#34; )) public void listenTopicQueue1(String msg){ System.out.println(\u0026#34;消费者接收到topic.queue1的消息：【\u0026#34; + msg + \u0026#34;】\u0026#34;); } @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \u0026#34;topic.queue2\u0026#34;), exchange = @Exchange(name = \u0026#34;itcast.topic\u0026#34;, type = ExchangeTypes.TOPIC), key = \u0026#34;#.news\u0026#34; )) public void listenTopicQueue2(String msg){ System.out.println(\u0026#34;消费者接收到topic.queue2的消息：【\u0026#34; + msg + \u0026#34;】\u0026#34;); } 3.6.4.总结 描述下Direct交换机与Topic交换机的差异？\nTopic交换机接收的消息RoutingKey必须是多个单词，以 **.** 分割 Topic交换机与队列绑定时的bindingKey可以指定通配符 #：代表0个或多个词 *：代表1个词 3.7.消息转换器 之前说过，Spring会把你发送的消息序列化为字节发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。\n只不过，默认情况下Spring采用的序列化方式是JDK序列化。众所周知，JDK序列化存在下列问题：\n数据体积过大 有安全漏洞 可读性差 我们来测试一下。\n3.7.1.测试默认转换器 我们修改消息发送的代码，发送一个Map对象：\n@Test public void testSendMap() throws InterruptedException { // 准备消息 Map\u0026lt;String,Object\u0026gt; msg = new HashMap\u0026lt;\u0026gt;(); msg.put(\u0026#34;name\u0026#34;, \u0026#34;Jack\u0026#34;); msg.put(\u0026#34;age\u0026#34;, 21); // 发送消息 rabbitTemplate.convertAndSend(\u0026#34;simple.queue\u0026#34;,\u0026#34;\u0026#34;, msg); } 停止consumer服务\n发送消息后查看控制台：\n3.7.2.配置JSON转换器 显然，JDK序列化方式并不合适。我们希望消息体的体积更小、可读性更高，因此可以使用JSON方式来做序列化和反序列化。\n在publisher和consumer两个服务中都引入依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.dataformat\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-dataformat-xml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.10\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置消息转换器。\n在启动类中添加一个Bean即可：\n@Bean public MessageConverter jsonMessageConverter(){ return new Jackson2JsonMessageConverter(); } ","permalink":"https://XianCH.github.io/posts/tech/distributed/rabbitmq%E5%AD%A6%E4%B9%A0/","summary":"RabbitMQ 1.初识MQ 1.1.同步和异步通讯 微服务间通讯有同步和异步两种方式： 同步通讯：就像打电话，需要实时响应。 异步通讯：就像发邮件，不需要马上回复。 两种方式各有优劣，打电话可以立即得到响应，但是你却不能跟多个人同时通话。发送邮件可以同时与多个人收发邮件，但是往往响应会有延迟。 1.1.","title":"RabbitMq"},{"content":"spring boot2学习笔记 一，\tspring boot2核心技术基础入门 1.spring能做什么 1.1 spring的能力 ![image-20220321190444355](spring boot2学习笔记.assets\\image-20220321190444355.png)\n二\t、为什么用SpringBoot Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can \u0026ldquo;just run\u0026rdquo;.\n能快速创建出生产级别的Spring应用\n2.1、SpringBoot优点 Create stand-alone Spring applications\n创建独立Spring应用 Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files)\n内嵌web服务器 Provide opinionated \u0026lsquo;starter\u0026rsquo; dependencies to simplify your build configuration\n自动starter依赖，简化构建配置 Automatically configure Spring and 3rd party libraries whenever possible\n自动配置Spring以及第三方功能 Provide production-ready features such as metrics, health checks, and externalized configuration\n提供生产级别的监控、健康检查及外部化配置 Absolutely no code generation and no requirement for XML configuration\n无代码生成、无需编写XML 三 ， spring boot开发文档 四，spring boot入门 1，hello world 导入依赖 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; ![image-20220324143750246](D:\\6 \u0026ndash; TypoDoc\\springboot2\\spring boot2学习笔记.assets\\image-20220324143750246.png) 这个依赖导入了开发中大部分的jar包\n1.1 编写主程序 ![image-20220324143859988](D:\\6 \u0026ndash; TypoDoc\\springboot2\\spring boot2学习笔记.assets\\image-20220324143859988.png)\n@RestController public class HelloController { @RequestMapping(\u0026#34;/hello\u0026#34;) public String handle01(){ return \u0026#34;hello,Spring boot 2!\u0026#34;; } } @SpringBootApplication public class MainApplication { public static void main(String[] args) { SpringApplication.run(MainApplication.class,args); } } 文件的部署\n用spring boot的插件把整个项目打包成jar包\n\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; ![image-20220324144608094](spring boot2学习笔记.assets/image-20220324144608094-16797314654721.png)\n五，\t了解自动配置原理 1.0 依赖管理 \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.4\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; 他的父项目\n\u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.4\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; 几乎声明了所有开发中常用的依赖版本，和依赖所对应的版本号\n如：\n![image-20220324144411720](.\\spring boot2学习笔记.assets\\image-20220324144411720.png)\n因此在prom.xml中导入依赖的时候不需要写对应的的版本号\n![image-20220324145112721](D:\\6 \u0026ndash; TypoDoc\\springboot2\\spring boot2学习笔记.assets\\image-20220324145112721.png)\n如何想自行更换版本：如更换mysql驱动 ​\t上mvn仓库Maven Repository: Search/Browse/Explore (mvnrepository.com)\n![image-20220324145711405](.\\spring boot2学习笔记.assets\\image-20220324145711405.png)\n​\t在porm。xml中输入\n\u0026lt;properties\u0026gt; \u0026lt;mysql.version\u0026gt;5.1.43\u0026lt;/mysql.version\u0026gt; \u0026lt;/properties\u0026gt; 依赖树\n![image-20220324150731469](.\\spring boot2学习笔记.assets\\image-20220324150731469.png)\n2.容器功能 2.1\t组件添加 @Configuration\n基本使用\n#############################Configuration使用示例###################################################### /** * 1、配置类里面使用@Bean标注在方法上给容器注册组件，默认也是单实例的 * 2、配置类本身也是组件 * 3、proxyBeanMethods：代理bean的方法 * Full(proxyBeanMethods = true)、【保证每个@Bean方法被调用多少次返回的组件都是单实例的】 * Lite(proxyBeanMethods = false)【每个@Bean方法被调用多少次返回的组件都是新创建的】 * 组件依赖必须使用Full模式默认。其他默认是否Lite模式 * * * */ @Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件 public class MyConfig { /** * Full:外部无论对配置类中的这个组件注册方法调用多少次获取的都是之前注册容器中的单实例对象 * @return */ @Bean //给容器中添加组件。以方法名作为组件的id。返回类型就是组件类型。返回的值，就是组件在容器中的实例 public User user01(){ User zhangsan = new User(\u0026#34;zhangsan\u0026#34;, 18); //user组件依赖了Pet组件 zhangsan.setPet(tomcatPet()); return zhangsan; } @Bean(\u0026#34;tom\u0026#34;) public Pet tomcatPet(){ return new Pet(\u0026#34;tomcat\u0026#34;); } } ################################@Configuration测试代码如下######################################## @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(\u0026#34;com.atguigu.boot\u0026#34;) public class MainApplication { public static void main(String[] args) { //1、返回我们IOC容器 ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args); //2、查看容器里面的组件 String[] names = run.getBeanDefinitionNames(); for (String name : names) { System.out.println(name); } //3、从容器中获取组件 Pet tom01 = run.getBean(\u0026#34;tom\u0026#34;, Pet.class); Pet tom02 = run.getBean(\u0026#34;tom\u0026#34;, Pet.class); System.out.println(\u0026#34;组件：\u0026#34;+(tom01 == tom02)); //4、com.atguigu.boot.config.MyConfig$$EnhancerBySpringCGLIB$$51f1e1ca@1654a892 MyConfig bean = run.getBean(MyConfig.class); System.out.println(bean); //如果@Configuration(proxyBeanMethods = true)代理对象调用方法。SpringBoot总会检查这个组件是否在容器中有。 //保持组件单实例 User user = bean.user01(); User user1 = bean.user01(); System.out.println(user == user1); User user01 = run.getBean(\u0026#34;user01\u0026#34;, User.class); Pet tom = run.getBean(\u0026#34;tom\u0026#34;, Pet.class); System.out.println(\u0026#34;用户的宠物：\u0026#34;+(user01.getPet() == tom)); } } @Bean、@Component、@Controller、@Service、@Repository\n@ComponentScan、@Import\n* 4、@Import({User.class, DBHelper.class}) * 给容器中自动创建出这两个类型的组件、默认组件的名字就是全类名 * * * */ @Import({User.class, DBHelper.class}) @Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件 public class MyConfig { } @Conditional\n条件装配：满足Conditional指定的条件，则进行组件注入\n![image-20220324212837038](.\\spring boot2学习笔记.assets\\image-20220324212837038.png)\n=====================测试条件装配========================== @Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件 //@ConditionalOnBean(name = \u0026#34;tom\u0026#34;) @ConditionalOnMissingBean(name = \u0026#34;tom\u0026#34;) public class MyConfig { /** * Full:外部无论对配置类中的这个组件注册方法调用多少次获取的都是之前注册容器中的单实例对象 * @return */ @Bean //给容器中添加组件。以方法名作为组件的id。返回类型就是组件类型。返回的值，就是组件在容器中的实例 public User user01(){ User zhangsan = new User(\u0026#34;zhangsan\u0026#34;, 18); //user组件依赖了Pet组件 zhangsan.setPet(tomcatPet()); return zhangsan; } @Bean(\u0026#34;tom22\u0026#34;) public Pet tomcatPet(){ return new Pet(\u0026#34;tomcat\u0026#34;); } } public static void main(String[] args) { //1、返回我们IOC容器 ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args); //2、查看容器里面的组件 String[] names = run.getBeanDefinitionNames(); for (String name : names) { System.out.println(name); } boolean tom = run.containsBean(\u0026#34;tom\u0026#34;); System.out.println(\u0026#34;容器中Tom组件：\u0026#34;+tom); boolean user01 = run.containsBean(\u0026#34;user01\u0026#34;); System.out.println(\u0026#34;容器中user01组件：\u0026#34;+user01); boolean tom22 = run.containsBean(\u0026#34;tom22\u0026#34;); System.out.println(\u0026#34;容器中tom22组件：\u0026#34;+tom22); } 2.2\t原生配置文件引入 @ImportResource ======================beans.xml========================= \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;haha\u0026#34; class=\u0026#34;com.atguigu.boot.bean.User\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;name\u0026#34; value=\u0026#34;zhangsan\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;age\u0026#34; value=\u0026#34;18\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;hehe\u0026#34; class=\u0026#34;com.atguigu.boot.bean.Pet\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;name\u0026#34; value=\u0026#34;tomcat\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; @ImportResource(\u0026#34;classpath:beans.xml\u0026#34;) public class MyConfig {} ======================测试================= boolean haha = run.containsBean(\u0026#34;haha\u0026#34;); boolean hehe = run.containsBean(\u0026#34;hehe\u0026#34;); System.out.println(\u0026#34;haha：\u0026#34;+haha);//true System.out.println(\u0026#34;hehe：\u0026#34;+hehe);//true 2.3\t配置绑定 如何使用Java读取到properties文件中的内容，并且把它封装到JavaBean中，以供随时使用；\npublic class getProperties { public static void main(String[] args) throws FileNotFoundException, IOException { Properties pps = new Properties(); pps.load(new FileInputStream(\u0026#34;a.properties\u0026#34;)); Enumeration enum1 = pps.propertyNames();//得到配置文件的名字 while(enum1.hasMoreElements()) { String strKey = (String) enum1.nextElement(); String strValue = pps.getProperty(strKey); System.out.println(strKey + \u0026#34;=\u0026#34; + strValue); //封装到JavaBean。 } } } 2.3.1\t@ConfigurationProperties /** * 只有在容器中的组件，才会拥有SpringBoot提供的强大功能 */ @Component @ConfigurationProperties(prefix = \u0026#34;mycar\u0026#34;) public class Car { private String brand; private Integer price; public String getBrand() { return brand; } public void setBrand(String brand) { this.brand = brand; } public Integer getPrice() { return price; } public void setPrice(Integer price) { this.price = price; } @Override public String toString() { return \u0026#34;Car{\u0026#34; + \u0026#34;brand=\u0026#39;\u0026#34; + brand + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, price=\u0026#34; + price + \u0026#39;}\u0026#39;; } } 2.3.3\t@EnableConfigurationProperties + @ConfigurationProperties\n2.3.4\t@Component + @ConfigurationProperties\n​\n@EnableConfigurationProperties(Car.class) //1、开启Car配置绑定功能 //2、把这个Car这个组件自动注册到容器中 public class MyConfig { } 3.\t自动配置原理入门 3.1\t引导加载自动配置类 @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication{} @SpringBootConfiguration\n@Configuration.代表当前是一个配置类\n@ComponentScan\n指定扫描哪些组件，Spring注解。\n@EnableAutoConfiguration\n@AutoConfigurationPackage @Import(AutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration {} @AutoConfigurationPackage\n自动配置包，指定了默认的包规则\n@Import(AutoConfigurationPackages.Registrar.class) //给容器中导入一个组件 public @interface AutoConfigurationPackage {} //利用Registrar给容器中导入一系列组件 //将指定的一个包下的所有组件导入进来？MainApplication 所在包下。 @Import(AutoConfigurationImportSelector.class)\n1、利用getAutoConfigurationEntry(annotationMetadata);给容器中批量导入一些组件 2、调用List\u0026lt;String\u0026gt; configurations = getCandidateConfigurations(annotationMetadata, attributes)获取到所有需要导入到容器中的配置类 3、利用工厂加载 Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; loadSpringFactories(@Nullable ClassLoader classLoader)；得到所有的组件 4、从META-INF/spring.factories位置来加载一个文件。 默认扫描我们当前系统里面所有META-INF/spring.factories位置的文件 spring-boot-autoconfigure-2.3.4.RELEASE.jar包里面也有META-INF/spring.factories ![image-20220324214138887](.\\spring boot2学习笔记.assets\\image-20220324214138887.png)\nspring-boot-autoconfigure-2.3.4.RELEASE.jar/META-INF/spring.factories # Auto Configure org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\ org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\ org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\ org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\ org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\ org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\ org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRestClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.jdbc.JdbcRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoReactiveDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoReactiveRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.r2dbc.R2dbcDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.r2dbc.R2dbcRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.r2dbc.R2dbcTransactionManagerAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.redis.RedisReactiveAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\ org.springframework.boot.autoconfigure.elasticsearch.ElasticsearchRestClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\ org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\ org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\ org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\ org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\ org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\ org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\ org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\ org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration,\\ org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration,\\ org.springframework.boot.autoconfigure.influx.InfluxDbAutoConfiguration,\\ org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\ org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\ org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\ org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\ org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\ org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\ org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration,\\ org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\ org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration,\\ org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\ org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\ org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\ org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\ org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\ org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\ org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\ org.springframework.boot.autoconfigure.mongo.MongoReactiveAutoConfiguration,\\ org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\ org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\ org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration,\\ org.springframework.boot.autoconfigure.r2dbc.R2dbcAutoConfiguration,\\ org.springframework.boot.autoconfigure.rsocket.RSocketMessagingAutoConfiguration,\\ org.springframework.boot.autoconfigure.rsocket.RSocketRequesterAutoConfiguration,\\ org.springframework.boot.autoconfigure.rsocket.RSocketServerAutoConfiguration,\\ org.springframework.boot.autoconfigure.rsocket.RSocketStrategiesAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.reactive.ReactiveSecurityAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.reactive.ReactiveUserDetailsServiceAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.rsocket.RSocketSecurityAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration,\\ org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\ org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.oauth2.client.reactive.ReactiveOAuth2ClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.oauth2.resource.reactive.ReactiveOAuth2ResourceServerAutoConfiguration,\\ org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\ org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration,\\ org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration,\\ org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\ org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\ org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\ org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration,\\ org.springframework.boot.autoconfigure.websocket.reactive.WebSocketReactiveAutoConfiguration,\\ org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration,\\ org.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration,\\ org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration,\\ org.springframework.boot.autoconfigure.webservices.client.WebServiceTemplateAutoConfiguration 这是springboot会自动加载的组件\n3.2\t按需开启自动配置项 虽然我们127个场景的所有自动配置启动的时候默认全部加载。xxxxAutoConfiguration 按照条件装配规则（@Conditional），最终会按需配置。\n3.3，修改默认配置 @Bean @ConditionalOnBean(MultipartResolver.class) //容器中有这个类型组件 @ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME) //容器中没有这个名字 multipartResolver 的组件 public MultipartResolver multipartResolver(MultipartResolver resolver) { //给@Bean标注的方法传入了对象参数，这个参数的值就会从容器中找。 //SpringMVC multipartResolver。防止有些用户配置的文件上传解析器不符合规范 // Detect if the user has created a MultipartResolver but named it incorrectly return resolver; } 给容器中加入了文件上传解析器； SpringBoot默认会在底层配好所有组件。但是如果用户自己配置了的话 以用户配置的优先\n例如：\n@Bean @ConditionalOnMissingBean public CharacterEncodingFilter characterEncodingFilter() { } 3.4\t总结 SpringBoot启动时先加载所有的自动配置类 xxxxAutoConfiguration\n每个自动配置类按照条件进行生效（Conditonalxxxx），默认都会绑定配置文件中的值，xxxxProperties里面拿。xxxxProperties和配置文件进行了绑定\n生效了的配置类会给容器配置相应的组件\n只要容器中有这些组将，就相当于有了这些功能\n定制配置\na\u0026gt;用户自己配置Bean替换底层的组件\nb\u0026gt;用户去看这个组件是获取的配置文件的什么值，自己去配置文件中修改\nxxxxAutoConfiguration \u0026mdash;-\u0026gt;对应的组件\u0026mdash;-\u0026gt;xxxxProperties里面拿值\u0026mdash;\u0026ndash;application.properties\n","permalink":"https://XianCH.github.io/posts/tech/java/springboot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","summary":"spring boot2学习笔记 一， spring boot2核心技术基础入门 1.spring能做什么 1.1 spring的能力 ![image-20220321190444355](spring boot2学习笔记.assets\\image-20220321190444355.png) 二 、为什么用SpringBoot Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can \u0026ldquo;just run\u0026rdquo;. 能快速创建出生产级别的Sp","title":"springboot学习笔记"},{"content":"","permalink":"https://XianCH.github.io/posts/life/life/","summary":"","title":"Life"},{"content":"","permalink":"https://XianCH.github.io/posts/read/read/","summary":"","title":"Read"},{"content":"sql备忘录 绑定外键 CONSTRAINT `tb_product_ibfk_1` FOREIGN KEY (`category_id`) REFERENCES `tb_product_category` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT 语句 绑定主键\nPRIMARY KEY (`id`) USING BTREE 索引 B-TREE索引:\tUSING BTREE\n数据类型 数值类型 ：\ntinyint -128~127之间的整数\nsmallint\nmediumint\nint\nbigint\n浮点类型 float ， double\n字符串类型：\nvarchar ，\nchar，（）中保存一个字节\n日期时间类型\nDATE\nTIME\nDATETIME\n``TIMESTAMP`。\n文本类型 文本类型包括TEXT和BLOB。在MySQL中，TEXT类型包括TINYTEXT、TEXT、MEDIUMTEXT和LONGTEXT，它们的存储方式都是变长存储，可以存储较大的文本数据；而BLOB类型包括TINYBLOB、BLOB、MEDIUMBLOB和LONGBLOB，它们的存储方式也是变长存储，可以存储较大的二进制数据。\n枚举类型和集合类型 枚举类型和集合类型是MySQL中特有的类型。枚举类型存储时会将枚举值转换成整数存储，而集合类型存储时则会将多个枚举值组合成一个集合进行存储\n精确数值:\nDECIMAL(M,D) M代表多少为数，D代表小数点后几位 ​\n修饰符 unsigned 非负数\n时间修饰符：CURRENT_TIMESTAMP(0)当前时间 0 表示小数点后面的位数\nDEFAULT CURRENT_TIMESTAMP(0) ON UPDATE CURRENT_TIMESTAMP(0)\n编码格式 在ASCII编码中，每个字符占用1个字节；\n在UTF-8编码中，一个英文字符占用1个字节，一个汉字字符占用3个字节；\n在UTF-16编码中，一个英文字符占用2个字节，一个汉字字符占用2个或4个字节；在UTF-32编码中，每个字符都占用4个字节。\n字符排序规则 CHARACTER SET = utf8 COLLATE = utf8_general_ci不区分大小写\n优化 ROW_FORMAT 是用于指定表中行的存储格式的一种选项\nROW_FORMAT = Dynamic是一种行格式，MySQL会根据行的大小自动选择行的存储方式，可以是COMPACT或者REDUNDANT。对于比较小的行，MySQL会使用更紧凑的存储方式（COMPACT），而对于较大的行，MySQL会使用更宽松的存储方式（REDUNDANT），以节省存储空间。这种自适应的存储方式可以在一定程度上提高表的存储效率和查询性能\n","permalink":"https://XianCH.github.io/posts/tech/database/sql%E5%A4%87%E5%BF%98%E5%BD%95/","summary":"sql备忘录 绑定外键 CONSTRAINT `tb_product_ibfk_1` FOREIGN KEY (`category_id`) REFERENCES `tb_product_category` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT 语句 绑定主键 PRIMARY KEY (`id`) USING BTREE 索引 B-TREE索引: USING BTREE 数据类型 数值类型 ： tinyint -128~127之间的整数 smallint mediumint int bigint 浮点类型 float ， double 字符串类型： varchar ， char，（）中保存一个字节 日期时间类型 DATE TIME DATETIME ``TIMESTAMP`。 文本类型 文本类型包括TEXT","title":"sql备忘录"},{"content":"一、SpringMVC简介 1、什么是MVC MVC是一种软件架构的思想，将软件按照模型、视图、控制器来划分\nM：Model，模型层，指工程中的JavaBean，作用是处理数据\nJavaBean分为两类：\n一类称为实体类Bean：专门存储业务数据的，如 Student、User 等 一类称为业务处理 Bean：指 Service 或 Dao 对象，专门用于处理业务逻辑和数据访问。 V：View，视图层，指工程中的html或jsp等页面，作用是与用户进行交互，展示数据\nC：Controller，控制层，指工程中的servlet，作用是接收请求和响应浏览器\nMVC的工作流程： 用户通过视图层发送请求到服务器，在服务器中请求被Controller接收，Controller调用相应的Model层处理请求，处理完毕将结果返回到Controller，Controller再根据请求处理的结果找到相应的View视图，渲染数据后最终响应给浏览器\n2、什么是SpringMVC SpringMVC是Spring的一个后续产品，是Spring的一个子项目\nSpringMVC 是 Spring 为表述层开发提供的一整套完备的解决方案。在表述层框架历经 Strust、WebWork、Strust2 等诸多产品的历代更迭之后，目前业界普遍选择了 SpringMVC 作为 Java EE 项目表述层开发的首选方案。\n注：三层架构分为表述层（或表示层）、业务逻辑层、数据访问层，表述层表示前台页面和后台servlet\n3、SpringMVC的特点 Spring 家族原生产品，与 IOC 容器等基础设施无缝对接 基于原生的Servlet，通过了功能强大的前端控制器DispatcherServlet，对请求和响应进行统一处理 表述层各细分领域需要解决的问题全方位覆盖，提供全面解决方案 代码清新简洁，大幅度提升开发效率 内部组件化程度高，可插拔式组件即插即用，想要什么功能配置相应组件即可 性能卓著，尤其适合现代大型、超大型互联网项目要求 二、HelloWorld 1、开发环境 IDE：idea 2019.2\n构建工具：maven3.5.4\n服务器：tomcat7\nSpring版本：5.3.1\n2、创建maven工程 a\u0026gt;添加web模块 b\u0026gt;打包方式：war c\u0026gt;引入依赖 \u0026lt;dependencies\u0026gt; \u0026lt;!-- SpringMVC --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 日志 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- ServletAPI --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Spring5和Thymeleaf整合包 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.thymeleaf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;thymeleaf-spring5\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.12.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 注：由于 Maven 的传递性，我们不必将所有需要的包全部配置依赖，而是配置最顶端的依赖，其他靠传递性导入。\n3、配置web.xml 注册SpringMVC的前端控制器DispatcherServlet\na\u0026gt;默认配置方式 此配置作用下，SpringMVC的配置文件默认位于WEB-INF下，默认名称为\u0026lt;servlet-name\u0026gt;-servlet.xml，例如，以下配置所对应SpringMVC的配置文件位于WEB-INF下，文件名为springMVC-servlet.xml\n\u0026lt;!-- 配置SpringMVC的前端控制器，对浏览器发送的请求统一进行处理 --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;!-- 设置springMVC的核心控制器所能处理的请求的请求路径 /所匹配的请求可以是/login或.html或.js或.css方式的请求路径 但是/不能匹配.jsp请求路径的请求 --\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; b\u0026gt;扩展配置方式 可通过init-param标签设置SpringMVC配置文件的位置和名称，通过load-on-startup标签设置SpringMVC前端控制器DispatcherServlet的初始化时间\n\u0026lt;!-- 配置SpringMVC的前端控制器，对浏览器发送的请求统一进行处理 --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;!-- 通过初始化参数指定SpringMVC配置文件的位置和名称 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;!-- contextConfigLocation为固定值 --\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;!-- 使用classpath:表示从类路径查找配置文件，例如maven工程中的src/main/resources --\u0026gt; \u0026lt;param-value\u0026gt;classpath:springMVC.xml\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 作为框架的核心组件，在启动过程中有大量的初始化操作要做 而这些操作放在第一次请求时才执行会严重影响访问速度 因此需要通过此标签将启动控制DispatcherServlet的初始化时间提前到服务器启动时 --\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;!-- 设置springMVC的核心控制器所能处理的请求的请求路径 /所匹配的请求可以是/login或.html或.js或.css方式的请求路径 但是/不能匹配.jsp请求路径的请求 --\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 注：\n\u0026lt;url-pattern\u0026gt;标签中使用/和/*的区别：\n/所匹配的请求可以是/login或.html或.js或.css方式的请求路径，但是/不能匹配.jsp请求路径的请求\n因此就可以避免在访问jsp页面时，该请求被DispatcherServlet处理，从而找不到相应的页面\n/*则能够匹配所有请求，例如在使用过滤器时，若需要对所有请求进行过滤，就需要使用/*的写法\n4、创建请求控制器 由于前端控制器对浏览器发送的请求进行了统一的处理，但是具体的请求有不同的处理过程，因此需要创建处理具体请求的类，即请求控制器\n请求控制器中每一个处理请求的方法成为控制器方法\n因为SpringMVC的控制器由一个POJO（普通的Java类）担任，因此需要通过@Controller注解将其标识为一个控制层组件，交给Spring的IoC容器管理，此时SpringMVC才能够识别控制器的存在\n@Controller public class HelloController { } 5、创建springMVC的配置文件 \u0026lt;!-- 自动扫描包 --\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.atguigu.mvc.controller\u0026#34;/\u0026gt; \u0026lt;!-- 配置Thymeleaf视图解析器 --\u0026gt; \u0026lt;bean id=\u0026#34;viewResolver\u0026#34; class=\u0026#34;org.thymeleaf.spring5.view.ThymeleafViewResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;order\u0026#34; value=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;characterEncoding\u0026#34; value=\u0026#34;UTF-8\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;templateEngine\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.thymeleaf.spring5.SpringTemplateEngine\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;templateResolver\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.thymeleaf.spring5.templateresolver.SpringResourceTemplateResolver\u0026#34;\u0026gt; \u0026lt;!-- 视图前缀 --\u0026gt; \u0026lt;property name=\u0026#34;prefix\u0026#34; value=\u0026#34;/WEB-INF/templates/\u0026#34;/\u0026gt; \u0026lt;!-- 视图后缀 --\u0026gt; \u0026lt;property name=\u0026#34;suffix\u0026#34; value=\u0026#34;.html\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;templateMode\u0026#34; value=\u0026#34;HTML5\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;characterEncoding\u0026#34; value=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- 处理静态资源，例如html、js、css、jpg 若只设置该标签，则只能访问静态资源，其他请求则无法访问 此时必须设置\u0026lt;mvc:annotation-driven/\u0026gt;解决问题 --\u0026gt; \u0026lt;mvc:default-servlet-handler/\u0026gt; \u0026lt;!-- 开启mvc注解驱动 --\u0026gt; \u0026lt;mvc:annotation-driven\u0026gt; \u0026lt;mvc:message-converters\u0026gt; \u0026lt;!-- 处理响应中文内容乱码 --\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.http.converter.StringHttpMessageConverter\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;defaultCharset\u0026#34; value=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;supportedMediaTypes\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;text/html\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;application/json\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/mvc:message-converters\u0026gt; \u0026lt;/mvc:annotation-driven\u0026gt; 6、测试HelloWorld a\u0026gt;实现对首页的访问 在请求控制器中创建处理请求的方法\n// @RequestMapping注解：处理请求和控制器方法之间的映射关系 // @RequestMapping注解的value属性可以通过请求地址匹配请求，/表示的当前工程的上下文路径 // localhost:8080/springMVC/ @RequestMapping(\u0026#34;/\u0026#34;) public String index() { //设置视图名称 return \u0026#34;index\u0026#34;; } b\u0026gt;通过超链接跳转到指定页面 在主页index.html中设置超链接\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34; xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;首页\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;首页\u0026lt;/h1\u0026gt; \u0026lt;a th:href=\u0026#34;@{/hello}\u0026#34;\u0026gt;HelloWorld\u0026lt;/a\u0026gt;\u0026lt;br/\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 在请求控制器中创建处理请求的方法\n@RequestMapping(\u0026#34;/hello\u0026#34;) public String HelloWorld() { return \u0026#34;target\u0026#34;; } 7、总结 浏览器发送请求，若请求地址符合前端控制器的url-pattern，该请求就会被前端控制器DispatcherServlet处理。前端控制器会读取SpringMVC的核心配置文件，通过扫描组件找到控制器，将请求地址和控制器中@RequestMapping注解的value属性值进行匹配，若匹配成功，该注解所标识的控制器方法就是处理请求的方法。处理请求的方法需要返回一个字符串类型的视图名称，该视图名称会被视图解析器解析，加上前缀和后缀组成视图的路径，通过Thymeleaf对视图进行渲染，最终转发到视图所对应页面\n三、@RequestMapping注解 1、@RequestMapping注解的功能 从注解名称上我们可以看到，@RequestMapping注解的作用就是将请求和处理请求的控制器方法关联起来，建立映射关系。\nSpringMVC 接收到指定的请求，就会来找到在映射关系中对应的控制器方法来处理这个请求。\n2、@RequestMapping注解的位置 @RequestMapping标识一个类：设置映射请求的请求路径的初始信息\n@RequestMapping标识一个方法：设置映射请求请求路径的具体信息\n@Controller @RequestMapping(\u0026#34;/test\u0026#34;) public class RequestMappingController { //此时请求映射所映射的请求的请求路径为：/test/testRequestMapping @RequestMapping(\u0026#34;/testRequestMapping\u0026#34;) public String testRequestMapping(){ return \u0026#34;success\u0026#34;; } } 3、@RequestMapping注解的value属性 @RequestMapping注解的value属性通过请求的请求地址匹配请求映射\n@RequestMapping注解的value属性是一个字符串类型的数组，表示该请求映射能够匹配多个请求地址所对应的请求\n@RequestMapping注解的value属性必须设置，至少通过请求地址匹配请求映射\n\u0026lt;a th:href=\u0026#34;@{/testRequestMapping}\u0026#34;\u0026gt;测试@RequestMapping的value属性--\u0026gt;/testRequestMapping\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt; \u0026lt;a th:href=\u0026#34;@{/test}\u0026#34;\u0026gt;测试@RequestMapping的value属性--\u0026gt;/test\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt; @RequestMapping( value = {\u0026#34;/testRequestMapping\u0026#34;, \u0026#34;/test\u0026#34;} ) public String testRequestMapping(){ return \u0026#34;success\u0026#34;; } 4、@RequestMapping注解的method属性 @RequestMapping注解的method属性通过请求的请求方式（get或post）匹配请求映射\n@RequestMapping注解的method属性是一个RequestMethod类型的数组，表示该请求映射能够匹配多种请求方式的请求\n若当前请求的请求地址满足请求映射的value属性，但是请求方式不满足method属性，则浏览器报错405：Request method \u0026lsquo;POST\u0026rsquo; not supported\n\u0026lt;a th:href=\u0026#34;@{/test}\u0026#34;\u0026gt;测试@RequestMapping的value属性--\u0026gt;/test\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt; \u0026lt;form th:action=\u0026#34;@{/test}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; @RequestMapping( value = {\u0026#34;/testRequestMapping\u0026#34;, \u0026#34;/test\u0026#34;}, method = {RequestMethod.GET, RequestMethod.POST} ) public String testRequestMapping(){ return \u0026#34;success\u0026#34;; } 注：\n1、对于处理指定请求方式的控制器方法，SpringMVC中提供了@RequestMapping的派生注解\n处理get请求的映射\u0026ndash;\u0026gt;@GetMapping\n处理post请求的映射\u0026ndash;\u0026gt;@PostMapping\n处理put请求的映射\u0026ndash;\u0026gt;@PutMapping\n处理delete请求的映射\u0026ndash;\u0026gt;@DeleteMapping\n2、常用的请求方式有get，post，put，delete\n但是目前浏览器只支持get和post，若在form表单提交时，为method设置了其他请求方式的字符串（put或delete），则按照默认的请求方式get处理\n若要发送put和delete请求，则需要通过spring提供的过滤器HiddenHttpMethodFilter，在RESTful部分会讲到\n5、@RequestMapping注解的params属性（了解） @RequestMapping注解的params属性通过请求的请求参数匹配请求映射\n@RequestMapping注解的params属性是一个字符串类型的数组，可以通过四种表达式设置请求参数和请求映射的匹配关系\n\u0026ldquo;param\u0026rdquo;：要求请求映射所匹配的请求必须携带param请求参数\n\u0026ldquo;!param\u0026rdquo;：要求请求映射所匹配的请求必须不能携带param请求参数\n\u0026ldquo;param=value\u0026rdquo;：要求请求映射所匹配的请求必须携带param请求参数且param=value\n\u0026ldquo;param!=value\u0026rdquo;：要求请求映射所匹配的请求必须携带param请求参数但是param!=value\n\u0026lt;a th:href=\u0026#34;@{/test(username=\u0026#39;admin\u0026#39;,password=123456)\u0026#34;\u0026gt;测试@RequestMapping的params属性--\u0026gt;/test\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt; @RequestMapping( value = {\u0026#34;/testRequestMapping\u0026#34;, \u0026#34;/test\u0026#34;} ,method = {RequestMethod.GET, RequestMethod.POST} ,params = {\u0026#34;username\u0026#34;,\u0026#34;password!=123456\u0026#34;} ) public String testRequestMapping(){ return \u0026#34;success\u0026#34;; } 注：\n若当前请求满足@RequestMapping注解的value和method属性，但是不满足params属性，此时页面回报错400：Parameter conditions \u0026ldquo;username, password!=123456\u0026rdquo; not met for actual request parameters: username={admin}, password={123456}\n6、@RequestMapping注解的headers属性（了解） @RequestMapping注解的headers属性通过请求的请求头信息匹配请求映射\n@RequestMapping注解的headers属性是一个字符串类型的数组，可以通过四种表达式设置请求头信息和请求映射的匹配关系\n\u0026ldquo;header\u0026rdquo;：要求请求映射所匹配的请求必须携带header请求头信息\n\u0026ldquo;!header\u0026rdquo;：要求请求映射所匹配的请求必须不能携带header请求头信息\n\u0026ldquo;header=value\u0026rdquo;：要求请求映射所匹配的请求必须携带header请求头信息且header=value\n\u0026ldquo;header!=value\u0026rdquo;：要求请求映射所匹配的请求必须携带header请求头信息且header!=value\n若当前请求满足@RequestMapping注解的value和method属性，但是不满足headers属性，此时页面显示404错误，即资源未找到\n7、SpringMVC支持ant风格的路径 ？：表示任意的单个字符\n*：表示任意的0个或多个字符\n**：表示任意的一层或多层目录\n注意：在使用**时，只能使用/**/xxx的方式\n8、SpringMVC支持路径中的占位符（重点） 原始方式：/deleteUser?id=1\nrest方式：/deleteUser/1\nSpringMVC路径中的占位符常用于RESTful风格中，当请求路径中将某些数据通过路径的方式传输到服务器中，就可以在相应的@RequestMapping注解的value属性中通过占位符{xxx}表示传输的数据，在通过@PathVariable注解，将占位符所表示的数据赋值给控制器方法的形参\n\u0026lt;a th:href=\u0026#34;@{/testRest/1/admin}\u0026#34;\u0026gt;测试路径中的占位符--\u0026gt;/testRest\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt; @RequestMapping(\u0026#34;/testRest/{id}/{username}\u0026#34;) public String testRest(@PathVariable(\u0026#34;id\u0026#34;) String id, @PathVariable(\u0026#34;username\u0026#34;) String username){ System.out.println(\u0026#34;id:\u0026#34;+id+\u0026#34;,username:\u0026#34;+username); return \u0026#34;success\u0026#34;; } //最终输出的内容为--\u0026gt;id:1,username:admin 四、SpringMVC获取请求参数 1、通过ServletAPI获取 将HttpServletRequest作为控制器方法的形参，此时HttpServletRequest类型的参数表示封装了当前请求的请求报文的对象\n@RequestMapping(\u0026#34;/testParam\u0026#34;) public String testParam(HttpServletRequest request){ String username = request.getParameter(\u0026#34;username\u0026#34;); String password = request.getParameter(\u0026#34;password\u0026#34;); System.out.println(\u0026#34;username:\u0026#34;+username+\u0026#34;,password:\u0026#34;+password); return \u0026#34;success\u0026#34;; } 2、通过控制器方法的形参获取请求参数 在控制器方法的形参位置，设置和请求参数同名的形参，当浏览器发送请求，匹配到请求映射时，在DispatcherServlet中就会将请求参数赋值给相应的形参\n\u0026lt;a th:href=\u0026#34;@{/testParam(username=\u0026#39;admin\u0026#39;,password=123456)}\u0026#34;\u0026gt;测试获取请求参数--\u0026gt;/testParam\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt; @RequestMapping(\u0026#34;/testParam\u0026#34;) public String testParam(String username, String password){ System.out.println(\u0026#34;username:\u0026#34;+username+\u0026#34;,password:\u0026#34;+password); return \u0026#34;success\u0026#34;; } 注：\n若请求所传输的请求参数中有多个同名的请求参数，此时可以在控制器方法的形参中设置字符串数组或者字符串类型的形参接收此请求参数\n若使用字符串数组类型的形参，此参数的数组中包含了每一个数据\n若使用字符串类型的形参，此参数的值为每个数据中间使用逗号拼接的结果\n3、@RequestParam @RequestParam是将请求参数和控制器方法的形参创建映射关系\n@RequestParam注解一共有三个属性：\nvalue：指定为形参赋值的请求参数的参数名\nrequired：设置是否必须传输此请求参数，默认值为true\n若设置为true时，则当前请求必须传输value所指定的请求参数，若没有传输该请求参数，且没有设置defaultValue属性，则页面报错400：Required String parameter \u0026lsquo;xxx\u0026rsquo; is not present；若设置为false，则当前请求不是必须传输value所指定的请求参数，若没有传输，则注解所标识的形参的值为null\ndefaultValue：不管required属性值为true或false，当value所指定的请求参数没有传输或传输的值为\u0026quot;\u0026ldquo;时，则使用默认值为形参赋值\n4、@RequestHeader @RequestHeader是将请求头信息和控制器方法的形参创建映射关系\n@RequestHeader注解一共有三个属性：value、required、defaultValue，用法同@RequestParam\n5、@CookieValue @CookieValue是将cookie数据和控制器方法的形参创建映射关系\n@CookieValue注解一共有三个属性：value、required、defaultValue，用法同@RequestParam\n6、通过POJO获取请求参数 可以在控制器方法的形参位置设置一个实体类类型的形参，此时若浏览器传输的请求参数的参数名和实体类中的属性名一致，那么请求参数就会为此属性赋值\n\u0026lt;form th:action=\u0026#34;@{/testpojo}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; 用户名：\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34;\u0026gt;\u0026lt;br\u0026gt; 密码：\u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34;\u0026gt;\u0026lt;br\u0026gt; 性别：\u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;sex\u0026#34; value=\u0026#34;男\u0026#34;\u0026gt;男\u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;sex\u0026#34; value=\u0026#34;女\u0026#34;\u0026gt;女\u0026lt;br\u0026gt; 年龄：\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;age\u0026#34;\u0026gt;\u0026lt;br\u0026gt; 邮箱：\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; @RequestMapping(\u0026#34;/testpojo\u0026#34;) public String testPOJO(User user){ System.out.println(user); return \u0026#34;success\u0026#34;; } //最终结果--\u0026gt;User{id=null, username=\u0026#39;张三\u0026#39;, password=\u0026#39;123\u0026#39;, age=23, sex=\u0026#39;男\u0026#39;, email=\u0026#39;123@qq.com\u0026#39;} 7、解决获取请求参数的乱码问题 解决获取请求参数的乱码问题，可以使用SpringMVC提供的编码过滤器CharacterEncodingFilter，但是必须在web.xml中进行注册\n\u0026lt;!--配置springMVC的编码过滤器--\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;CharacterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.CharacterEncodingFilter\u0026lt;/filter-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;encoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;UTF-8\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;forceResponseEncoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;true\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;CharacterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; 注：\nSpringMVC中处理编码的过滤器一定要配置到其他过滤器之前，否则无效\n五、域对象共享数据 1、使用ServletAPI向request域对象共享数据 @RequestMapping(\u0026#34;/testServletAPI\u0026#34;) public String testServletAPI(HttpServletRequest request){ request.setAttribute(\u0026#34;testScope\u0026#34;, \u0026#34;hello,servletAPI\u0026#34;); return \u0026#34;success\u0026#34;; } 2、使用ModelAndView向request域对象共享数据 @RequestMapping(\u0026#34;/testModelAndView\u0026#34;) public ModelAndView testModelAndView(){ /** * ModelAndView有Model和View的功能 * Model主要用于向请求域共享数据 * View主要用于设置视图，实现页面跳转 */ ModelAndView mav = new ModelAndView(); //向请求域共享数据 mav.addObject(\u0026#34;testScope\u0026#34;, \u0026#34;hello,ModelAndView\u0026#34;); //设置视图，实现页面跳转 mav.setViewName(\u0026#34;success\u0026#34;); return mav; } 3、使用Model向request域对象共享数据 @RequestMapping(\u0026#34;/testModel\u0026#34;) public String testModel(Model model){ model.addAttribute(\u0026#34;testScope\u0026#34;, \u0026#34;hello,Model\u0026#34;); return \u0026#34;success\u0026#34;; } 4、使用map向request域对象共享数据 @RequestMapping(\u0026#34;/testMap\u0026#34;) public String testMap(Map\u0026lt;String, Object\u0026gt; map){ map.put(\u0026#34;testScope\u0026#34;, \u0026#34;hello,Map\u0026#34;); return \u0026#34;success\u0026#34;; } 5、使用ModelMap向request域对象共享数据 @RequestMapping(\u0026#34;/testModelMap\u0026#34;) public String testModelMap(ModelMap modelMap){ modelMap.addAttribute(\u0026#34;testScope\u0026#34;, \u0026#34;hello,ModelMap\u0026#34;); return \u0026#34;success\u0026#34;; } 6、Model、ModelMap、Map的关系 Model、ModelMap、Map类型的参数其实本质上都是 BindingAwareModelMap 类型的\npublic interface Model{} public class ModelMap extends LinkedHashMap\u0026lt;String, Object\u0026gt; {} public class ExtendedModelMap extends ModelMap implements Model {} public class BindingAwareModelMap extends ExtendedModelMap {} 7、向session域共享数据 @RequestMapping(\u0026#34;/testSession\u0026#34;) public String testSession(HttpSession session){ session.setAttribute(\u0026#34;testSessionScope\u0026#34;, \u0026#34;hello,session\u0026#34;); return \u0026#34;success\u0026#34;; } 8、向application域共享数据 @RequestMapping(\u0026#34;/testApplication\u0026#34;) public String testApplication(HttpSession session){ ServletContext application = session.getServletContext(); application.setAttribute(\u0026#34;testApplicationScope\u0026#34;, \u0026#34;hello,application\u0026#34;); return \u0026#34;success\u0026#34;; } 六、SpringMVC的视图 SpringMVC中的视图是View接口，视图的作用渲染数据，将模型Model中的数据展示给用户\nSpringMVC视图的种类很多，默认有转发视图和重定向视图\n当工程引入jstl的依赖，转发视图会自动转换为JstlView\n若使用的视图技术为Thymeleaf，在SpringMVC的配置文件中配置了Thymeleaf的视图解析器，由此视图解析器解析之后所得到的是ThymeleafView\n1、ThymeleafView 当控制器方法中所设置的视图名称没有任何前缀时，此时的视图名称会被SpringMVC配置文件中所配置的视图解析器解析，视图名称拼接视图前缀和视图后缀所得到的最终路径，会通过转发的方式实现跳转\n@RequestMapping(\u0026#34;/testHello\u0026#34;) public String testHello(){ return \u0026#34;hello\u0026#34;; } 2、转发视图 SpringMVC中默认的转发视图是InternalResourceView\nSpringMVC中创建转发视图的情况：\n当控制器方法中所设置的视图名称以\u0026quot;forward:\u0026ldquo;为前缀时，创建InternalResourceView视图，此时的视图名称不会被SpringMVC配置文件中所配置的视图解析器解析，而是会将前缀\u0026quot;forward:\u0026ldquo;去掉，剩余部分作为最终路径通过转发的方式实现跳转\n例如\u0026quot;forward:/\u0026quot;，\u0026ldquo;forward:/employee\u0026rdquo;\n@RequestMapping(\u0026#34;/testForward\u0026#34;) public String testForward(){ return \u0026#34;forward:/testHello\u0026#34;; } 3、重定向视图 SpringMVC中默认的重定向视图是RedirectView\n当控制器方法中所设置的视图名称以\u0026quot;redirect:\u0026ldquo;为前缀时，创建RedirectView视图，此时的视图名称不会被SpringMVC配置文件中所配置的视图解析器解析，而是会将前缀\u0026quot;redirect:\u0026ldquo;去掉，剩余部分作为最终路径通过重定向的方式实现跳转\n例如\u0026quot;redirect:/\u0026quot;，\u0026ldquo;redirect:/employee\u0026rdquo;\n@RequestMapping(\u0026#34;/testRedirect\u0026#34;) public String testRedirect(){ return \u0026#34;redirect:/testHello\u0026#34;; } 注：\n重定向视图在解析时，会先将redirect:前缀去掉，然后会判断剩余部分是否以/开头，若是则会自动拼接上下文路径\n4、视图控制器view-controller 当控制器方法中，仅仅用来实现页面跳转，即只需要设置视图名称时，可以将处理器方法使用view-controller标签进行表示\n\u0026lt;!-- path：设置处理的请求地址 view-name：设置请求地址所对应的视图名称 --\u0026gt; \u0026lt;mvc:view-controller path=\u0026#34;/testView\u0026#34; view-name=\u0026#34;success\u0026#34;\u0026gt;\u0026lt;/mvc:view-controller\u0026gt; 注：\n当SpringMVC中设置任何一个view-controller时，其他控制器中的请求映射将全部失效，此时需要在SpringMVC的核心配置文件中设置开启mvc注解驱动的标签：\n\u0026lt;mvc:annotation-driven /\u0026gt;\n七、RESTful 1、RESTful简介 REST：Representational State Transfer，表现层资源状态转移。\na\u0026gt;资源 资源是一种看待服务器的方式，即，将服务器看作是由很多离散的资源组成。每个资源是服务器上一个可命名的抽象概念。因为资源是一个抽象的概念，所以它不仅仅能代表服务器文件系统中的一个文件、数据库中的一张表等等具体的东西，可以将资源设计的要多抽象有多抽象，只要想象力允许而且客户端应用开发者能够理解。与面向对象设计类似，资源是以名词为核心来组织的，首先关注的是名词。一个资源可以由一个或多个URI来标识。URI既是资源的名称，也是资源在Web上的地址。对某个资源感兴趣的客户端应用，可以通过资源的URI与其进行交互。\nb\u0026gt;资源的表述 资源的表述是一段对于资源在某个特定时刻的状态的描述。可以在客户端-服务器端之间转移（交换）。资源的表述可以有多种格式，例如HTML/XML/JSON/纯文本/图片/视频/音频等等。资源的表述格式可以通过协商机制来确定。请求-响应方向的表述通常使用不同的格式。\nc\u0026gt;状态转移 状态转移说的是：在客户端和服务器端之间转移（transfer）代表资源状态的表述。通过转移和操作资源的表述，来间接实现操作资源的目的。\n2、RESTful的实现 具体说，就是 HTTP 协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。\n它们分别对应四种基本操作：GET 用来获取资源，POST 用来新建资源，PUT 用来更新资源，DELETE 用来删除资源。\nREST 风格提倡 URL 地址使用统一的风格设计，从前到后各个单词使用斜杠分开，不使用问号键值对方式携带请求参数，而是将要发送给服务器的数据作为 URL 地址的一部分，以保证整体风格的一致性。\n操作 传统方式 REST风格 查询操作 getUserById?id=1 user/1\u0026ndash;\u0026gt;get请求方式 保存操作 saveUser user\u0026ndash;\u0026gt;post请求方式 删除操作 deleteUser?id=1 user/1\u0026ndash;\u0026gt;delete请求方式 更新操作 updateUser user\u0026ndash;\u0026gt;put请求方式 3、HiddenHttpMethodFilter 由于浏览器只支持发送get和post方式的请求，那么该如何发送put和delete请求呢？\nSpringMVC 提供了 HiddenHttpMethodFilter 帮助我们将 POST 请求转换为 DELETE 或 PUT 请求\nHiddenHttpMethodFilter 处理put和delete请求的条件：\na\u0026gt;当前请求的请求方式必须为post\nb\u0026gt;当前请求必须传输请求参数_method\n满足以上条件，HiddenHttpMethodFilter 过滤器就会将当前请求的请求方式转换为请求参数_method的值，因此请求参数_method的值才是最终的请求方式\n在web.xml中注册HiddenHttpMethodFilter\n\u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;HiddenHttpMethodFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.HiddenHttpMethodFilter\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;HiddenHttpMethodFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; 注：\n目前为止，SpringMVC中提供了两个过滤器：CharacterEncodingFilter和HiddenHttpMethodFilter\n在web.xml中注册时，必须先注册CharacterEncodingFilter，再注册HiddenHttpMethodFilter\n原因：\n在 CharacterEncodingFilter 中通过 request.setCharacterEncoding(encoding) 方法设置字符集的\nrequest.setCharacterEncoding(encoding) 方法要求前面不能有任何获取请求参数的操作\n而 HiddenHttpMethodFilter 恰恰有一个获取请求方式的操作：\nString paramValue = request.getParameter(this.methodParam); 八、RESTful案例 1、准备工作 和传统 CRUD 一样，实现对员工信息的增删改查。\n搭建环境\n准备实体类\npackage com.atguigu.mvc.bean; public class Employee { private Integer id; private String lastName; private String email; //1 male, 0 female private Integer gender; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public String getEmail() { return email; } public void setEmail(String email) { this.email = email; } public Integer getGender() { return gender; } public void setGender(Integer gender) { this.gender = gender; } public Employee(Integer id, String lastName, String email, Integer gender) { super(); this.id = id; this.lastName = lastName; this.email = email; this.gender = gender; } public Employee() { } } 准备dao模拟数据\npackage com.atguigu.mvc.dao; import java.util.Collection; import java.util.HashMap; import java.util.Map; import com.atguigu.mvc.bean.Employee; import org.springframework.stereotype.Repository; @Repository public class EmployeeDao { private static Map\u0026lt;Integer, Employee\u0026gt; employees = null; static{ employees = new HashMap\u0026lt;Integer, Employee\u0026gt;(); employees.put(1001, new Employee(1001, \u0026#34;E-AA\u0026#34;, \u0026#34;aa@163.com\u0026#34;, 1)); employees.put(1002, new Employee(1002, \u0026#34;E-BB\u0026#34;, \u0026#34;bb@163.com\u0026#34;, 1)); employees.put(1003, new Employee(1003, \u0026#34;E-CC\u0026#34;, \u0026#34;cc@163.com\u0026#34;, 0)); employees.put(1004, new Employee(1004, \u0026#34;E-DD\u0026#34;, \u0026#34;dd@163.com\u0026#34;, 0)); employees.put(1005, new Employee(1005, \u0026#34;E-EE\u0026#34;, \u0026#34;ee@163.com\u0026#34;, 1)); } private static Integer initId = 1006; public void save(Employee employee){ if(employee.getId() == null){ employee.setId(initId++); } employees.put(employee.getId(), employee); } public Collection\u0026lt;Employee\u0026gt; getAll(){ return employees.values(); } public Employee get(Integer id){ return employees.get(id); } public void delete(Integer id){ employees.remove(id); } } 2、功能清单 功能 URL 地址 请求方式 访问首页√ / GET 查询全部数据√ /employee GET 删除√ /employee/2 DELETE 跳转到添加数据页面√ /toAdd GET 执行保存√ /employee POST 跳转到更新数据页面√ /employee/2 GET 执行更新√ /employee PUT 3、具体功能：访问首页 a\u0026gt;配置view-controller \u0026lt;mvc:view-controller path=\u0026#34;/\u0026#34; view-name=\u0026#34;index\u0026#34;/\u0026gt; b\u0026gt;创建页面 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34; xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; \u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;首页\u0026lt;/h1\u0026gt; \u0026lt;a th:href=\u0026#34;@{/employee}\u0026#34;\u0026gt;访问员工信息\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 4、具体功能：查询所有员工数据 a\u0026gt;控制器方法 @RequestMapping(value = \u0026#34;/employee\u0026#34;, method = RequestMethod.GET) public String getEmployeeList(Model model){ Collection\u0026lt;Employee\u0026gt; employeeList = employeeDao.getAll(); model.addAttribute(\u0026#34;employeeList\u0026#34;, employeeList); return \u0026#34;employee_list\u0026#34;; } b\u0026gt;创建employee_list.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34; xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Employee Info\u0026lt;/title\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; th:src=\u0026#34;@{/static/js/vue.js}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;table border=\u0026#34;1\u0026#34; cellpadding=\u0026#34;0\u0026#34; cellspacing=\u0026#34;0\u0026#34; style=\u0026#34;text-align: center;\u0026#34; id=\u0026#34;dataTable\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th colspan=\u0026#34;5\u0026#34;\u0026gt;Employee Info\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;id\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;lastName\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;email\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;gender\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;options(\u0026lt;a th:href=\u0026#34;@{/toAdd}\u0026#34;\u0026gt;add\u0026lt;/a\u0026gt;)\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr th:each=\u0026#34;employee : ${employeeList}\u0026#34;\u0026gt; \u0026lt;td th:text=\u0026#34;${employee.id}\u0026#34;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td th:text=\u0026#34;${employee.lastName}\u0026#34;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td th:text=\u0026#34;${employee.email}\u0026#34;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td th:text=\u0026#34;${employee.gender}\u0026#34;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;a class=\u0026#34;deleteA\u0026#34; @click=\u0026#34;deleteEmployee\u0026#34; th:href=\u0026#34;@{\u0026#39;/employee/\u0026#39;+${employee.id}}\u0026#34;\u0026gt;delete\u0026lt;/a\u0026gt; \u0026lt;a th:href=\u0026#34;@{\u0026#39;/employee/\u0026#39;+${employee.id}}\u0026#34;\u0026gt;update\u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 5、具体功能：删除 a\u0026gt;创建处理delete请求方式的表单 \u0026lt;!-- 作用：通过超链接控制表单的提交，将post请求转换为delete请求 --\u0026gt; \u0026lt;form id=\u0026#34;delete_form\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;!-- HiddenHttpMethodFilter要求：必须传输_method请求参数，并且值为最终的请求方式 --\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;_method\u0026#34; value=\u0026#34;delete\u0026#34;/\u0026gt; \u0026lt;/form\u0026gt; b\u0026gt;删除超链接绑定点击事件 引入vue.js\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34; th:src=\u0026#34;@{/static/js/vue.js}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 删除超链接\n\u0026lt;a class=\u0026#34;deleteA\u0026#34; @click=\u0026#34;deleteEmployee\u0026#34; th:href=\u0026#34;@{\u0026#39;/employee/\u0026#39;+${employee.id}}\u0026#34;\u0026gt;delete\u0026lt;/a\u0026gt; 通过vue处理点击事件\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; var vue = new Vue({ el:\u0026#34;#dataTable\u0026#34;, methods:{ //event表示当前事件 deleteEmployee:function (event) { //通过id获取表单标签 var delete_form = document.getElementById(\u0026#34;delete_form\u0026#34;); //将触发事件的超链接的href属性为表单的action属性赋值 delete_form.action = event.target.href; //提交表单 delete_form.submit(); //阻止超链接的默认跳转行为 event.preventDefault(); } } }); \u0026lt;/script\u0026gt; c\u0026gt;控制器方法 @RequestMapping(value = \u0026#34;/employee/{id}\u0026#34;, method = RequestMethod.DELETE) public String deleteEmployee(@PathVariable(\u0026#34;id\u0026#34;) Integer id){ employeeDao.delete(id); return \u0026#34;redirect:/employee\u0026#34;; } 6、具体功能：跳转到添加数据页面 a\u0026gt;配置view-controller \u0026lt;mvc:view-controller path=\u0026#34;/toAdd\u0026#34; view-name=\u0026#34;employee_add\u0026#34;\u0026gt;\u0026lt;/mvc:view-controller\u0026gt; b\u0026gt;创建employee_add.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34; xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Add Employee\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form th:action=\u0026#34;@{/employee}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; lastName:\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;lastName\u0026#34;\u0026gt;\u0026lt;br\u0026gt; email:\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;email\u0026#34;\u0026gt;\u0026lt;br\u0026gt; gender:\u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;gender\u0026#34; value=\u0026#34;1\u0026#34;\u0026gt;male \u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;gender\u0026#34; value=\u0026#34;0\u0026#34;\u0026gt;female\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;add\u0026#34;\u0026gt;\u0026lt;br\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 7、具体功能：执行保存 a\u0026gt;控制器方法 @RequestMapping(value = \u0026#34;/employee\u0026#34;, method = RequestMethod.POST) public String addEmployee(Employee employee){ employeeDao.save(employee); return \u0026#34;redirect:/employee\u0026#34;; } 8、具体功能：跳转到更新数据页面 a\u0026gt;修改超链接 \u0026lt;a th:href=\u0026#34;@{\u0026#39;/employee/\u0026#39;+${employee.id}}\u0026#34;\u0026gt;update\u0026lt;/a\u0026gt; b\u0026gt;控制器方法 @RequestMapping(value = \u0026#34;/employee/{id}\u0026#34;, method = RequestMethod.GET) public String getEmployeeById(@PathVariable(\u0026#34;id\u0026#34;) Integer id, Model model){ Employee employee = employeeDao.get(id); model.addAttribute(\u0026#34;employee\u0026#34;, employee); return \u0026#34;employee_update\u0026#34;; } c\u0026gt;创建employee_update.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34; xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Update Employee\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form th:action=\u0026#34;@{/employee}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;_method\u0026#34; value=\u0026#34;put\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;id\u0026#34; th:value=\u0026#34;${employee.id}\u0026#34;\u0026gt; lastName:\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;lastName\u0026#34; th:value=\u0026#34;${employee.lastName}\u0026#34;\u0026gt;\u0026lt;br\u0026gt; email:\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;email\u0026#34; th:value=\u0026#34;${employee.email}\u0026#34;\u0026gt;\u0026lt;br\u0026gt; \u0026lt;!-- th:field=\u0026#34;${employee.gender}\u0026#34;可用于单选框或复选框的回显 若单选框的value和employee.gender的值一致，则添加checked=\u0026#34;checked\u0026#34;属性 --\u0026gt; gender:\u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;gender\u0026#34; value=\u0026#34;1\u0026#34; th:field=\u0026#34;${employee.gender}\u0026#34;\u0026gt;male \u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;gender\u0026#34; value=\u0026#34;0\u0026#34; th:field=\u0026#34;${employee.gender}\u0026#34;\u0026gt;female\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;update\u0026#34;\u0026gt;\u0026lt;br\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 9、具体功能：执行更新 a\u0026gt;控制器方法 @RequestMapping(value = \u0026#34;/employee\u0026#34;, method = RequestMethod.PUT) public String updateEmployee(Employee employee){ employeeDao.save(employee); return \u0026#34;redirect:/employee\u0026#34;; } 八、HttpMessageConverter HttpMessageConverter，报文信息转换器，将请求报文转换为Java对象，或将Java对象转换为响应报文\nHttpMessageConverter提供了两个注解和两个类型：@RequestBody，@ResponseBody，RequestEntity，\nResponseEntity\n1、@RequestBody @RequestBody可以获取请求体，需要在控制器方法设置一个形参，使用@RequestBody进行标识，当前请求的请求体就会为当前注解所标识的形参赋值\n\u0026lt;form th:action=\u0026#34;@{/testRequestBody}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; 用户名：\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34;\u0026gt;\u0026lt;br\u0026gt; 密码：\u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34;\u0026gt;\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; @RequestMapping(\u0026#34;/testRequestBody\u0026#34;) public String testRequestBody(@RequestBody String requestBody){ System.out.println(\u0026#34;requestBody:\u0026#34;+requestBody); return \u0026#34;success\u0026#34;; } 输出结果：\nrequestBody:username=admin\u0026amp;password=123456\n2、RequestEntity RequestEntity封装请求报文的一种类型，需要在控制器方法的形参中设置该类型的形参，当前请求的请求报文就会赋值给该形参，可以通过getHeaders()获取请求头信息，通过getBody()获取请求体信息\n@RequestMapping(\u0026#34;/testRequestEntity\u0026#34;) public String testRequestEntity(RequestEntity\u0026lt;String\u0026gt; requestEntity){ System.out.println(\u0026#34;requestHeader:\u0026#34;+requestEntity.getHeaders()); System.out.println(\u0026#34;requestBody:\u0026#34;+requestEntity.getBody()); return \u0026#34;success\u0026#34;; } 输出结果： requestHeader:[host:\u0026ldquo;localhost:8080\u0026rdquo;, connection:\u0026ldquo;keep-alive\u0026rdquo;, content-length:\u0026ldquo;27\u0026rdquo;, cache-control:\u0026ldquo;max-age=0\u0026rdquo;, sec-ch-ua:\u0026rdquo;\u0026rdquo; Not A;Brand\u0026rdquo;;v=\u0026ldquo;99\u0026rdquo;, \u0026ldquo;Chromium\u0026rdquo;;v=\u0026ldquo;90\u0026rdquo;, \u0026ldquo;Google Chrome\u0026rdquo;;v=\u0026ldquo;90\u0026quot;\u0026rdquo;, sec-ch-ua-mobile:\u0026quot;?0\u0026rdquo;, upgrade-insecure-requests:\u0026ldquo;1\u0026rdquo;, origin:\u0026ldquo;http://localhost:8080\u0026rdquo;, user-agent:\u0026ldquo;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\u0026rdquo;] requestBody:username=admin\u0026amp;password=123\n3、@ResponseBody @ResponseBody用于标识一个控制器方法，可以将该方法的返回值直接作为响应报文的响应体响应到浏览器\n@RequestMapping(\u0026#34;/testResponseBody\u0026#34;) @ResponseBody public String testResponseBody(){ return \u0026#34;success\u0026#34;; } 结果：浏览器页面显示success\n4、SpringMVC处理json @ResponseBody处理json的步骤：\na\u0026gt;导入jackson的依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.12.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; b\u0026gt;在SpringMVC的核心配置文件中开启mvc的注解驱动，此时在HandlerAdaptor中会自动装配一个消息转换器：MappingJackson2HttpMessageConverter，可以将响应到浏览器的Java对象转换为Json格式的字符串\n\u0026lt;mvc:annotation-driven /\u0026gt; c\u0026gt;在处理器方法上使用@ResponseBody注解进行标识\nd\u0026gt;将Java对象直接作为控制器方法的返回值返回，就会自动转换为Json格式的字符串\n@RequestMapping(\u0026#34;/testResponseUser\u0026#34;) @ResponseBody public User testResponseUser(){ return new User(1001,\u0026#34;admin\u0026#34;,\u0026#34;123456\u0026#34;,23,\u0026#34;男\u0026#34;); } 浏览器的页面中展示的结果：\n{\u0026ldquo;id\u0026rdquo;:1001,\u0026ldquo;username\u0026rdquo;:\u0026ldquo;admin\u0026rdquo;,\u0026ldquo;password\u0026rdquo;:\u0026ldquo;123456\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:23,\u0026ldquo;sex\u0026rdquo;:\u0026ldquo;男\u0026rdquo;}\n5、SpringMVC处理ajax a\u0026gt;请求超链接：\n\u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;a th:href=\u0026#34;@{/testAjax}\u0026#34; @click=\u0026#34;testAjax\u0026#34;\u0026gt;testAjax\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt; \u0026lt;/div\u0026gt; b\u0026gt;通过vue和axios处理点击事件：\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34; th:src=\u0026#34;@{/static/js/vue.js}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; th:src=\u0026#34;@{/static/js/axios.min.js}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; var vue = new Vue({ el:\u0026#34;#app\u0026#34;, methods:{ testAjax:function (event) { axios({ method:\u0026#34;post\u0026#34;, url:event.target.href, params:{ username:\u0026#34;admin\u0026#34;, password:\u0026#34;123456\u0026#34; } }).then(function (response) { alert(response.data); }); event.preventDefault(); } } }); \u0026lt;/script\u0026gt; c\u0026gt;控制器方法：\n@RequestMapping(\u0026#34;/testAjax\u0026#34;) @ResponseBody public String testAjax(String username, String password){ System.out.println(\u0026#34;username:\u0026#34;+username+\u0026#34;,password:\u0026#34;+password); return \u0026#34;hello,ajax\u0026#34;; } 6、@RestController注解 @RestController注解是springMVC提供的一个复合注解，标识在控制器的类上，就相当于为类添加了@Controller注解，并且为其中的每个方法添加了@ResponseBody注解\n7、ResponseEntity ResponseEntity用于控制器方法的返回值类型，该控制器方法的返回值就是响应到浏览器的响应报文\n九、文件上传和下载 1、文件下载 使用ResponseEntity实现下载文件的功能\n@RequestMapping(\u0026#34;/testDown\u0026#34;) public ResponseEntity\u0026lt;byte[]\u0026gt; testResponseEntity(HttpSession session) throws IOException { //获取ServletContext对象 ServletContext servletContext = session.getServletContext(); //获取服务器中文件的真实路径 String realPath = servletContext.getRealPath(\u0026#34;/static/img/1.jpg\u0026#34;); //创建输入流 InputStream is = new FileInputStream(realPath); //创建字节数组 byte[] bytes = new byte[is.available()]; //将流读到字节数组中 is.read(bytes); //创建HttpHeaders对象设置响应头信息 MultiValueMap\u0026lt;String, String\u0026gt; headers = new HttpHeaders(); //设置要下载方式以及下载文件的名字 headers.add(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=1.jpg\u0026#34;); //设置响应状态码 HttpStatus statusCode = HttpStatus.OK; //创建ResponseEntity对象 ResponseEntity\u0026lt;byte[]\u0026gt; responseEntity = new ResponseEntity\u0026lt;\u0026gt;(bytes, headers, statusCode); //关闭输入流 is.close(); return responseEntity; } 2、文件上传 文件上传要求form表单的请求方式必须为post，并且添加属性enctype=\u0026ldquo;multipart/form-data\u0026rdquo;\nSpringMVC中将上传的文件封装到MultipartFile对象中，通过此对象可以获取文件相关信息\n上传步骤：\na\u0026gt;添加依赖：\n\u0026lt;!-- https://mvnrepository.com/artifact/commons-fileupload/commons-fileupload --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-fileupload\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-fileupload\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; b\u0026gt;在SpringMVC的配置文件中添加配置：\n\u0026lt;!--必须通过文件解析器的解析才能将文件转换为MultipartFile对象--\u0026gt; \u0026lt;bean id=\u0026#34;multipartResolver\u0026#34; class=\u0026#34;org.springframework.web.multipart.commons.CommonsMultipartResolver\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; c\u0026gt;控制器方法：\n@RequestMapping(\u0026#34;/testUp\u0026#34;) public String testUp(MultipartFile photo, HttpSession session) throws IOException { //获取上传的文件的文件名 String fileName = photo.getOriginalFilename(); //处理文件重名问题 String hzName = fileName.substring(fileName.lastIndexOf(\u0026#34;.\u0026#34;)); fileName = UUID.randomUUID().toString() + hzName; //获取服务器中photo目录的路径 ServletContext servletContext = session.getServletContext(); String photoPath = servletContext.getRealPath(\u0026#34;photo\u0026#34;); File file = new File(photoPath); if(!file.exists()){ file.mkdir(); } String finalPath = photoPath + File.separator + fileName; //实现上传功能 photo.transferTo(new File(finalPath)); return \u0026#34;success\u0026#34;; } 十、拦截器 1、拦截器的配置 SpringMVC中的拦截器用于拦截控制器方法的执行\nSpringMVC中的拦截器需要实现HandlerInterceptor\nSpringMVC的拦截器必须在SpringMVC的配置文件中进行配置：\n\u0026lt;bean class=\u0026#34;com.atguigu.interceptor.FirstInterceptor\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;ref bean=\u0026#34;firstInterceptor\u0026#34;\u0026gt;\u0026lt;/ref\u0026gt; \u0026lt;!-- 以上两种配置方式都是对DispatcherServlet所处理的所有的请求进行拦截 --\u0026gt; \u0026lt;mvc:interceptor\u0026gt; \u0026lt;mvc:mapping path=\u0026#34;/**\u0026#34;/\u0026gt; \u0026lt;mvc:exclude-mapping path=\u0026#34;/testRequestEntity\u0026#34;/\u0026gt; \u0026lt;ref bean=\u0026#34;firstInterceptor\u0026#34;\u0026gt;\u0026lt;/ref\u0026gt; \u0026lt;/mvc:interceptor\u0026gt; \u0026lt;!-- 以上配置方式可以通过ref或bean标签设置拦截器，通过mvc:mapping设置需要拦截的请求，通过mvc:exclude-mapping设置需要排除的请求，即不需要拦截的请求 --\u0026gt; 2、拦截器的三个抽象方法 SpringMVC中的拦截器有三个抽象方法：\npreHandle：控制器方法执行之前执行preHandle()，其boolean类型的返回值表示是否拦截或放行，返回true为放行，即调用控制器方法；返回false表示拦截，即不调用控制器方法\npostHandle：控制器方法执行之后执行postHandle()\nafterComplation：处理完视图和模型数据，渲染视图完毕之后执行afterComplation()\n3、多个拦截器的执行顺序 a\u0026gt;若每个拦截器的preHandle()都返回true\n此时多个拦截器的执行顺序和拦截器在SpringMVC的配置文件的配置顺序有关：\npreHandle()会按照配置的顺序执行，而postHandle()和afterComplation()会按照配置的反序执行\nb\u0026gt;若某个拦截器的preHandle()返回了false\npreHandle()返回false和它之前的拦截器的preHandle()都会执行，postHandle()都不执行，返回false的拦截器之前的拦截器的afterComplation()会执行\n十一、异常处理器 1、基于配置的异常处理 SpringMVC提供了一个处理控制器方法执行过程中所出现的异常的接口：HandlerExceptionResolver\nHandlerExceptionResolver接口的实现类有：DefaultHandlerExceptionResolver和SimpleMappingExceptionResolver\nSpringMVC提供了自定义的异常处理器SimpleMappingExceptionResolver，使用方式：\n\u0026lt;bean class=\u0026#34;org.springframework.web.servlet.handler.SimpleMappingExceptionResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;exceptionMappings\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;!-- properties的键表示处理器方法执行过程中出现的异常 properties的值表示若出现指定异常时，设置一个新的视图名称，跳转到指定页面 --\u0026gt; \u0026lt;prop key=\u0026#34;java.lang.ArithmeticException\u0026#34;\u0026gt;error\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- exceptionAttribute属性设置一个属性名，将出现的异常信息在请求域中进行共享 --\u0026gt; \u0026lt;property name=\u0026#34;exceptionAttribute\u0026#34; value=\u0026#34;ex\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 2、基于注解的异常处理 //@ControllerAdvice将当前类标识为异常处理的组件 @ControllerAdvice public class ExceptionController { //@ExceptionHandler用于设置所标识方法处理的异常 @ExceptionHandler(ArithmeticException.class) //ex表示当前请求处理中出现的异常对象 public String handleArithmeticException(Exception ex, Model model){ model.addAttribute(\u0026#34;ex\u0026#34;, ex); return \u0026#34;error\u0026#34;; } } 十二、注解配置SpringMVC 使用配置类和注解代替web.xml和SpringMVC配置文件的功能\n1、创建初始化类，代替web.xml 在Servlet3.0环境中，容器会在类路径中查找实现javax.servlet.ServletContainerInitializer接口的类，如果找到的话就用它来配置Servlet容器。 Spring提供了这个接口的实现，名为SpringServletContainerInitializer，这个类反过来又会查找实现WebApplicationInitializer的类并将配置的任务交给它们来完成。Spring3.2引入了一个便利的WebApplicationInitializer基础实现，名为AbstractAnnotationConfigDispatcherServletInitializer，当我们的类扩展了AbstractAnnotationConfigDispatcherServletInitializer并将其部署到Servlet3.0容器的时候，容器会自动发现它，并用它来配置Servlet上下文。\npublic class WebInit extends AbstractAnnotationConfigDispatcherServletInitializer { /** * 指定spring的配置类 * @return */ @Override protected Class\u0026lt;?\u0026gt;[] getRootConfigClasses() { return new Class[]{SpringConfig.class}; } /** * 指定SpringMVC的配置类 * @return */ @Override protected Class\u0026lt;?\u0026gt;[] getServletConfigClasses() { return new Class[]{WebConfig.class}; } /** * 指定DispatcherServlet的映射规则，即url-pattern * @return */ @Override protected String[] getServletMappings() { return new String[]{\u0026#34;/\u0026#34;}; } /** * 添加过滤器 * @return */ @Override protected Filter[] getServletFilters() { CharacterEncodingFilter encodingFilter = new CharacterEncodingFilter(); encodingFilter.setEncoding(\u0026#34;UTF-8\u0026#34;); encodingFilter.setForceRequestEncoding(true); HiddenHttpMethodFilter hiddenHttpMethodFilter = new HiddenHttpMethodFilter(); return new Filter[]{encodingFilter, hiddenHttpMethodFilter}; } } 2、创建SpringConfig配置类，代替spring的配置文件 @Configuration public class SpringConfig { //ssm整合之后，spring的配置信息写在此类中 } 3、创建WebConfig配置类，代替SpringMVC的配置文件 @Configuration //扫描组件 @ComponentScan(\u0026#34;com.atguigu.mvc.controller\u0026#34;) //开启MVC注解驱动 @EnableWebMvc public class WebConfig implements WebMvcConfigurer { //使用默认的servlet处理静态资源 @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) { configurer.enable(); } //配置文件上传解析器 @Bean public CommonsMultipartResolver multipartResolver(){ return new CommonsMultipartResolver(); } //配置拦截器 @Override public void addInterceptors(InterceptorRegistry registry) { FirstInterceptor firstInterceptor = new FirstInterceptor(); registry.addInterceptor(firstInterceptor).addPathPatterns(\u0026#34;/**\u0026#34;); } //配置视图控制 /*@Override public void addViewControllers(ViewControllerRegistry registry) { registry.addViewController(\u0026#34;/\u0026#34;).setViewName(\u0026#34;index\u0026#34;); }*/ //配置异常映射 /*@Override public void configureHandlerExceptionResolvers(List\u0026lt;HandlerExceptionResolver\u0026gt; resolvers) { SimpleMappingExceptionResolver exceptionResolver = new SimpleMappingExceptionResolver(); Properties prop = new Properties(); prop.setProperty(\u0026#34;java.lang.ArithmeticException\u0026#34;, \u0026#34;error\u0026#34;); //设置异常映射 exceptionResolver.setExceptionMappings(prop); //设置共享异常信息的键 exceptionResolver.setExceptionAttribute(\u0026#34;ex\u0026#34;); resolvers.add(exceptionResolver); }*/ //配置生成模板解析器 @Bean public ITemplateResolver templateResolver() { WebApplicationContext webApplicationContext = ContextLoader.getCurrentWebApplicationContext(); // ServletContextTemplateResolver需要一个ServletContext作为构造参数，可通过WebApplicationContext 的方法获得 ServletContextTemplateResolver templateResolver = new ServletContextTemplateResolver( webApplicationContext.getServletContext()); templateResolver.setPrefix(\u0026#34;/WEB-INF/templates/\u0026#34;); templateResolver.setSuffix(\u0026#34;.html\u0026#34;); templateResolver.setCharacterEncoding(\u0026#34;UTF-8\u0026#34;); templateResolver.setTemplateMode(TemplateMode.HTML); return templateResolver; } //生成模板引擎并为模板引擎注入模板解析器 @Bean public SpringTemplateEngine templateEngine(ITemplateResolver templateResolver) { SpringTemplateEngine templateEngine = new SpringTemplateEngine(); templateEngine.setTemplateResolver(templateResolver); return templateEngine; } //生成视图解析器并未解析器注入模板引擎 @Bean public ViewResolver viewResolver(SpringTemplateEngine templateEngine) { ThymeleafViewResolver viewResolver = new ThymeleafViewResolver(); viewResolver.setCharacterEncoding(\u0026#34;UTF-8\u0026#34;); viewResolver.setTemplateEngine(templateEngine); return viewResolver; } } 4、测试功能 @RequestMapping(\u0026#34;/\u0026#34;) public String index(){ return \u0026#34;index\u0026#34;; } 十三、SpringMVC执行流程 1、SpringMVC常用组件 DispatcherServlet：前端控制器，不需要工程师开发，由框架提供 作用：统一处理请求和响应，整个流程控制的中心，由它调用其它组件处理用户的请求\nHandlerMapping：处理器映射器，不需要工程师开发，由框架提供 作用：根据请求的url、method等信息查找Handler，即控制器方法\nHandler：处理器，需要工程师开发 作用：在DispatcherServlet的控制下Handler对具体的用户请求进行处理\nHandlerAdapter：处理器适配器，不需要工程师开发，由框架提供 作用：通过HandlerAdapter对处理器（控制器方法）进行执行\nViewResolver：视图解析器，不需要工程师开发，由框架提供 作用：进行视图解析，得到相应的视图，例如：ThymeleafView、InternalResourceView、RedirectView\nView：视图 作用：将模型数据通过页面展示给用户\n2、DispatcherServlet初始化过程 DispatcherServlet 本质上是一个 Servlet，所以天然的遵循 Servlet 的生命周期。所以宏观上是 Servlet 生命周期来进行调度。\na\u0026gt;初始化WebApplicationContext 所在类：org.springframework.web.servlet.FrameworkServlet\nprotected WebApplicationContext initWebApplicationContext() { WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) { // A context instance was injected at construction time -\u0026gt; use it wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) { ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) { // The context has not yet been refreshed -\u0026gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) { // The context instance was injected without an explicit parent -\u0026gt; set // the root application context (if any; may be null) as the parent cwac.setParent(rootContext); } configureAndRefreshWebApplicationContext(cwac); } } } if (wac == null) { // No context instance was injected at construction time -\u0026gt; see if one // has been registered in the servlet context. If one exists, it is assumed // that the parent context (if any) has already been set and that the // user has performed any initialization such as setting the context id wac = findWebApplicationContext(); } if (wac == null) { // No context instance is defined for this servlet -\u0026gt; create a local one // 创建WebApplicationContext wac = createWebApplicationContext(rootContext); } if (!this.refreshEventReceived) { // Either the context is not a ConfigurableApplicationContext with refresh // support or the context injected at construction time had already been // refreshed -\u0026gt; trigger initial onRefresh manually here. synchronized (this.onRefreshMonitor) { // 刷新WebApplicationContext onRefresh(wac); } } if (this.publishContext) { // Publish the context as a servlet context attribute. // 将IOC容器在应用域共享 String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); } return wac; } b\u0026gt;创建WebApplicationContext 所在类：org.springframework.web.servlet.FrameworkServlet\nprotected WebApplicationContext createWebApplicationContext(@Nullable ApplicationContext parent) { Class\u0026lt;?\u0026gt; contextClass = getContextClass(); if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) { throw new ApplicationContextException( \u0026#34;Fatal initialization error in servlet with name \u0026#39;\u0026#34; + getServletName() + \u0026#34;\u0026#39;: custom WebApplicationContext class [\u0026#34; + contextClass.getName() + \u0026#34;] is not of type ConfigurableWebApplicationContext\u0026#34;); } // 通过反射创建 IOC 容器对象 ConfigurableWebApplicationContext wac = (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass); wac.setEnvironment(getEnvironment()); // 设置父容器 wac.setParent(parent); String configLocation = getContextConfigLocation(); if (configLocation != null) { wac.setConfigLocation(configLocation); } configureAndRefreshWebApplicationContext(wac); return wac; } c\u0026gt;DispatcherServlet初始化策略 FrameworkServlet创建WebApplicationContext后，刷新容器，调用onRefresh(wac)，此方法在DispatcherServlet中进行了重写，调用了initStrategies(context)方法，初始化策略，即初始化DispatcherServlet的各个组件\n所在类：org.springframework.web.servlet.DispatcherServlet\nprotected void initStrategies(ApplicationContext context) { initMultipartResolver(context); initLocaleResolver(context); initThemeResolver(context); initHandlerMappings(context); initHandlerAdapters(context); initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); initViewResolvers(context); initFlashMapManager(context); } 3、DispatcherServlet调用组件处理请求 a\u0026gt;processRequest() FrameworkServlet重写HttpServlet中的service()和doXxx()，这些方法中调用了processRequest(request, response)\n所在类：org.springframework.web.servlet.FrameworkServlet\nprotected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { long startTime = System.currentTimeMillis(); Throwable failureCause = null; LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext(); LocaleContext localeContext = buildLocaleContext(request); RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor()); initContextHolders(request, localeContext, requestAttributes); try { // 执行服务，doService()是一个抽象方法，在DispatcherServlet中进行了重写 doService(request, response); } catch (ServletException | IOException ex) { failureCause = ex; throw ex; } catch (Throwable ex) { failureCause = ex; throw new NestedServletException(\u0026#34;Request processing failed\u0026#34;, ex); } finally { resetContextHolders(request, previousLocaleContext, previousAttributes); if (requestAttributes != null) { requestAttributes.requestCompleted(); } logResult(request, response, failureCause, asyncManager); publishRequestHandledEvent(request, response, startTime, failureCause); } } b\u0026gt;doService() 所在类：org.springframework.web.servlet.DispatcherServlet\n@Override protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception { logRequest(request); // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. Map\u0026lt;String, Object\u0026gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) { attributesSnapshot = new HashMap\u0026lt;\u0026gt;(); Enumeration\u0026lt;?\u0026gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) { String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(DEFAULT_STRATEGIES_PREFIX)) { attributesSnapshot.put(attrName, request.getAttribute(attrName)); } } } // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); if (this.flashMapManager != null) { FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) { request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); } request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); } RequestPath requestPath = null; if (this.parseRequestPath \u0026amp;\u0026amp; !ServletRequestPathUtils.hasParsedRequestPath(request)) { requestPath = ServletRequestPathUtils.parseAndCache(request); } try { // 处理请求和响应 doDispatch(request, response); } finally { if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) { // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) { restoreAttributesAfterInclude(request, attributesSnapshot); } } if (requestPath != null) { ServletRequestPathUtils.clearParsedRequestPath(request); } } } c\u0026gt;doDispatch() 所在类：org.springframework.web.servlet.DispatcherServlet\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try { ModelAndView mv = null; Exception dispatchException = null; try { processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. /* mappedHandler：调用链 包含handler、interceptorList、interceptorIndex handler：浏览器发送的请求所匹配的控制器方法 interceptorList：处理控制器方法的所有拦截器集合 interceptorIndex：拦截器索引，控制拦截器afterCompletion()的执行 */ mappedHandler = getHandler(processedRequest); if (mappedHandler == null) { noHandlerFound(processedRequest, response); return; } // Determine handler adapter for the current request. // 通过控制器方法创建相应的处理器适配器，调用所对应的控制器方法 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = \u0026#34;GET\u0026#34;.equals(method); if (isGet || \u0026#34;HEAD\u0026#34;.equals(method)) { long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) \u0026amp;\u0026amp; isGet) { return; } } // 调用拦截器的preHandle() if (!mappedHandler.applyPreHandle(processedRequest, response)) { return; } // Actually invoke the handler. // 由处理器适配器调用具体的控制器方法，最终获得ModelAndView对象 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) { return; } applyDefaultViewName(processedRequest, mv); // 调用拦截器的postHandle() mappedHandler.applyPostHandle(processedRequest, response, mv); } catch (Exception ex) { dispatchException = ex; } catch (Throwable err) { // As of 4.3, we\u0026#39;re processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\u0026#34;Handler dispatch failed\u0026#34;, err); } // 后续处理：处理模型数据和渲染视图 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); } catch (Exception ex) { triggerAfterCompletion(processedRequest, response, mappedHandler, ex); } catch (Throwable err) { triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\u0026#34;Handler processing failed\u0026#34;, err)); } finally { if (asyncManager.isConcurrentHandlingStarted()) { // Instead of postHandle and afterCompletion if (mappedHandler != null) { mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); } } else { // Clean up any resources used by a multipart request. if (multipartRequestParsed) { cleanupMultipart(processedRequest); } } } } d\u0026gt;processDispatchResult() private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerExecutionChain mappedHandler, @Nullable ModelAndView mv, @Nullable Exception exception) throws Exception { boolean errorView = false; if (exception != null) { if (exception instanceof ModelAndViewDefiningException) { logger.debug(\u0026#34;ModelAndViewDefiningException encountered\u0026#34;, exception); mv = ((ModelAndViewDefiningException) exception).getModelAndView(); } else { Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(request, response, handler, exception); errorView = (mv != null); } } // Did the handler return a view to render? if (mv != null \u0026amp;\u0026amp; !mv.wasCleared()) { // 处理模型数据和渲染视图 render(mv, request, response); if (errorView) { WebUtils.clearErrorRequestAttributes(request); } } else { if (logger.isTraceEnabled()) { logger.trace(\u0026#34;No view rendering, null ModelAndView returned.\u0026#34;); } } if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) { // Concurrent handling started during a forward return; } if (mappedHandler != null) { // Exception (if any) is already handled.. // 调用拦截器的afterCompletion() mappedHandler.triggerAfterCompletion(request, response, null); } } 4、SpringMVC的执行流程 用户向服务器发送请求，请求被SpringMVC 前端控制器 DispatcherServlet捕获。\nDispatcherServlet对请求URL进行解析，得到请求资源标识符（URI），判断请求URI对应的映射：\na) 不存在\ni. 再判断是否配置了mvc:default-servlet-handler\nii. 如果没配置，则控制台报映射查找不到，客户端展示404错误\niii. 如果有配置，则访问目标资源（一般为静态资源，如：JS,CSS,HTML），找不到客户端也会展示404错误\nb) 存在则执行下面的流程\n根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain执行链对象的形式返回。\nDispatcherServlet 根据获得的Handler，选择一个合适的HandlerAdapter。\n如果成功获得HandlerAdapter，此时将开始执行拦截器的preHandler(…)方法【正向】\n提取Request中的模型数据，填充Handler入参，开始执行Handler（Controller)方法，处理请求。在填充Handler的入参过程中，根据你的配置，Spring将帮你做一些额外的工作：\na) HttpMessageConveter： 将请求消息（如Json、xml等数据）转换成一个对象，将对象转换为指定的响应信息\nb) 数据转换：对请求消息进行数据转换。如String转换成Integer、Double等\nc) 数据格式化：对请求消息进行数据格式化。 如将字符串转换成格式化数字或格式化日期等\nd) 数据验证： 验证数据的有效性（长度、格式等），验证结果存储到BindingResult或Error中\nHandler执行完成后，向DispatcherServlet 返回一个ModelAndView对象。\n此时将开始执行拦截器的postHandle(\u0026hellip;)方法【逆向】。\n根据返回的ModelAndView（此时会判断是否存在异常：如果存在异常，则执行HandlerExceptionResolver进行异常处理）选择一个适合的ViewResolver进行视图解析，根据Model和View，来渲染视图。\n渲染视图完毕执行拦截器的afterCompletion(…)方法【逆向】。\n将渲染结果返回给客户端。\n","permalink":"https://XianCH.github.io/posts/tech/java/springmvc/","summary":"一、SpringMVC简介 1、什么是MVC MVC是一种软件架构的思想，将软件按照模型、视图、控制器来划分 M：Model，模型层，指工程中的JavaBean，作用是处理数据 JavaBean分为两类： 一类称为实体类Bean：专门存储业务数据的，如 Student、User 等 一类称为业务","title":"springmvc学习笔记笔记"},{"content":" Sulv\u0026#39;s Blog 一个记录技术、阅读、生活的博客 👉友链格式 名称： Sulv\u0026rsquo;s Blog 网址： https://www.sulvblog.cn 图标： https://www.sulvblog.cn/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内\n👉Hugo博客交流群 787018782\n","permalink":"https://XianCH.github.io/links/","summary":"Sulv\u0026#39;s Blog 一个记录技术、阅读、生活的博客 👉友链格式 名称： Sulv\u0026rsquo;s Blog 网址： https://www.sulvblog.cn 图标： https://www.sulvblog.cn/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内 👉Hugo博客交流群 787018782","title":"🤝友链"},{"content":"关于我\n英文名: xxxxxx 职业: xxxxxx 运动: 跑步、乒乓球、爬山 ","permalink":"https://XianCH.github.io/about/","summary":"关于我 英文名: xxxxxx 职业: xxxxxx 运动: 跑步、乒乓球、爬山","title":"🙋🏻‍♂️about"}]